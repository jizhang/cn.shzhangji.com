<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Hive小文件问题的处理 | 张吉的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Hive的后端存储是HDFS，它对大文件的处理是非常高效的，如果合理配置文件系统的块大小，NameNode可以支持很大的数据量。但是在数据仓库中，越是上层的表其汇总程度就越高，数据量也就越小。而且这些表通常会按日期进行分区，随着时间的推移，HDFS的文件数目就会逐渐增加。
小文件带来的问题关于这个问题的阐述可以读一读Cloudera的这篇文章。简单来说，HDFS的文件元信息，包括位置、大小、分块信">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive小文件问题的处理">
<meta property="og:url" content="http://shzhangji.com/2014/04/07/hive-small-files/index.html">
<meta property="og:site_name" content="张吉的博客">
<meta property="og:description" content="Hive的后端存储是HDFS，它对大文件的处理是非常高效的，如果合理配置文件系统的块大小，NameNode可以支持很大的数据量。但是在数据仓库中，越是上层的表其汇总程度就越高，数据量也就越小。而且这些表通常会按日期进行分区，随着时间的推移，HDFS的文件数目就会逐渐增加。
小文件带来的问题关于这个问题的阐述可以读一读Cloudera的这篇文章。简单来说，HDFS的文件元信息，包括位置、大小、分块信">
<meta property="og:image" content="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/images/federation.gif">
<meta property="og:updated_time" content="2017-03-09T22:24:58.549Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hive小文件问题的处理">
<meta name="twitter:description" content="Hive的后端存储是HDFS，它对大文件的处理是非常高效的，如果合理配置文件系统的块大小，NameNode可以支持很大的数据量。但是在数据仓库中，越是上层的表其汇总程度就越高，数据量也就越小。而且这些表通常会按日期进行分区，随着时间的推移，HDFS的文件数目就会逐渐增加。
小文件带来的问题关于这个问题的阐述可以读一读Cloudera的这篇文章。简单来说，HDFS的文件元信息，包括位置、大小、分块信">
<meta name="twitter:image" content="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/images/federation.gif">
<meta name="twitter:creator" content="@zjerryj">
<link rel="publisher" href="zhangji87@gmail.com">
  
    <link rel="alternate" href="/cnblogs/atom.xml" title="张吉的博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="https://fonts.proxy.ustclug.org/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/cnblogs/css/style.css">
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-37223379-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/cnblogs/" id="logo">张吉的博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/cnblogs/" id="subtitle">If I rest, I rust.</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/cnblogs/">首页</a>
        
          <a class="main-nav-link" href="/cnblogs/categories/Big-Data">大数据</a>
        
          <a class="main-nav-link" href="/cnblogs/categories/Programming">编程</a>
        
          <a class="main-nav-link" href="/cnblogs/categories/Digest">摘译</a>
        
          <a class="main-nav-link" href="/cnblogs/archives">全部文章</a>
        
          <a class="main-nav-link" href="http://shzhangji.com/">English</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/cnblogs/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://shzhangji.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-hive-small-files" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/cnblogs/2014/04/07/hive-small-files/" class="article-date">
  <time datetime="2014-04-07T09:09:00.000Z" itemprop="datePublished">2014-04-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/cnblogs/categories/Notes/">Notes</a>►<a class="article-category-link" href="/cnblogs/categories/Notes/Big-Data/">Big Data</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Hive小文件问题的处理
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Hive的后端存储是HDFS，它对大文件的处理是非常高效的，如果合理配置文件系统的块大小，NameNode可以支持很大的数据量。但是在数据仓库中，越是上层的表其汇总程度就越高，数据量也就越小。而且这些表通常会按日期进行分区，随着时间的推移，HDFS的文件数目就会逐渐增加。</p>
<h2 id="小文件带来的问题"><a href="#小文件带来的问题" class="headerlink" title="小文件带来的问题"></a>小文件带来的问题</h2><p>关于这个问题的阐述可以读一读Cloudera的<a href="http://blog.cloudera.com/blog/2009/02/the-small-files-problem/" target="_blank" rel="external">这篇文章</a>。简单来说，HDFS的文件元信息，包括位置、大小、分块信息等，都是保存在NameNode的内存中的。每个对象大约占用150个字节，因此一千万个文件及分块就会占用约3G的内存空间，一旦接近这个量级，NameNode的性能就会开始下降了。</p>
<p>此外，HDFS读写小文件时也会更加耗时，因为每次都需要从NameNode获取元信息，并与对应的DataNode建立连接。对于MapReduce程序来说，小文件还会增加Mapper的个数，每个脚本只处理很少的数据，浪费了大量的调度时间。当然，这个问题可以通过使用CombinedInputFile和JVM重用来解决。</p>
<a id="more"></a>
<h2 id="Hive小文件产生的原因"><a href="#Hive小文件产生的原因" class="headerlink" title="Hive小文件产生的原因"></a>Hive小文件产生的原因</h2><p>前面已经提到，汇总后的数据量通常比源数据要少得多。而为了提升运算速度，我们会增加Reducer的数量，Hive本身也会做类似优化——Reducer数量等于源数据的量除以hive.exec.reducers.bytes.per.reducer所配置的量（默认1G）。Reducer数量的增加也即意味着结果文件的增加，从而产生小文件的问题。</p>
<h2 id="配置Hive结果合并"><a href="#配置Hive结果合并" class="headerlink" title="配置Hive结果合并"></a>配置Hive结果合并</h2><p>我们可以通过一些配置项来使Hive在执行结束后对结果文件进行合并：</p>
<ul>
<li><code>hive.merge.mapfiles</code> 在map-only job后合并文件，默认<code>true</code></li>
<li><code>hive.merge.mapredfiles</code> 在map-reduce job后合并文件，默认<code>false</code></li>
<li><code>hive.merge.size.per.task</code> 合并后每个文件的大小，默认<code>256000000</code></li>
<li><code>hive.merge.smallfiles.avgsize</code> 平均文件大小，是决定是否执行合并操作的阈值，默认<code>16000000</code></li>
</ul>
<p>Hive在对结果文件进行合并时会执行一个额外的map-only脚本，mapper的数量是文件总大小除以size.per.task参数所得的值，触发合并的条件是：</p>
<ol>
<li>根据查询类型不同，相应的mapfiles/mapredfiles参数需要打开；</li>
<li>结果文件的平均大小需要大于avgsize参数的值。</li>
</ol>
<p>示例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment">-- map-red job，5个reducer，产生5个60K的文件。</span></div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> dw_stage.zj_small <span class="keyword">as</span></div><div class="line"><span class="keyword">select</span> paid, <span class="keyword">count</span>(*)</div><div class="line"><span class="keyword">from</span> dw_db.dw_soj_imp_dtl</div><div class="line"><span class="keyword">where</span> log_dt = <span class="string">'2014-04-14'</span></div><div class="line"><span class="keyword">group</span> <span class="keyword">by</span> paid;</div><div class="line"></div><div class="line"><span class="comment">-- 执行额外的map-only job，一个mapper，产生一个300K的文件。</span></div><div class="line"><span class="keyword">set</span> hive.merge.mapredfiles=<span class="literal">true</span>;</div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> dw_stage.zj_small <span class="keyword">as</span></div><div class="line"><span class="keyword">select</span> paid, <span class="keyword">count</span>(*)</div><div class="line"><span class="keyword">from</span> dw_db.dw_soj_imp_dtl</div><div class="line"><span class="keyword">where</span> log_dt = <span class="string">'2014-04-14'</span></div><div class="line"><span class="keyword">group</span> <span class="keyword">by</span> paid;</div><div class="line"></div><div class="line"><span class="comment">-- map-only job，45个mapper，产生45个25M左右的文件。</span></div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> dw_stage.zj_small <span class="keyword">as</span></div><div class="line"><span class="keyword">select</span> *</div><div class="line"><span class="keyword">from</span> dw_db.dw_soj_imp_dtl</div><div class="line"><span class="keyword">where</span> log_dt = <span class="string">'2014-04-14'</span></div><div class="line"><span class="keyword">and</span> paid <span class="keyword">like</span> <span class="string">'%baidu%'</span>;</div><div class="line"></div><div class="line"><span class="comment">-- 执行额外的map-only job，4个mapper，产生4个250M左右的文件。</span></div><div class="line"><span class="keyword">set</span> hive.merge.smallfiles.avgsize=<span class="number">100000000</span>;</div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> dw_stage.zj_small <span class="keyword">as</span></div><div class="line"><span class="keyword">select</span> *</div><div class="line"><span class="keyword">from</span> dw_db.dw_soj_imp_dtl</div><div class="line"><span class="keyword">where</span> log_dt = <span class="string">'2014-04-14'</span></div><div class="line"><span class="keyword">and</span> paid <span class="keyword">like</span> <span class="string">'%baidu%'</span>;</div></pre></td></tr></table></figure>
<h3 id="压缩文件的处理"><a href="#压缩文件的处理" class="headerlink" title="压缩文件的处理"></a>压缩文件的处理</h3><p>如果结果表使用了压缩格式，则必须配合SequenceFile来存储，否则无法进行合并，以下是示例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">set</span> mapred.output.compression.type=<span class="keyword">BLOCK</span>;</div><div class="line"><span class="keyword">set</span> hive.exec.compress.output=<span class="literal">true</span>;</div><div class="line"><span class="keyword">set</span> mapred.output.compression.codec=org.apache.hadoop.io.compress.LzoCodec;</div><div class="line"><span class="keyword">set</span> hive.merge.smallfiles.avgsize=<span class="number">100000000</span>;</div><div class="line"></div><div class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> dw_stage.zj_small;</div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> dw_stage.zj_small</div><div class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> SEQUENCEFILE</div><div class="line"><span class="keyword">as</span> <span class="keyword">select</span> *</div><div class="line"><span class="keyword">from</span> dw_db.dw_soj_imp_dtl</div><div class="line"><span class="keyword">where</span> log_dt = <span class="string">'2014-04-14'</span></div><div class="line"><span class="keyword">and</span> paid <span class="keyword">like</span> <span class="string">'%baidu%'</span>;</div></pre></td></tr></table></figure>
<h2 id="使用HAR归档文件"><a href="#使用HAR归档文件" class="headerlink" title="使用HAR归档文件"></a>使用HAR归档文件</h2><p>Hadoop的<a href="http://hadoop.apache.org/docs/stable1/hadoop_archives.html" target="_blank" rel="external">归档文件</a>格式也是解决小文件问题的方式之一。而且Hive提供了<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Archiving" target="_blank" rel="external">原生支持</a>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">set hive.archive.enabled=true;</div><div class="line">set hive.archive.har.parentdir.settable=true;</div><div class="line">set har.partfile.size=1099511627776;</div><div class="line"></div><div class="line">ALTER TABLE srcpart ARCHIVE PARTITION(ds=&apos;2008-04-08&apos;, hr=&apos;12&apos;);</div><div class="line"></div><div class="line">ALTER TABLE srcpart UNARCHIVE PARTITION(ds=&apos;2008-04-08&apos;, hr=&apos;12&apos;);</div></pre></td></tr></table></figure>
<p>如果使用的不是分区表，则可创建成外部表，并使用<code>har://</code>协议来指定路径。</p>
<h2 id="HDFS-Federation"><a href="#HDFS-Federation" class="headerlink" title="HDFS Federation"></a>HDFS Federation</h2><p>Hadoop V2引入了HDFS Federation的概念：</p>
<p><img src="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/images/federation.gif" alt=""></p>
<p>实则是将NameNode做了拆分，从而增强了它的扩展性，小文件的问题也能够得到缓解。</p>
<h2 id="其他工具"><a href="#其他工具" class="headerlink" title="其他工具"></a>其他工具</h2><p>对于通常的应用，使用Hive结果合并就能达到很好的效果。如果不想因此增加运行时间，可以自行编写一些脚本，在系统空闲时对分区内的文件进行合并，也能达到目的。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://shzhangji.com/cnblogs/2014/04/07/hive-small-files/" data-id="cj56fexsh002mpem68geo2as5" class="article-share-link">分享</a>
      
        <a href="http://shzhangji.com/cnblogs/2014/04/07/hive-small-files/#disqus_thread" class="article-comment-link">留言</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/cnblogs/2014/07/05/deploy-shark-0.9-with-cdh-4.5/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">
        
          在CDH 4.5上安装Shark 0.9
        
      </div>
    </a>
  
  
    <a href="/cnblogs/2014/01/25/java-reflection-tutorial/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">Java反射机制</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/cnblogs/tags/analytics/" style="font-size: 10px;">analytics</a> <a href="/cnblogs/tags/aosa/" style="font-size: 13.33px;">aosa</a> <a href="/cnblogs/tags/clojure/" style="font-size: 20px;">clojure</a> <a href="/cnblogs/tags/crossfilter/" style="font-size: 10px;">crossfilter</a> <a href="/cnblogs/tags/dc-js/" style="font-size: 10px;">dc.js</a> <a href="/cnblogs/tags/druid/" style="font-size: 10px;">druid</a> <a href="/cnblogs/tags/es6/" style="font-size: 10px;">es6</a> <a href="/cnblogs/tags/fp/" style="font-size: 10px;">fp</a> <a href="/cnblogs/tags/frontend/" style="font-size: 10px;">frontend</a> <a href="/cnblogs/tags/git/" style="font-size: 10px;">git</a> <a href="/cnblogs/tags/hadoop/" style="font-size: 16.67px;">hadoop</a> <a href="/cnblogs/tags/hive/" style="font-size: 13.33px;">hive</a> <a href="/cnblogs/tags/javascript/" style="font-size: 13.33px;">javascript</a> <a href="/cnblogs/tags/lodash/" style="font-size: 10px;">lodash</a> <a href="/cnblogs/tags/machine-learning/" style="font-size: 10px;">machine learning</a> <a href="/cnblogs/tags/mapreduce/" style="font-size: 10px;">mapreduce</a> <a href="/cnblogs/tags/nginx/" style="font-size: 10px;">nginx</a> <a href="/cnblogs/tags/noir/" style="font-size: 16.67px;">noir</a> <a href="/cnblogs/tags/ops/" style="font-size: 13.33px;">ops</a> <a href="/cnblogs/tags/perl/" style="font-size: 13.33px;">perl</a> <a href="/cnblogs/tags/programming/" style="font-size: 10px;">programming</a> <a href="/cnblogs/tags/python/" style="font-size: 13.33px;">python</a> <a href="/cnblogs/tags/scala/" style="font-size: 10px;">scala</a> <a href="/cnblogs/tags/spark/" style="font-size: 13.33px;">spark</a> <a href="/cnblogs/tags/storm/" style="font-size: 10px;">storm</a> <a href="/cnblogs/tags/stream-processing/" style="font-size: 10px;">stream processing</a> <a href="/cnblogs/tags/translation/" style="font-size: 13.33px;">translation</a> <a href="/cnblogs/tags/websocket/" style="font-size: 10px;">websocket</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2017/07/">七月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2017/06/">六月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2016/03/">三月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2015/09/">九月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2015/06/">六月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2015/03/">三月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2015/01/">一月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2014/12/">十二月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2014/11/">十一月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2014/10/">十月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2014/07/">七月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2014/04/">四月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2014/01/">一月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/12/">十二月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/09/">九月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/06/">六月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/05/">五月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/04/">四月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/03/">三月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/02/">二月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/01/">一月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2012/12/">十二月 2012</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2012/11/">十一月 2012</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/cnblogs/2017/07/16/log-tailer-with-websocket-and-python/">使用 WebSocket 和 Python 编写日志查看器</a>
          </li>
        
          <li>
            <a href="/cnblogs/2017/06/29/why-use-lodash-when-es6-is-available/">为什么不用 ES6 完全替换 Lodash</a>
          </li>
        
          <li>
            <a href="/cnblogs/2017/06/18/build-interactive-report-with-crossfilter-and-dc-js/">使用 Crossfilter 和 dc.js 构建交互式报表</a>
          </li>
        
          <li>
            <a href="/cnblogs/2017/06/18/druid-machine-learning-spark/">Hive+Druid 实现快速查询；回归分析是机器学习吗；StructuredStreaming 可用于生产环境</a>
          </li>
        
          <li>
            <a href="/cnblogs/2016/03/13/top-5-frameworks/">开发人员必知的5种开源框架</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 张吉<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/cnblogs/" class="mobile-nav-link">首页</a>
  
    <a href="/cnblogs/categories/Big-Data" class="mobile-nav-link">大数据</a>
  
    <a href="/cnblogs/categories/Programming" class="mobile-nav-link">编程</a>
  
    <a href="/cnblogs/categories/Digest" class="mobile-nav-link">摘译</a>
  
    <a href="/cnblogs/archives" class="mobile-nav-link">全部文章</a>
  
    <a href="http://shzhangji.com/" class="mobile-nav-link">English</a>
  
</nav>
    
<script>
  var disqus_shortname = 'jizhang';
  
  var disqus_url = 'http://shzhangji.com/cnblogs/2014/04/07/hive-small-files/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="https://ajax.proxy.ustclug.org/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/cnblogs/fancybox/jquery.fancybox.css">
  <script src="/cnblogs/fancybox/jquery.fancybox.pack.js"></script>


<script src="/cnblogs/js/script.js"></script>

  </div>
</body>
</html>