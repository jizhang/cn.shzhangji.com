<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>张吉的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="张吉的博客">
<meta property="og:url" content="http://shzhangji.com/cnblogs/page/2/index.html">
<meta property="og:site_name" content="张吉的博客">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="张吉的博客">
<meta name="twitter:creator" content="@zjerryj">
<link rel="publisher" href="zhangji87@gmail.com">
  
    <link rel="alternate" href="/cnblogs/atom.xml" title="张吉的博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link rel="stylesheet" href="/cnblogs/css/source-code-pro.css">
  
  <link rel="stylesheet" href="/cnblogs/css/style.css">
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-37223379-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/cnblogs/" id="logo">张吉的博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/cnblogs/" id="subtitle">If I rest, I rust.</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/cnblogs/">首页</a>
        
          <a class="main-nav-link" href="/cnblogs/categories/Big-Data">大数据</a>
        
          <a class="main-nav-link" href="/cnblogs/categories/Programming">编程</a>
        
          <a class="main-nav-link" href="/cnblogs/categories/Digest">摘译</a>
        
          <a class="main-nav-link" href="/cnblogs/archives">全部文章</a>
        
          <a class="main-nav-link" href="http://shzhangji.com/">English</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/cnblogs/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://shzhangji.com/cnblogs"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-error-handling-in-restful-api" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/cnblogs/2018/04/07/error-handling-in-restful-api/" class="article-date">
  <time datetime="2018-04-07T06:49:19.000Z" itemprop="datePublished">2018-04-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/cnblogs/categories/Programming/">Programming</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/cnblogs/2018/04/07/error-handling-in-restful-api/">RESTful API 中的错误处理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/cnblogs/images/restful-api.png" alt="RESTful API"></p>
<p>构建 Web 服务时，我们会使用 RESTful API 来实现组件间的通信，特别是在现今前后端分离的技术背景下。REST 是一种基于 HTTP 协议的通信方式，它简单、基于文本、且在各种语言、浏览器及客户端软件中能得到很好的支持。然而，REST 目前并没有一个普遍接受的标准，因此开发者需要自行决定 API 的设计，其中一项决策就是错误处理。比如我们是否应该使用 HTTP 状态码来标识错误？如何返回表单验证的结果等等。以下这篇文章是基于日常使用中的经验总结的一套错误处理流程，供读者们参考。</p>
<h2 id="错误的分类"><a href="#错误的分类" class="headerlink" title="错误的分类"></a>错误的分类</h2><p>错误可以分为两种类型：全局错误和本地错误。全局错误包括：请求了一个不存在的 API、无权请求这个 API、数据库连接失败、或其他一些没有预期到的、会终止程序运行的服务端错误。这类错误应该由 Web 框架捕获，无需各个 API 处理。</p>
<p>本地错误则和 API 密切相关，例如表单验证、唯一性检查、或其他可预期的错误。我们需要编写特定代码来捕获这类错误，并抛出一个包含提示信息的全局异常，供 Web 框架捕获并返回给客户端。</p>
<p>例如，Flask 框架就提供了此类全局异常处理机制：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BadRequest</span><span class="params">(Exception)</span>:</span></span><br><span class="line">    <span class="string">"""将本地错误包装成一个异常实例供抛出"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, message, status=<span class="number">400</span>, payload=None)</span>:</span></span><br><span class="line">        self.message = message</span><br><span class="line">        self.status = status</span><br><span class="line">        self.payload = payload</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.errorhandler(BadRequest)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle_bad_request</span><span class="params">(error)</span>:</span></span><br><span class="line">    <span class="string">"""捕获 BadRequest 全局异常，序列化为 JSON 并返回 HTTP 400"""</span></span><br><span class="line">    payload = dict(error.payload <span class="keyword">or</span> ())</span><br><span class="line">    payload[<span class="string">'status'</span>] = error.status</span><br><span class="line">    payload[<span class="string">'message'</span>] = error.message</span><br><span class="line">    <span class="keyword">return</span> jsonify(payload), <span class="number">400</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/person', methods=['POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">person_post</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""创建用户的 API，成功则返回用户 ID"""</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> request.form.get(<span class="string">'username'</span>):</span><br><span class="line">        <span class="keyword">raise</span> BadRequest(<span class="string">'用户名不能为空'</span>, <span class="number">40001</span>, &#123; <span class="string">'ext'</span>: <span class="number">1</span> &#125;)</span><br><span class="line">    <span class="keyword">return</span> jsonify(last_insert_id=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
        
          <p class="article-more-link">
            <a href="/cnblogs/2018/04/07/error-handling-in-restful-api/#more">阅读全文</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://shzhangji.com/cnblogs/2018/04/07/error-handling-in-restful-api/" data-id="cjzqij3rf003txkr4v7omvg93" class="article-share-link">分享</a>
      
        <a href="http://shzhangji.com/cnblogs/2018/04/07/error-handling-in-restful-api/#disqus_thread" class="article-comment-link">留言</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/frontend/">frontend</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/javascript/">javascript</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/python/">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/restful/">restful</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-flume-source-code-component-lifecycle" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/cnblogs/2017/10/24/flume-source-code-component-lifecycle/" class="article-date">
  <time datetime="2017-10-24T01:18:26.000Z" itemprop="datePublished">2017-10-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/cnblogs/categories/Big-Data/">Big Data</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/cnblogs/2017/10/24/flume-source-code-component-lifecycle/">Flume 源码解析：组件生命周期</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://flume.apache.org/" target="_blank" rel="noopener">Apache Flume</a> 是数据仓库体系中用于做实时 ETL 的工具。它提供了丰富的数据源和写入组件，这些组件在运行时都由 Flume 的生命周期管理机制进行监控和维护。本文将对这部分功能的源码进行解析。</p>
<h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><p>Flume 的源码可以从 GitHub 上下载。它是一个 Maven 项目，我们将其导入到 IDE 中以便更好地进行源码阅读。以下是代码仓库的基本结构：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/flume-ng-node</span><br><span class="line">/flume-ng-code</span><br><span class="line">/flume-ng-sdk</span><br><span class="line">/flume-ng-sources/flume-kafka-source</span><br><span class="line">/flume-ng-channels/flume-kafka-channel</span><br><span class="line">/flume-ng-sinks/flume-hdfs-sink</span><br></pre></td></tr></table></figure>
<h2 id="程序入口"><a href="#程序入口" class="headerlink" title="程序入口"></a>程序入口</h2><p>Flume Agent 的入口 <code>main</code> 函数位于 <code>flume-ng-node</code> 模块的 <code>org.apache.flume.node.Application</code> 类中。下列代码是该函数的摘要：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Application</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    CommandLineParser parser = <span class="keyword">new</span> GnuParser();</span><br><span class="line">    <span class="keyword">if</span> (isZkConfigured) &#123;</span><br><span class="line">      <span class="keyword">if</span> (reload) &#123;</span><br><span class="line">        PollingZooKeeperConfigurationProvider zookeeperConfigurationProvider;</span><br><span class="line">        components.add(zookeeperConfigurationProvider);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        StaticZooKeeperConfigurationProvider zookeeperConfigurationProvider;</span><br><span class="line">        application.handleConfigurationEvent();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// PropertiesFileConfigurationProvider</span></span><br><span class="line">    &#125;</span><br><span class="line">    application.start();</span><br><span class="line">    Runtime.getRuntime().addShutdownHook(<span class="keyword">new</span> Thread(<span class="string">"agent-shutdown-hook"</span>) &#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        appReference.stop();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>启动过程说明如下：</p>
<ol>
<li>使用 <code>commons-cli</code> 对命令行参数进行解析，提取 Agent 名称、配置信息读取方式及其路径信息；</li>
<li>配置信息可以通过文件或 ZooKeeper 的方式进行读取，两种方式都支持热加载，即我们不需要重启 Agent 就可以更新配置内容：<ul>
<li>基于文件的配置热加载是通过一个后台线程对文件进行轮询实现的；</li>
<li>基于 ZooKeeper 的热加载则是使用了 Curator 的 <code>NodeCache</code> 模式，底层是 ZooKeeper 原生的监听（Watch）特性。</li>
</ul>
</li>
<li>如果配置热更新是开启的（默认开启），配置提供方 <code>ConfigurationProvider</code> 就会将自身注册到 Agent 程序的组件列表中，并在 <code>Application#start</code> 方法调用后，由 <code>LifecycleSupervisor</code> 类进行启动和管理，加载和解析配置文件，从中读取组件列表。</li>
<li>如果热更新未开启，则配置提供方将在启动时立刻读取配置文件，并由 <code>LifecycleSupervisor</code> 启动和管理所有组件。</li>
<li>最后，<code>main</code> 会调用 <code>Runtime#addShutdownHook</code>，当 JVM 关闭时（SIGTERM 或者 Ctrl+C），<code>Application#stop</code> 会被用于关闭 Flume Agent，使各组件优雅退出。</li>
</ol>
        
          <p class="article-more-link">
            <a href="/cnblogs/2017/10/24/flume-source-code-component-lifecycle/#more">阅读全文</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://shzhangji.com/cnblogs/2017/10/24/flume-source-code-component-lifecycle/" data-id="cjzqij3rh003vxkr4cglq4ge4" class="article-share-link">分享</a>
      
        <a href="http://shzhangji.com/cnblogs/2017/10/24/flume-source-code-component-lifecycle/#disqus_thread" class="article-comment-link">留言</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/flume/">flume</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/java/">java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/source-code/">source code</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-pandas-and-tidy-data" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/cnblogs/2017/09/30/pandas-and-tidy-data/" class="article-date">
  <time datetime="2017-09-30T06:37:56.000Z" itemprop="datePublished">2017-09-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/cnblogs/categories/Big-Data/">Big Data</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/cnblogs/2017/09/30/pandas-and-tidy-data/">Pandas 与数据整理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在 <a href="https://www.jstatsoft.org/article/view/v059i10" target="_blank" rel="noopener">Tidy Data</a> 论文中，<a href="https://en.wikipedia.org/wiki/Hadley_Wickham" target="_blank" rel="noopener">Wickham 博士</a> 提出了这样一种“整洁”的数据结构：每个变量是一列，每次观测结果是一行，不同的观测类型存放在单独的表中。他认为这样的数据结构可以帮助分析师更简单高效地进行处理、建模、和可视化。他在论文中列举了 <em>五种</em> 不符合整洁数据的情况，并演示了如何通过 <a href="https://github.com/hadley/tidy-data/" target="_blank" rel="noopener">R 语言</a> 对它们进行整理。本文中，我们将使用 Python 和 Pandas 来达到同样的目的。</p>
<p>文中的源代码和演示数据可以在 GitHub（<a href="https://github.com/jizhang/pandas-tidy-data" target="_blank" rel="noopener">链接</a>）上找到。读者应该已经安装好 Python 开发环境，推荐各位使用 Anaconda 和 Spyder IDE。</p>
<h2 id="列名称是数据值，而非变量名"><a href="#列名称是数据值，而非变量名" class="headerlink" title="列名称是数据值，而非变量名"></a>列名称是数据值，而非变量名</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">'data/pew.csv'</span>)</span><br><span class="line">df.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/cnblogs/images/tidy-data/pew.png" alt="宗教信仰与收入 - Pew 论坛"></p>
<p>表中的列“&lt;$10k”、“$10-20k”其实是“收入”变量的具体值。<em>变量</em> 是指某一特性的观测值，如身高、体重，本例中则是收入、宗教信仰。表中的数值数据构成了另一个变量——人数。要做到 <em>每个变量是一列</em> ，我们需要进行以下变换：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df = df.set_index(<span class="string">'religion'</span>)</span><br><span class="line">df = df.stack()</span><br><span class="line">df.index = df.index.rename(<span class="string">'income'</span>, level=<span class="number">1</span>)</span><br><span class="line">df.name = <span class="string">'frequency'</span></span><br><span class="line">df = df.reset_index()</span><br><span class="line">df.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/cnblogs/images/tidy-data/pew-tidy.png" alt="宗教信仰与收入 - 整洁版"></p>
        
          <p class="article-more-link">
            <a href="/cnblogs/2017/09/30/pandas-and-tidy-data/#more">阅读全文</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://shzhangji.com/cnblogs/2017/09/30/pandas-and-tidy-data/" data-id="cjzqij3rd003qxkr4shzhafzm" class="article-share-link">分享</a>
      
        <a href="http://shzhangji.com/cnblogs/2017/09/30/pandas-and-tidy-data/#disqus_thread" class="article-comment-link">留言</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/analytics/">analytics</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/pandas/">pandas</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/python/">python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-apache-beam-quick-start-with-python" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/cnblogs/2017/09/13/apache-beam-quick-start-with-python/" class="article-date">
  <time datetime="2017-09-13T04:39:03.000Z" itemprop="datePublished">2017-09-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/cnblogs/categories/Big-Data/">Big Data</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/cnblogs/2017/09/13/apache-beam-quick-start-with-python/">Apache Beam 快速入门（Python 版）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://beam.apache.org/get-started/beam-overview/" target="_blank" rel="noopener">Apache Beam</a> 是一种大数据处理标准，由谷歌于 2016 年创建。它提供了一套统一的 DSL 用以处理离线和实时数据，并能在目前主流的大数据处理平台上使用，包括 Spark、Flink、以及谷歌自身的商业套件 Dataflow。Beam 的数据模型基于过去的几项研究成果：<a href="https://web.archive.org/web/20160923141630/https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35650.pdf" target="_blank" rel="noopener">FlumeJava</a>、<a href="https://web.archive.org/web/20160201091359/http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41378.pdf" target="_blank" rel="noopener">Millwheel</a>，适用场景包括 ETL、统计分析、实时计算等。目前，Beam 提供了两种语言的 SDK：Java、Python。本文将讲述如何使用 Python 编写 Beam 应用程序。</p>
<p><img src="/cnblogs/images/beam/arch.jpg" alt="Apache Beam Pipeline"></p>
<h2 id="安装-Apache-Beam"><a href="#安装-Apache-Beam" class="headerlink" title="安装 Apache Beam"></a>安装 Apache Beam</h2><p>Apache Beam Python SDK 必须使用 Python 2.7.x 版本，你可以安装 <a href="https://github.com/pyenv/pyenv" target="_blank" rel="noopener">pyenv</a> 来管理不同版本的 Python，或者直接从<a href="https://www.python.org/downloads/source/" target="_blank" rel="noopener">源代码</a>编译安装（需要支持 SSL）。之后，你便可以在 Python 虚拟环境中安装 Beam SDK 了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ virtualenv venv --distribute</span><br><span class="line">$ source venv/bin/activate</span><br><span class="line">(venv) $ pip install apache-beam</span><br></pre></td></tr></table></figure>
        
          <p class="article-more-link">
            <a href="/cnblogs/2017/09/13/apache-beam-quick-start-with-python/#more">阅读全文</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://shzhangji.com/cnblogs/2017/09/13/apache-beam-quick-start-with-python/" data-id="cjzqij3rb003nxkr4zoj90g5v" class="article-share-link">分享</a>
      
        <a href="http://shzhangji.com/cnblogs/2017/09/13/apache-beam-quick-start-with-python/#disqus_thread" class="article-comment-link">留言</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/apache-beam/">apache beam</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/mapreduce/">mapreduce</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/python/">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/stream-processing/">stream processing</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-python-data-science-anomaly-detection-opensource" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/cnblogs/2017/09/06/python-data-science-anomaly-detection-opensource/" class="article-date">
  <time datetime="2017-09-06T01:49:10.000Z" itemprop="datePublished">2017-09-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/cnblogs/categories/Digest/">Digest</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/cnblogs/2017/09/06/python-data-science-anomaly-detection-opensource/">2017 Top 15 Python 数据科学类库；时间序列异常点检测；如何加入开源项目</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="2017-Top-15-Python-数据科学类库"><a href="#2017-Top-15-Python-数据科学类库" class="headerlink" title="2017 Top 15 Python 数据科学类库"></a>2017 Top 15 Python 数据科学类库</h2><p><img src="/cnblogs/images/digest/google-trends.png" alt="Google Trends"></p>
<p>近年来，Python 在数据科学领域得到了越来越多的关注，本文整理归类了使用率最高的数据科学类库，供大家参考。</p>
<p>NumPy、SciPy、Pandas 是 Python 数据科学的核心类库。NumPy 提供了 N 维数组、矩阵、向量等数据结构，能够进行高性能的数学运算；SciPy 包含了线性代数、拟合优化、统计学习的通用方法；Pandas 则一般用于数据清洗、探索型分析等工作。</p>
<p>可视化方面，Matplotlib 是最早流行的类库，提供了丰富的图形化接口，但 API 的使用方式偏底层，需要编写较多代码；Seaborn 构建在 Matplotlib 之上，重新定义了图表样式，更适合在报告、演示文档中使用，并且它还预置了诸多探索型分析函数，可以快速地对数据进行描述性可视化；Bokeh 主打交互性，它运行在浏览器中，让使用者可以方便地调节可视化参数；Plotly 也是一款基于页面的可视化工具，但因为是商业软件，需要授权后才能使用。</p>
<p>SciKit-Learn 是公认的 Python 机器学习标准类库，它提供了准确、统一的接口，可以方便地使用各种机器学习算法；深度学习领域，Theano 是比较老牌的类库之一，特点是能够运行于不同的系统架构之上（CPU、GPU）；Tensorflow 则是最近较火的基础类库，使用它提供的各种算子和数据流工具，我们可以构建出多层神经网络，在集群上对大数据进行运算；Keras 则是一款较上层的工具库，底层使用 Theano 或 Tensorflow 作为引擎，可以通过快速构建实验来验证模型。</p>
<p>自然语言处理领域中，NLTK 提供了文本标记、分词、构建语料树等功能，用以揭示句中或句间的依赖关系；Gensim 则擅长构建向量空间模型、话题建模、挖掘大量文本中重复出现的模式，其算法都属于非监督学习，因此只需提供语料库就能得到结果。</p>
<p>原文：<a href="http://www.kdnuggets.com/2017/06/top-15-python-libraries-data-science.html" target="_blank" rel="noopener">http://www.kdnuggets.com/2017/06/top-15-python-libraries-data-science.html</a></p>
        
          <p class="article-more-link">
            <a href="/cnblogs/2017/09/06/python-data-science-anomaly-detection-opensource/#more">阅读全文</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://shzhangji.com/cnblogs/2017/09/06/python-data-science-anomaly-detection-opensource/" data-id="cjzqij3r9003jxkr43fpxtobp" class="article-share-link">分享</a>
      
        <a href="http://shzhangji.com/cnblogs/2017/09/06/python-data-science-anomaly-detection-opensource/#disqus_thread" class="article-comment-link">留言</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/analytics/">analytics</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/data-science/">data science</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/opensource/">opensource</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hive-window-and-analytical-functions" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/cnblogs/2017/09/05/hive-window-and-analytical-functions/" class="article-date">
  <time datetime="2017-09-05T04:17:10.000Z" itemprop="datePublished">2017-09-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/cnblogs/categories/Big-Data/">Big Data</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/cnblogs/2017/09/05/hive-window-and-analytical-functions/">Hive 窗口与分析型函数</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>SQL 结构化查询语言是数据分析领域的重要工具之一。它提供了数据筛选、转换、聚合等操作，并能借助 Hive 和 Hadoop 进行大数据量的处理。但是，传统的 SQL 语句并不能支持诸如分组排名、滑动平均值等计算，原因是 <code>GROUP BY</code> 语句只能为每个分组的数据返回一行结果，而非每条数据一行。幸运的是，新版的 SQL 标准引入了窗口查询功能，使用 <code>WINDOW</code> 语句我们可以基于分区和窗口为每条数据都生成一行结果记录，这一标准也已得到了 Hive 的支持。</p>
<p><img src="/cnblogs/images/hive-window/window-stock.png" alt="滑动平均值"></p>
<p>举例来说，我们想要计算表中每只股票的两日滑动平均值，可以编写以下查询语句：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  <span class="string">`date`</span>, <span class="string">`stock`</span>, <span class="string">`close`</span></span><br><span class="line">  ,<span class="keyword">AVG</span>(<span class="string">`close`</span>) <span class="keyword">OVER</span> <span class="string">`w`</span> <span class="keyword">AS</span> <span class="string">`mavg`</span></span><br><span class="line"><span class="keyword">FROM</span> <span class="string">`t_stock`</span></span><br><span class="line"><span class="keyword">WINDOW</span> <span class="string">`w`</span> <span class="keyword">AS</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="string">`stock`</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="string">`date`</span></span><br><span class="line">               <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">1</span> <span class="keyword">PRECEDING</span> <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="keyword">ROW</span>)</span><br></pre></td></tr></table></figure>
<p><code>OVER</code>、<code>WINDOW</code>、以及 <code>ROWS BETWEEN AND</code> 都是新增的窗口查询关键字。在这个查询中，<code>PARTITION BY</code> 和 <code>ORDER BY</code> 的工作方式与 <code>GROUP BY</code>、<code>ORDER BY</code> 相似，区别在于它们不会将多行记录聚合成一条结果，而是将它们拆分到互不重叠的分区中进行后续处理。其后的 <code>ROWS BETWEEN AND</code> 语句用于构建一个 <em>窗口帧</em>。此例中，每一个窗口帧都包含了当前记录和上一条记录。下文会对窗口帧做进一步描述。最后，<code>AVG</code> 是一个窗口函数，用于计算每个窗口帧的结果。窗口帧的定义（<code>WINDOW</code> 语句）还可以直接附加到窗口函数之后：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">AVG</span>(<span class="string">`close`</span>) <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="string">`stock`</span>) <span class="keyword">AS</span> <span class="string">`mavg`</span> <span class="keyword">FROM</span> <span class="string">`t_stock`</span>;</span><br></pre></td></tr></table></figure>
        
          <p class="article-more-link">
            <a href="/cnblogs/2017/09/05/hive-window-and-analytical-functions/#more">阅读全文</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://shzhangji.com/cnblogs/2017/09/05/hive-window-and-analytical-functions/" data-id="cjzqij3r7003hxkr4knvhi865" class="article-share-link">分享</a>
      
        <a href="http://shzhangji.com/cnblogs/2017/09/05/hive-window-and-analytical-functions/#disqus_thread" class="article-comment-link">留言</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/analytics/">analytics</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/hive/">hive</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/sql/">sql</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-an-introduction-to-stream-lib-the-stream-processing-utilities" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/cnblogs/2017/08/27/an-introduction-to-stream-lib-the-stream-processing-utilities/" class="article-date">
  <time datetime="2017-08-27T05:47:16.000Z" itemprop="datePublished">2017-08-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/cnblogs/categories/Big-Data/">Big Data</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/cnblogs/2017/08/27/an-introduction-to-stream-lib-the-stream-processing-utilities/">实时计算工具库 stream-lib 使用指南</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>进行大数据处理时，计算唯一值、95% 分位数等操作非常占用空间和时间。但有时我们只是想对数据集有一个概略的了解，数值的准确性并不那么重要。实时监控系统中也是如此，可以容忍一定的错误率。目前已经有许多算法可以通过牺牲准确性来减少计算所需的空间和时间，这些算法大多支持数据结构之间的合并，因此可以方便地用在实时计算中。<a href="https://github.com/addthis/stream-lib" target="_blank" rel="noopener"><code>stream-lib</code></a> 就是一个集成了很多此类算法的实时计算工具库，是对现有研究成果的 Java 实现。本文就将介绍这一工具库的使用方法。</p>
<h2 id="唯一值计算-HyperLogLog"><a href="#唯一值计算-HyperLogLog" class="headerlink" title="唯一值计算 HyperLogLog"></a>唯一值计算 <code>HyperLogLog</code></h2><p>独立访客（UV）是网站的重要指标之一。我们通常会为每一个用户生成一个 UUID，并在 HTTP Cookie 中记录和跟踪，或直接使用 IP 地址做近似计算。我们可以使用一个 <code>HashSet</code> 来计算 UV 的准确值，但无疑会占用大量的空间。<code>HyperLogLog</code> 则是一种近似算法，用于解决此类唯一值计算的问题。该算法<a href="https://en.wikipedia.org/wiki/HyperLogLog" target="_blank" rel="noopener">在对超过 10^9 个唯一值进行计算时可以做到 2% 的标准差，并只占用 1.5 kB 内存</a>。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.clearspring.analytics<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>stream<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ICardinality card = <span class="keyword">new</span> HyperLogLog(<span class="number">10</span>);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i : <span class="keyword">new</span> <span class="keyword">int</span>[] &#123; <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span> &#125;) &#123;</span><br><span class="line">    card.offer(i);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(card.cardinality()); <span class="comment">// 4</span></span><br></pre></td></tr></table></figure>
        
          <p class="article-more-link">
            <a href="/cnblogs/2017/08/27/an-introduction-to-stream-lib-the-stream-processing-utilities/#more">阅读全文</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://shzhangji.com/cnblogs/2017/08/27/an-introduction-to-stream-lib-the-stream-processing-utilities/" data-id="cjzqij3r3003exkr4cjyifrz0" class="article-share-link">分享</a>
      
        <a href="http://shzhangji.com/cnblogs/2017/08/27/an-introduction-to-stream-lib-the-stream-processing-utilities/#disqus_thread" class="article-comment-link">留言</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/algorithm/">algorithm</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/java/">java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/stream-processing/">stream processing</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-extract-data-from-mysql-with-binlog-and-canal" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/cnblogs/2017/08/13/extract-data-from-mysql-with-binlog-and-canal/" class="article-date">
  <time datetime="2017-08-13T02:06:58.000Z" itemprop="datePublished">2017-08-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/cnblogs/categories/Big-Data/">Big Data</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/cnblogs/2017/08/13/extract-data-from-mysql-with-binlog-and-canal/">使用 Binlog 和 Canal 从 MySQL 抽取数据</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>数据抽取是 ETL 流程的第一步。我们会将数据从 RDBMS 或日志服务器等外部系统抽取至数据仓库，进行清洗、转换、聚合等操作。在现代网站技术栈中，MySQL 是最常见的数据库管理系统，我们会从多个不同的 MySQL 实例中抽取数据，存入一个中心节点，或直接进入 Hive。市面上已有多种成熟的、基于 SQL 查询的抽取软件，如著名的开源项目 <a href="http://sqoop.apache.org/" target="_blank" rel="noopener">Apache Sqoop</a>，然而这些工具并不支持实时的数据抽取。MySQL Binlog 则是一种实时的数据流，用于主从节点之间的数据复制，我们可以利用它来进行数据抽取。借助阿里巴巴开源的 <a href="https://github.com/alibaba/canal" target="_blank" rel="noopener">Canal</a> 项目，我们能够非常便捷地将 MySQL 中的数据抽取到任意目标存储中。</p>
<p><img src="/cnblogs/images/canal.png" alt="Canal"></p>
<h2 id="Canal-的组成部分"><a href="#Canal-的组成部分" class="headerlink" title="Canal 的组成部分"></a>Canal 的组成部分</h2><p>简单来说，Canal 会将自己伪装成 MySQL 从节点（Slave），并从主节点（Master）获取 Binlog，解析和贮存后供下游消费端使用。Canal 包含两个组成部分：服务端和客户端。服务端负责连接至不同的 MySQL 实例，并为每个实例维护一个事件消息队列；客户端则可以订阅这些队列中的数据变更事件，处理并存储到数据仓库中。下面我们来看如何快速搭建起一个 Canal 服务。</p>
        
          <p class="article-more-link">
            <a href="/cnblogs/2017/08/13/extract-data-from-mysql-with-binlog-and-canal/#more">阅读全文</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://shzhangji.com/cnblogs/2017/08/13/extract-data-from-mysql-with-binlog-and-canal/" data-id="cjzqij3qz0037xkr4fh1ti407" class="article-share-link">分享</a>
      
        <a href="http://shzhangji.com/cnblogs/2017/08/13/extract-data-from-mysql-with-binlog-and-canal/#disqus_thread" class="article-comment-link">留言</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/canal/">canal</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/etl/">etl</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/java/">java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/mysql/">mysql</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-how-to-extract-event-time-in-apache-flume" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/cnblogs/2017/08/06/how-to-extract-event-time-in-apache-flume/" class="article-date">
  <time datetime="2017-08-06T01:09:06.000Z" itemprop="datePublished">2017-08-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/cnblogs/categories/Big-Data/">Big Data</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/cnblogs/2017/08/06/how-to-extract-event-time-in-apache-flume/">Apache Flume 如何解析消息中的事件时间</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>数据开发工作中，从上游消息队列抽取数据是一项常规的 ETL 流程。在基于 Hadoop 构建的数据仓库体系中，我们通常会使用 Flume 将事件日志从 Kafka 抽取到 HDFS，然后针对其开发 MapReduce 脚本，或直接创建以时间分区的 Hive 外部表。这项流程中的关键一环是提取日志中的事件时间，因为实时数据通常会包含延迟，且在系统临时宕机的情况下，我们需要追回遗漏的数据，因而使用的时间戳必须是事件产生的时间。Flume 提供的诸多工具能帮助我们非常便捷地实现这一点。</p>
<p><img src="/cnblogs/images/flume.png" alt="Apache Flume"></p>
<h2 id="HDFS-Sink-和时间戳头信息"><a href="#HDFS-Sink-和时间戳头信息" class="headerlink" title="HDFS Sink 和时间戳头信息"></a>HDFS Sink 和时间戳头信息</h2><p>以下是一个基本的 HDFS Sink 配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a1.sinks = k1</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path = /user/flume/ds_alog/dt=%Y%m%d</span><br></pre></td></tr></table></figure>
<p><code>%Y%m%d</code> 是该 Sink 支持的时间占位符，它会使用头信息中 <code>timestamp</code> 的值来替换这些占位符。HDFS Sink 还提供了 <code>hdfs.useLocalTimeStamp</code> 选项，直接使用当前系统时间来替换时间占位符，但这并不是我们想要达到的目的。</p>
<p>我们还可以使用 Hive Sink 直接将事件日志导入成 Hive 表，它能直接和 Hive 元数据库通信，自动创建表分区，并支持分隔符分隔和 JSON 两种序列化形式。当然，它同样需要一个 <code>timestamp</code> 头信息。不过，我们没有选择 Hive Sink，主要出于以下原因：</p>
<ul>
<li>它不支持正则表达式，因此我们无法从类似访问日志这样的数据格式中提取字段列表；</li>
<li>它所提取的字段列表是根据 Hive 表信息产生的。假设上游数据源在 JSON 日志中加入了新的键值，直至我们主动更新 Hive 元信息，这些新增字段将被直接丢弃。对于数据仓库来说，完整保存原始数据是很有必要的。</li>
</ul>
        
          <p class="article-more-link">
            <a href="/cnblogs/2017/08/06/how-to-extract-event-time-in-apache-flume/#more">阅读全文</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://shzhangji.com/cnblogs/2017/08/06/how-to-extract-event-time-in-apache-flume/" data-id="cjzqij3r1003bxkr4beto4xrz" class="article-share-link">分享</a>
      
        <a href="http://shzhangji.com/cnblogs/2017/08/06/how-to-extract-event-time-in-apache-flume/#disqus_thread" class="article-comment-link">留言</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/etl/">etl</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/flume/">flume</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/java/">java</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-how-to-achieve-exactly-once-semantics-in-spark-streaming" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/cnblogs/2017/08/01/how-to-achieve-exactly-once-semantics-in-spark-streaming/" class="article-date">
  <time datetime="2017-08-01T04:54:47.000Z" itemprop="datePublished">2017-08-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/cnblogs/categories/Big-Data/">Big Data</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/cnblogs/2017/08/01/how-to-achieve-exactly-once-semantics-in-spark-streaming/">Spark Streaming 中如何实现 Exactly-Once 语义</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Exactly-once 语义是实时计算的难点之一。要做到每一条记录只会被处理一次，即使服务器或网络发生故障时也能保证没有遗漏，这不仅需要实时计算框架本身的支持，还对上游的消息系统、下游的数据存储有所要求。此外，我们在编写计算流程时也需要遵循一定规范，才能真正实现 Exactly-once。本文将讲述如何结合 Spark Streaming 框架、Kafka 消息系统、以及 MySQL 数据库来实现 Exactly-once 的实时计算流程。</p>
<p><img src="http://spark.apache.org/docs/latest/img/streaming-arch.png" alt="Spark Streaming"></p>
<h2 id="引例"><a href="#引例" class="headerlink" title="引例"></a>引例</h2><p>首先让我们实现一个简单而完整的实时计算流程。我们从 Kafka 接收用户访问日志，解析并提取其中的时间和日志级别，并统计每分钟错误日志的数量，结果保存到 MySQL 中。</p>
<p>示例日志:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2017-07-30 14:09:08 ERROR some message</span><br><span class="line">2017-07-30 14:09:20 INFO  some message</span><br><span class="line">2017-07-30 14:10:50 ERROR some message</span><br></pre></td></tr></table></figure>
<p>结果表结构，其中 <code>log_time</code> 字段会截取到分钟级别：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> error_log (</span><br><span class="line">  log_time datetime primary <span class="keyword">key</span>,</span><br><span class="line">  log_count <span class="built_in">int</span> <span class="keyword">not</span> <span class="literal">null</span> <span class="keyword">default</span> <span class="number">0</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>
        
          <p class="article-more-link">
            <a href="/cnblogs/2017/08/01/how-to-achieve-exactly-once-semantics-in-spark-streaming/#more">阅读全文</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://shzhangji.com/cnblogs/2017/08/01/how-to-achieve-exactly-once-semantics-in-spark-streaming/" data-id="cjzqij3qx0034xkr4zvlrb87h" class="article-share-link">分享</a>
      
        <a href="http://shzhangji.com/cnblogs/2017/08/01/how-to-achieve-exactly-once-semantics-in-spark-streaming/#disqus_thread" class="article-comment-link">留言</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/kafka/">kafka</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/scala/">scala</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/spark/">spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/spark-streaming/">spark streaming</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/cnblogs/tags/stream-processing/">stream processing</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/cnblogs/">&laquo; 上一页</a><a class="page-number" href="/cnblogs/">1</a><span class="page-number current">2</span><a class="page-number" href="/cnblogs/page/3/">3</a><a class="page-number" href="/cnblogs/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/cnblogs/page/6/">6</a><a class="extend next" rel="next" href="/cnblogs/page/3/">下一页 &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Python数据平台</h3>
    <div class="widget">
      <img src="/cnblogs/images/pydp-qrcode.jpg" style="width: 100%;">
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/cnblogs/tags/algorithm/" style="font-size: 10px;">algorithm</a> <a href="/cnblogs/tags/analytics/" style="font-size: 15px;">analytics</a> <a href="/cnblogs/tags/angular/" style="font-size: 10px;">angular</a> <a href="/cnblogs/tags/aop/" style="font-size: 10px;">aop</a> <a href="/cnblogs/tags/aosa/" style="font-size: 11.25px;">aosa</a> <a href="/cnblogs/tags/apache-beam/" style="font-size: 10px;">apache beam</a> <a href="/cnblogs/tags/bootstrap/" style="font-size: 10px;">bootstrap</a> <a href="/cnblogs/tags/c/" style="font-size: 10px;">c</a> <a href="/cnblogs/tags/canal/" style="font-size: 10px;">canal</a> <a href="/cnblogs/tags/cdh/" style="font-size: 10px;">cdh</a> <a href="/cnblogs/tags/clojure/" style="font-size: 17.5px;">clojure</a> <a href="/cnblogs/tags/crossfilter/" style="font-size: 10px;">crossfilter</a> <a href="/cnblogs/tags/data-science/" style="font-size: 10px;">data science</a> <a href="/cnblogs/tags/dc-js/" style="font-size: 10px;">dc.js</a> <a href="/cnblogs/tags/docker/" style="font-size: 10px;">docker</a> <a href="/cnblogs/tags/druid/" style="font-size: 10px;">druid</a> <a href="/cnblogs/tags/eclipse/" style="font-size: 10px;">eclipse</a> <a href="/cnblogs/tags/es6/" style="font-size: 10px;">es6</a> <a href="/cnblogs/tags/eslint/" style="font-size: 10px;">eslint</a> <a href="/cnblogs/tags/etl/" style="font-size: 13.75px;">etl</a> <a href="/cnblogs/tags/flink/" style="font-size: 11.25px;">flink</a> <a href="/cnblogs/tags/flume/" style="font-size: 12.5px;">flume</a> <a href="/cnblogs/tags/frontend/" style="font-size: 12.5px;">frontend</a> <a href="/cnblogs/tags/functional-programming/" style="font-size: 10px;">functional programming</a> <a href="/cnblogs/tags/git/" style="font-size: 11.25px;">git</a> <a href="/cnblogs/tags/hadoop/" style="font-size: 13.75px;">hadoop</a> <a href="/cnblogs/tags/hbase/" style="font-size: 10px;">hbase</a> <a href="/cnblogs/tags/hdfs/" style="font-size: 11.25px;">hdfs</a> <a href="/cnblogs/tags/hive/" style="font-size: 15px;">hive</a> <a href="/cnblogs/tags/java/" style="font-size: 18.75px;">java</a> <a href="/cnblogs/tags/javascript/" style="font-size: 15px;">javascript</a> <a href="/cnblogs/tags/jvm/" style="font-size: 10px;">jvm</a> <a href="/cnblogs/tags/kafka/" style="font-size: 11.25px;">kafka</a> <a href="/cnblogs/tags/kubernetes/" style="font-size: 10px;">kubernetes</a> <a href="/cnblogs/tags/lodash/" style="font-size: 10px;">lodash</a> <a href="/cnblogs/tags/machine-learning/" style="font-size: 11.25px;">machine learning</a> <a href="/cnblogs/tags/mapreduce/" style="font-size: 11.25px;">mapreduce</a> <a href="/cnblogs/tags/mysql/" style="font-size: 11.25px;">mysql</a> <a href="/cnblogs/tags/nginx/" style="font-size: 10px;">nginx</a> <a href="/cnblogs/tags/noir/" style="font-size: 12.5px;">noir</a> <a href="/cnblogs/tags/opensource/" style="font-size: 10px;">opensource</a> <a href="/cnblogs/tags/ops/" style="font-size: 11.25px;">ops</a> <a href="/cnblogs/tags/pandas/" style="font-size: 11.25px;">pandas</a> <a href="/cnblogs/tags/perl/" style="font-size: 11.25px;">perl</a> <a href="/cnblogs/tags/python/" style="font-size: 18.75px;">python</a> <a href="/cnblogs/tags/react/" style="font-size: 10px;">react</a> <a href="/cnblogs/tags/restful/" style="font-size: 10px;">restful</a> <a href="/cnblogs/tags/scala/" style="font-size: 12.5px;">scala</a> <a href="/cnblogs/tags/source-code/" style="font-size: 10px;">source code</a> <a href="/cnblogs/tags/spark/" style="font-size: 16.25px;">spark</a> <a href="/cnblogs/tags/spark-streaming/" style="font-size: 10px;">spark streaming</a> <a href="/cnblogs/tags/spring/" style="font-size: 12.5px;">spring</a> <a href="/cnblogs/tags/sql/" style="font-size: 11.25px;">sql</a> <a href="/cnblogs/tags/storm/" style="font-size: 10px;">storm</a> <a href="/cnblogs/tags/stream-processing/" style="font-size: 13.75px;">stream processing</a> <a href="/cnblogs/tags/tensorflow/" style="font-size: 10px;">tensorflow</a> <a href="/cnblogs/tags/thrift/" style="font-size: 10px;">thrift</a> <a href="/cnblogs/tags/translation/" style="font-size: 20px;">translation</a> <a href="/cnblogs/tags/tutorial/" style="font-size: 17.5px;">tutorial</a> <a href="/cnblogs/tags/unix/" style="font-size: 10px;">unix</a> <a href="/cnblogs/tags/vue/" style="font-size: 10px;">vue</a> <a href="/cnblogs/tags/vuex/" style="font-size: 10px;">vuex</a> <a href="/cnblogs/tags/websocket/" style="font-size: 10px;">websocket</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2019/08/">八月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2019/06/">六月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2018/12/">十二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2018/10/">十月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2018/09/">九月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2018/05/">五月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2018/04/">四月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2017/10/">十月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2017/09/">九月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2017/08/">八月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2017/07/">七月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2017/06/">六月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2016/03/">三月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2015/09/">九月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2015/06/">六月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2015/03/">三月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2015/01/">一月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2014/12/">十二月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2014/11/">十一月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2014/10/">十月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2014/07/">七月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2014/04/">四月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2014/01/">一月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/12/">十二月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/09/">九月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/06/">六月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/05/">五月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/04/">四月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/03/">三月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/02/">二月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2013/01/">一月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2012/12/">十二月 2012</a></li><li class="archive-list-item"><a class="archive-list-link" href="/cnblogs/archives/2012/11/">十一月 2012</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/cnblogs/2019/08/25/deploy-flink-job-cluster-on-kubernetes/">使用 Kubernetes 部署 Flink 应用</a>
          </li>
        
          <li>
            <a href="/cnblogs/2019/06/11/understanding-hive-acid-transactional-table/">深入理解 Hive ACID 事务表</a>
          </li>
        
          <li>
            <a href="/cnblogs/2018/12/30/real-time-exactly-once-etl-with-apache-flink/">使用 Apache Flink 开发实时 ETL</a>
          </li>
        
          <li>
            <a href="/cnblogs/2018/12/09/spark-datasource-api-v2/">Spark DataSource API V2</a>
          </li>
        
          <li>
            <a href="/cnblogs/2018/10/04/flume-source-code-hdfs-sink/">Flume 源码解析：HDFS Sink</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh"><img alt="知识共享许可协议" style="border-width:0" src="https://mirrors.creativecommons.org/presskit/buttons/80x15/svg/by-nc-sa.svg"></a>
      <br>
      &copy; 2019 张吉<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/cnblogs/" class="mobile-nav-link">首页</a>
  
    <a href="/cnblogs/categories/Big-Data" class="mobile-nav-link">大数据</a>
  
    <a href="/cnblogs/categories/Programming" class="mobile-nav-link">编程</a>
  
    <a href="/cnblogs/categories/Digest" class="mobile-nav-link">摘译</a>
  
    <a href="/cnblogs/archives" class="mobile-nav-link">全部文章</a>
  
    <a href="http://shzhangji.com/" class="mobile-nav-link">English</a>
  
</nav>
    
<script>
  var disqus_shortname = 'jizhang';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/cnblogs/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/cnblogs/fancybox/jquery.fancybox.css">
  <script src="/cnblogs/fancybox/jquery.fancybox.pack.js"></script>


<script src="/cnblogs/js/script.js"></script>

  </div>
</body>
</html>