<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>张吉的博客</title>
  
  <subtitle>If I rest, I rust.</subtitle>
  <link href="/cnblogs/atom.xml" rel="self"/>
  
  <link href="http://shzhangji.com/cnblogs/"/>
  <updated>2018-10-25T06:45:19.000Z</updated>
  <id>http://shzhangji.com/cnblogs/</id>
  
  <author>
    <name>张吉</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Flume 源码解析：HDFS Sink</title>
    <link href="http://shzhangji.com/cnblogs/2018/10/04/flume-source-code-hdfs-sink/"/>
    <id>http://shzhangji.com/cnblogs/2018/10/04/flume-source-code-hdfs-sink/</id>
    <published>2018-10-04T05:49:03.000Z</published>
    <updated>2018-10-25T06:45:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Flume 数据流程的最后一部分是 Sink，它会将上游抽取并转换好的数据输送到外部存储中去，如本地文件、HDFS、ElasticSearch 等。本文将通过分析源码来展现 HDFS Sink 的工作流程。</p><h2 id="Sink-组件的生命周期"><a href="#Sink-组件的生命周期" class="headerlink" title="Sink 组件的生命周期"></a>Sink 组件的生命周期</h2><p><a href="http://shzhangji.com/cnblogs/2017/10/24/flume-source-code-component-lifecycle/">在上一篇文章中</a>, 我们了解到 Flume 组件都会实现 <code>LifecycleAware</code> 接口，并由 <code>LifecycleSupervisor</code> 实例管理和监控。不过，Sink 组件并不直接由它管理，而且被包装在了 <code>SinkRunner</code> 和 <code>SinkProcessor</code> 这两个类中。Flume 支持三种 <a href="https://flume.apache.org/FlumeUserGuide.html#flume-sink-processors" target="_blank" rel="noopener">Sink 处理器</a>，该处理器会将 Channel 和 Sink 以不同的方式连接起来。这里我们只讨论 <code>DefaultSinkProcessor</code> 的情况，即一个 Channel 只会连接一个 Sink。同时，我们也将略过对 Sink 分组的讨论。</p><p><img src="/cnblogs/images/flume/sink-component-lifecycle.png" alt="Sink Component LifeCycle"></p><a id="more"></a><h2 id="HDFS-Sink-模块中的类"><a href="#HDFS-Sink-模块中的类" class="headerlink" title="HDFS Sink 模块中的类"></a>HDFS Sink 模块中的类</h2><p>HDFS Sink 模块的源码在 <code>flume-hdfs-sink</code> 子目录中，主要由以下几个类组成：</p><p><img src="/cnblogs/images/flume/hdfs-sink-classes.png" alt="HDFS Sink Classes"></p><p><code>HDFSEventSink</code> 类实现了生命周期的各个方法，包括 <code>configure</code>、<code>start</code>、<code>process</code>、<code>stop</code> 等。它启动后会维护一组 <code>BucketWriter</code> 实例，每个实例对应一个 HDFS 输出文件路径，上游的消息会传递给它，并写入 HDFS。通过不同的 <code>HDFSWriter</code> 实现，它可以将数据写入文本文件、压缩文件、或是 <code>SequenceFile</code>。</p><h2 id="配置与启动"><a href="#配置与启动" class="headerlink" title="配置与启动"></a>配置与启动</h2><p>Flume 配置文件加载时，会实例化各个组件，并调用它们的 <code>configure</code> 方法，其中就包括 Sink 组件。在 <code>HDFSEventSink#configure</code> 方法中，程序会读取配置文件中以 <code>hdfs.</code> 为开头的项目，为其提供默认值，并做基本的参数校验。如，<code>batchSize</code> 必须大于零，<code>fileType</code> 指定为 <code>CompressedStream</code> 时 <code>codeC</code> 参数也必须指定等等。同时，程序还会初始化一个 <code>SinkCounter</code>，用于统计运行过程中的各项指标。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">  filePath = Preconditions.checkNotNull(</span><br><span class="line">      context.getString(<span class="string">"hdfs.path"</span>), <span class="string">"hdfs.path is required"</span>);</span><br><span class="line">  rollInterval = context.getLong(<span class="string">"hdfs.rollInterval"</span>, defaultRollInterval);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (sinkCounter == <span class="keyword">null</span>) &#123;</span><br><span class="line">    sinkCounter = <span class="keyword">new</span> SinkCounter(getName());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>HDFSEventSink#start</code> 方法中会创建两个线程池：<code>callTimeoutPool</code> 线程池会在 <code>BucketWriter#callWithTimeout</code> 方法中使用，用来限定 HDFS 远程调用的请求时间，如 <a href="http://hadoop.apache.org/docs/r2.4.1/api/org/apache/hadoop/fs/FileSystem.html" target="_blank" rel="noopener"><code>FileSystem#create</code></a> 或 <a href="https://hadoop.apache.org/docs/r2.4.1/api/org/apache/hadoop/fs/FSDataOutputStream.html" target="_blank" rel="noopener"><code>FSDataOutputStream#hflush</code></a> 都有可能超时；<code>timedRollerPool</code> 则用于对文件进行滚动，前提是用户配置了 <code>rollInterval</code> 选项，我们将在下一节详细说明。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  callTimeoutPool = Executors.newFixedThreadPool(threadsPoolSize,</span><br><span class="line">      <span class="keyword">new</span> ThreadFactoryBuilder().setNameFormat(timeoutName).build());</span><br><span class="line">  timedRollerPool = Executors.newScheduledThreadPool(rollTimerPoolSize,</span><br><span class="line">      <span class="keyword">new</span> ThreadFactoryBuilder().setNameFormat(rollerName).build());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="处理数据"><a href="#处理数据" class="headerlink" title="处理数据"></a>处理数据</h2><p><code>process</code> 方法包含了 HDFS Sink 的主要逻辑，也就是从上游的 Channel 中获取数据，并写入指定的 HDFS 文件，流程图如下：</p><p><img src="/cnblogs/images/flume/process-method-flow-chart.png" alt="Process Method Flow Chart"></p><h3 id="Channel-事务"><a href="#Channel-事务" class="headerlink" title="Channel 事务"></a>Channel 事务</h3><p>处理逻辑的外层是一个 Channel 事务，并提供了异常处理。以 Kafka Channel 为例：事务开始时，程序会从 Kafka 中读取数据，但不会立刻提交变动后的偏移量。只有当这些消息被成功写入 HDFS 文件之后，偏移量才会提交给 Kafka，下次循环将从新的偏移量开始消费。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Channel channel = getChannel();</span><br><span class="line">Transaction transaction = channel.getTransaction();</span><br><span class="line">transaction.begin()</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  event = channel.take();</span><br><span class="line">  bucketWriter.append(event);</span><br><span class="line">  transaction.commit()</span><br><span class="line">&#125; <span class="keyword">catch</span> (Throwable th) &#123;</span><br><span class="line">  transaction.rollback();</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> EventDeliveryException(th);</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">  transaction.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="查找或创建-BucketWriter"><a href="#查找或创建-BucketWriter" class="headerlink" title="查找或创建 BucketWriter"></a>查找或创建 <code>BucketWriter</code></h3><p><code>BucketWriter</code> 实例和 HDFS 文件一一对应，文件路径是通过配置生成的，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a1.sinks.access_log.hdfs.path = /user/flume/access_log/dt=%Y%m%d</span><br><span class="line">a1.sinks.access_log.hdfs.filePrefix = events.%[localhost]</span><br><span class="line">a1.sinks.access_log.hdfs.inUsePrefix = .</span><br><span class="line">a1.sinks.access_log.hdfs.inUseSuffix = .tmp</span><br><span class="line">a1.sinks.access_log.hdfs.rollInterval = 300</span><br><span class="line">a1.sinks.access_log.hdfs.fileType = CompressedStream</span><br><span class="line">a1.sinks.access_log.hdfs.codeC = lzop</span><br></pre></td></tr></table></figure><p>以上配置生成的临时文件和目标文件路径为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/user/flume/access_log/dt=20180925/.events.hostname1.1537848761307.lzo.tmp</span><br><span class="line">/user/flume/access_log/dt=20180925/events.hostname1.1537848761307.lzo</span><br></pre></td></tr></table></figure><p>配置中的占位符会由 <a href="https://flume.apache.org/releases/content/1.4.0/apidocs/org/apache/flume/formatter/output/BucketPath.html" target="_blank" rel="noopener"><code>BucketPath#escapeString</code></a> 方法替换，Flume 支持三类占位符：</p><ul><li><code>%{...}</code>：使用消息中的头信息进行替换；</li><li><code>%[...]</code>：目前仅支持 <code>%[localhost]</code>、<code>%[ip]</code>、以及 <code>%[fqdn]</code>；</li><li><code>%x</code>：日期占位符，通过头信息中的 <code>timestamp</code> 来生成，或者使用 <code>useLocalTimeStamp</code> 配置项。</li></ul><p>文件的前后缀则是在 <code>BucketWriter#open</code> 方法中追加的。代码中的 <code>counter</code> 是当前文件的创建时间戳，<code>lzo</code> 则是当前压缩格式的默认文件后缀。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String fullFileName = fileName + <span class="string">"."</span> + counter;</span><br><span class="line">fullFileName += fileSuffix;</span><br><span class="line">fullFileName += codeC.getDefaultExtension();</span><br><span class="line">bucketPath = filePath + <span class="string">"/"</span> + inUsePrefix + fullFileName + inUseSuffix;</span><br><span class="line">targetPath = filePath + <span class="string">"/"</span> + fullFileName;</span><br></pre></td></tr></table></figure><p>如果指定路径没有对应的 <code>BucketWriter</code> 实例，程序会创建一个，并根据 <code>fileType</code> 配置项来生成对应的 <code>HDFSWriter</code> 实例。Flume 支持的三种类型是：<code>HDFSSequenceFile</code>、<code>HDFSDataStream</code>、以及 <code>HDFSCompressedDataStream</code>，写入 HDFS 的动作是由这些类中的代码完成的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bucketWriter = sfWriters.get(lookupPath);</span><br><span class="line"><span class="keyword">if</span> (bucketWriter == <span class="keyword">null</span>) &#123;</span><br><span class="line">  hdfsWriter = writerFactory.getWriter(fileType);</span><br><span class="line">  bucketWriter = <span class="keyword">new</span> BucketWriter(hdfsWriter);</span><br><span class="line">  sfWriters.put(lookupPath, bucketWriter);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="写入数据并刷新"><a href="#写入数据并刷新" class="headerlink" title="写入数据并刷新"></a>写入数据并刷新</h3><p>在写入数据之前，<code>BucketWriter</code> 首先会检查文件是否已经打开，如未打开则会命关联的 <code>HDFSWriter</code> 类开启新的文件，以 <code>HDFSCompressedDataStream</code> 为例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(String filePath, CompressionCodec codec)</span> </span>&#123;</span><br><span class="line">  FileSystem hdfs = dstPath.getFileSystem(conf);</span><br><span class="line">  fsOut = hdfs.append(dstPath)</span><br><span class="line">  compressor = CodedPool.getCompressor(codec, conf);</span><br><span class="line">  cmpOut = codec.createOutputStream(fsOut, compressor);</span><br><span class="line">  serializer = EventSerializerFactory.getInstance(serializerType, cmpOut);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">append</span><span class="params">(Event e)</span> <span class="keyword">throws</span> IO Exception </span>&#123;</span><br><span class="line">  serializer.write(event);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Flume 默认的 <code>serializerType</code> 配置是 <code>TEXT</code>，即使用 <a href="https://flume.apache.org/releases/content/1.4.0/apidocs/org/apache/flume/serialization/BodyTextEventSerializer.html" target="_blank" rel="noopener">BodyTextEventSerializer</a> 来序列化数据，不做加工，直接写进输出流：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(Event e)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  out.write(e.getBody());</span><br><span class="line">  <span class="keyword">if</span> (appendNewline) &#123;</span><br><span class="line">    out.write(<span class="string">'\n'</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当 <code>BucketWriter</code> 需要关闭或重开时会调用 <code>HDFSWriter#sync</code> 方法，进而执行序列化实例和输出流实例上的 <code>flush</code> 方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sync</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  serializer.flush();</span><br><span class="line">  compOut.finish();</span><br><span class="line">  fsOut.flush();</span><br><span class="line">  hflushOrSync(fsOut);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从 Hadoop 0.21.0 开始，<a href="https://hadoop.apache.org/docs/r2.4.1/api/org/apache/hadoop/fs/Syncable.html" target="_blank" rel="noopener"><code>Syncable#sync</code></a> 拆分成了 <code>hflush</code> 和 <code>hsync</code> 两个方法，前者只是将数据从客户端的缓存中刷新出去，后者则会保证数据已被写入 HDFS 本地磁盘。为了兼容新老 API，Flume 会通过 Java 反射机制来确定 <code>hflush</code> 是否存在，不存在则调用 <code>sync</code> 方法。上述代码中的 <code>flushOrSync</code> 正是做了这样的判断。</p><h3 id="文件滚动"><a href="#文件滚动" class="headerlink" title="文件滚动"></a>文件滚动</h3><p>HDFS Sink 支持三种滚动方式：按文件大小、按消息数量、以及按时间间隔。按大小和按数量的滚动是在 <code>BucketWriter#shouldRotate</code> 方法中判断的，每次 <code>append</code> 时都会调用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">shouldRotate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">boolean</span> doRotate = <span class="keyword">false</span>;</span><br><span class="line">  <span class="keyword">if</span> ((rollCount &gt; <span class="number">0</span>) &amp;&amp; (rollCount &lt;= eventCounter)) &#123;</span><br><span class="line">    doRotate = <span class="keyword">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> ((rollSize &gt; <span class="number">0</span>) &amp;&amp; (rollSize &lt;= processSize)) &#123;</span><br><span class="line">    doRotate = <span class="keyword">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> doRotate;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>按时间滚动则是使用了上文提到的 <code>timedRollerPool</code> 线程池，通过启动一个定时线程来实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (rollInterval &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    Callable&lt;Void&gt; action = <span class="keyword">new</span> Callable&lt;Void&gt;() &#123;</span><br><span class="line">      <span class="function"><span class="keyword">public</span> Void <span class="title">call</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        close(<span class="keyword">true</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    timedRollFuture = timedRollerPool.schedule(action, rollInterval);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="关闭与停止"><a href="#关闭与停止" class="headerlink" title="关闭与停止"></a>关闭与停止</h2><p>当 <code>HDFSEventSink#close</code> 被触发时，它会遍历所有的 <code>BucketWriter</code> 实例，调用它们的 <code>close</code> 方法，进而关闭下属的 <code>HDFSWriter</code>。这个过程和 <code>flush</code> 类似，只是还会做一些额外操作，如关闭后的 <code>BucketWriter</code> 会将自身从 <code>sfWriters</code> 哈希表中移除：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">(<span class="keyword">boolean</span> callCloseCallback)</span> </span>&#123;</span><br><span class="line">  writer.close();</span><br><span class="line">  timedRollFuture.cancel(<span class="keyword">false</span>);</span><br><span class="line">  onCloseCallback.run(onCloseCallbackPath);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>onCloseCallback</code> 回调函数是在 <code>HDFSEventSink</code> 初始化 <code>BucketWriter</code> 时传入的：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">WriterCallback closeCallback = <span class="keyword">new</span> WriterCallback() &#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(String bucketPath)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">synchronized</span> (sfWritersLock) &#123;</span><br><span class="line">        sfWriters.remove(bucketPath);</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">bucketWriter = <span class="keyword">new</span> BucketWriter(lookPath, closeCallback);</span><br></pre></td></tr></table></figure><p>最后，<code>HDFSEventSink</code> 会关闭 <code>callTimeoutPool</code> 和 <code>timedRollerPool</code> 线程池，整个组件随即停止。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ExecutorService[] toShutdown = &#123; callTimeoutPool, timedRollerPool &#125;;</span><br><span class="line"><span class="keyword">for</span> (ExecutorService execService : toShutdown) &#123;</span><br><span class="line">  execService.shutdown();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://flume.apache.org/FlumeUserGuide.html#hdfs-sink" target="_blank" rel="noopener">https://flume.apache.org/FlumeUserGuide.html#hdfs-sink</a></li><li><a href="https://github.com/apache/flume" target="_blank" rel="noopener">https://github.com/apache/flume</a></li><li><a href="https://data-flair.training/blogs/flume-sink-processors/" target="_blank" rel="noopener">https://data-flair.training/blogs/flume-sink-processors/</a></li><li><a href="http://hadoop-hbase.blogspot.com/2012/05/hbase-hdfs-and-durable-sync.html" target="_blank" rel="noopener">http://hadoop-hbase.blogspot.com/2012/05/hbase-hdfs-and-durable-sync.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Apache Flume 数据流程的最后一部分是 Sink，它会将上游抽取并转换好的数据输送到外部存储中去，如本地文件、HDFS、ElasticSearch 等。本文将通过分析源码来展现 HDFS Sink 的工作流程。&lt;/p&gt;
&lt;h2 id=&quot;Sink-组件的生命周期&quot;&gt;&lt;a href=&quot;#Sink-组件的生命周期&quot; class=&quot;headerlink&quot; title=&quot;Sink 组件的生命周期&quot;&gt;&lt;/a&gt;Sink 组件的生命周期&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;http://shzhangji.com/cnblogs/2017/10/24/flume-source-code-component-lifecycle/&quot;&gt;在上一篇文章中&lt;/a&gt;, 我们了解到 Flume 组件都会实现 &lt;code&gt;LifecycleAware&lt;/code&gt; 接口，并由 &lt;code&gt;LifecycleSupervisor&lt;/code&gt; 实例管理和监控。不过，Sink 组件并不直接由它管理，而且被包装在了 &lt;code&gt;SinkRunner&lt;/code&gt; 和 &lt;code&gt;SinkProcessor&lt;/code&gt; 这两个类中。Flume 支持三种 &lt;a href=&quot;https://flume.apache.org/FlumeUserGuide.html#flume-sink-processors&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Sink 处理器&lt;/a&gt;，该处理器会将 Channel 和 Sink 以不同的方式连接起来。这里我们只讨论 &lt;code&gt;DefaultSinkProcessor&lt;/code&gt; 的情况，即一个 Channel 只会连接一个 Sink。同时，我们也将略过对 Sink 分组的讨论。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/cnblogs/images/flume/sink-component-lifecycle.png&quot; alt=&quot;Sink Component LifeCycle&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/cnblogs/categories/Big-Data/"/>
    
    
      <category term="java" scheme="http://shzhangji.com/cnblogs/tags/java/"/>
    
      <category term="flume" scheme="http://shzhangji.com/cnblogs/tags/flume/"/>
    
      <category term="hdfs" scheme="http://shzhangji.com/cnblogs/tags/hdfs/"/>
    
  </entry>
  
  <entry>
    <title>Java 空指针异常的若干解决方案</title>
    <link href="http://shzhangji.com/cnblogs/2018/09/22/how-to-avoid-null-pointer-exception/"/>
    <id>http://shzhangji.com/cnblogs/2018/09/22/how-to-avoid-null-pointer-exception/</id>
    <published>2018-09-22T12:27:36.000Z</published>
    <updated>2018-10-25T06:45:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>Java 中任何对象都有可能为空，当我们调用空对象的方法时就会抛出 <code>NullPointerException</code> 空指针异常，这是一种非常常见的错误类型。我们可以使用若干种方法来避免产生这类异常，使得我们的代码更为健壮。本文将列举这些解决方案，包括传统的空值检测、编程规范、以及使用现代 Java 语言引入的各类工具来作为辅助。</p><h2 id="运行时检测"><a href="#运行时检测" class="headerlink" title="运行时检测"></a>运行时检测</h2><p>最显而易见的方法就是使用 <code>if (obj == null)</code> 来对所有需要用到的对象来进行检测，包括函数参数、返回值、以及类实例的成员变量。当你检测到 <code>null</code> 值时，可以选择抛出更具针对性的异常类型，如 <code>IllegalArgumentException</code>，并添加消息内容。我们可以使用一些库函数来简化代码，如 Java 7 开始提供的 <a href="https://docs.oracle.com/javase/7/docs/api/java/util/Objects.html" target="_blank" rel="noopener"><code>Objects#requireNonNull</code></a> 方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testObjects</span><span class="params">(Object arg)</span> </span>&#123;</span><br><span class="line">  Object checked = Objects.requireNonNull(arg, <span class="string">"arg must not be null"</span>);</span><br><span class="line">  checked.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Guava 的 <a href="https://github.com/google/guava/wiki/PreconditionsExplained" target="_blank" rel="noopener"><code>Preconditions</code></a> 类中也提供了一系列用于检测参数合法性的工具函数，其中就包含空值检测：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testGuava</span><span class="params">(Object arg)</span> </span>&#123;</span><br><span class="line">  Object checked = Preconditions.checkNotNull(arg, <span class="string">"%s must not be null"</span>, <span class="string">"arg"</span>);</span><br><span class="line">  checked.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们还可以使用 <a href="https://projectlombok.org/features/NonNull" target="_blank" rel="noopener">Lombok</a> 来生成空值检测代码，并抛出带有提示信息的空指针异常：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testLombok</span><span class="params">(@NonNull Object arg)</span> </span>&#123;</span><br><span class="line">  arg.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成的代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testLombokGenerated</span><span class="params">(Object arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (arg == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException(<span class="string">"arg is marked @NonNull but is null"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  arg.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个注解还可以用在类实例的成员变量上，所有的赋值操作会自动进行空值检测。</p><a id="more"></a><h2 id="编程规范"><a href="#编程规范" class="headerlink" title="编程规范"></a>编程规范</h2><p>通过遵守某些编程规范，也可以从一定程度上减少空指针异常的发生。</p><ul><li>使用那些已经对 <code>null</code> 值做过判断的方法，如 <code>String#equals</code>、<code>String#valueOf</code>、以及三方库中用来判断字符串和集合是否为空的函数：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (str != <span class="keyword">null</span> &amp;&amp; str.equals(<span class="string">"text"</span>)) &#123;&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="string">"text"</span>.equals(str)) &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (obj != <span class="keyword">null</span>) &#123; obj.toString(); &#125;</span><br><span class="line">String.valueOf(obj); <span class="comment">// "null"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// from spring-core</span></span><br><span class="line">StringUtils.isEmpty(str);</span><br><span class="line">CollectionUtils.isEmpty(col);</span><br><span class="line"><span class="comment">// from guava</span></span><br><span class="line">Strings.isNullOrEmpty(str);</span><br><span class="line"><span class="comment">// from commons-collections4</span></span><br><span class="line">CollectionUtils.isEmpty(col);</span><br></pre></td></tr></table></figure><ul><li>如果函数的某个参数可以接收 <code>null</code> 值，考虑改写成两个函数，使用不同的函数签名，这样就可以强制要求每个参数都不为空了：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">methodA</span><span class="params">(Object arg1)</span> </span>&#123;</span><br><span class="line">  methodB(arg1, <span class="keyword">new</span> Object[<span class="number">0</span>]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">methodB</span><span class="params">(Object arg1, Object[] arg2)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (Object obj : arg2) &#123;&#125; <span class="comment">// no null check</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>如果函数的返回值是集合类型，当结果为空时，不要返回 <code>null</code> 值，而是返回一个空的集合；如果返回值类型是对象，则可以选择抛出异常。Spring JdbcTemplate 正是使用了这种处理方式：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 当查询结果为空时，返回 new ArrayList&lt;&gt;()</span></span><br><span class="line">jdbcTemplate.queryForList(<span class="string">"SELECT * FROM person"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 若找不到该条记录，则抛出 EmptyResultDataAccessException</span></span><br><span class="line">jdbcTemplate.queryForObject(<span class="string">"SELECT age FROM person WHERE id = 1"</span>, Integer.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 支持泛型集合</span></span><br><span class="line"><span class="keyword">public</span> &lt;T&gt; <span class="function">List&lt;T&gt; <span class="title">testReturnCollection</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> Collections.emptyList();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="静态代码分析"><a href="#静态代码分析" class="headerlink" title="静态代码分析"></a>静态代码分析</h2><p>Java 语言有许多静态代码分析工具，如 Eclipse IDE、SpotBugs、Checker Framework 等，它们可以帮助程序员检测出编译期的错误。结合 <code>@Nullable</code> 和 <code>@Nonnull</code> 等注解，我们就可以在程序运行之前发现可能抛出空指针异常的代码。</p><p>但是，空值检测注解还没有得到标准化。虽然 2006 年 9 月社区提出了 <a href="https://jcp.org/en/jsr/detail?id=305" target="_blank" rel="noopener">JSR 305</a> 规范，但它长期处于搁置状态。很多第三方库提供了类似的注解，且得到了不同工具的支持，其中使用较多的有：</p><ul><li><code>javax.annotation.Nonnull</code>：由 JSR 305 提出，其参考实现为 <code>com.google.code.findbugs.jsr305</code>；</li><li><code>org.eclipse.jdt.annotation.NonNull</code>：Eclipse IDE 原生支持的空值检测注解；</li><li><code>edu.umd.cs.findbugs.annotations.NonNull</code>：SpotBugs 使用的注解，基于 <code>findbugs.jsr305</code>；</li><li><code>org.springframework.lang.NonNull</code>：Spring Framework 5.0 开始提供；</li><li><code>org.checkerframework.checker.nullness.qual.NonNull</code>：Checker Framework 使用；</li><li><code>android.support.annotation.NonNull</code>：集成在安卓开发工具中；</li></ul><p>我建议使用一种跨 IDE 的解决方案，如 SpotBugs 或 Checker Framework，它们都能和 Maven 结合得很好。</p><h3 id="SpotBugs-与-NonNull、-CheckForNull"><a href="#SpotBugs-与-NonNull、-CheckForNull" class="headerlink" title="SpotBugs 与 @NonNull、@CheckForNull"></a>SpotBugs 与 <code>@NonNull</code>、<code>@CheckForNull</code></h3><p>SpotBugs 是 FindBugs 的后继者。通过在方法的参数和返回值上添加 <code>@NonNull</code> 和 <code>@CheckForNull</code> 注解，SpotBugs 可以帮助我们进行编译期的空值检测。需要注意的是，SpotBugs 不支持 <code>@Nullable</code> 注解，必须用 <code>@CheckForNull</code> 代替。如官方文档中所说，仅当需要覆盖 <code>@ParametersAreNonnullByDefault</code> 时才会用到 <code>@Nullable</code>。</p><p><a href="https://spotbugs.readthedocs.io/en/latest/maven.html" target="_blank" rel="noopener">官方文档</a> 中说明了如何将 SpotBugs 应用到 Maven 和 Eclipse 中去。我们还需要将 <code>spotbugs-annotations</code> 加入到项目依赖中，以便使用对应的注解。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.github.spotbugs<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spotbugs-annotations<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.7<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>以下是对不同使用场景的说明：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@NonNull</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> Object <span class="title">returnNonNull</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 错误：returnNonNull() 可能返回空值，但其已声明为 @Nonnull</span></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@CheckForNull</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> Object <span class="title">returnNullable</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testReturnNullable</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Object obj = returnNullable();</span><br><span class="line">  <span class="comment">// 错误：方法的返回值可能为空</span></span><br><span class="line">  System.out.println(obj.toString());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">argumentNonNull</span><span class="params">(@NonNull Object arg)</span> </span>&#123;</span><br><span class="line">  System.out.println(arg.toString());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testArgumentNonNull</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 错误：不能将 null 传递给非空参数</span></span><br><span class="line">  argumentNonNull(<span class="keyword">null</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testNullableArgument</span><span class="params">(@CheckForNull Object arg)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 错误：参数可能为空</span></span><br><span class="line">  System.out.println(arg.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于 Eclipse 用户，还可以使用 IDE 内置的空值检测工具，只需将默认的注解 <code>org.eclipse.jdt.annotation.Nullable</code> 替换为 SpotBugs 的注解即可：</p><p><img src="/cnblogs/images/java-npe/eclipse.png" alt="Eclipse null analysis"></p><h3 id="Checker-Framework-与-NonNull、-Nullable"><a href="#Checker-Framework-与-NonNull、-Nullable" class="headerlink" title="Checker Framework 与 @NonNull、@Nullable"></a>Checker Framework 与 <code>@NonNull</code>、<code>@Nullable</code></h3><p>Checker Framework 能够作为 <code>javac</code> 编译器的插件运行，对代码中的数据类型进行检测，预防各类问题。我们可以参照 <a href="https://checkerframework.org/manual/#maven" target="_blank" rel="noopener">官方文档</a>，将 Checker Framework 与 <code>maven-compiler-plugin</code> 结合，之后每次执行 <code>mvn compile</code> 时就会进行检查。Checker Framework 的空值检测程序支持几乎所有的注解，包括 JSR 305、Eclipse、甚至 <code>lombok.NonNull</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.checkerframework.checker.nullness.qual.Nullable;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Nullable</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> Object <span class="title">returnNullable</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testReturnNullable</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Object obj = returnNullable();</span><br><span class="line">  <span class="comment">// 错误：obj 可能为空</span></span><br><span class="line">  System.out.println(obj.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Checker Framework 默认会将 <code>@NonNull</code> 应用到所有的函数参数和返回值上，因此，即使不添加这个注解，以下程序也是无法编译通过的：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Object <span class="title">returnNonNull</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 错误：方法声明为 @NonNull，但返回的是 null。</span></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">argumentNonNull</span><span class="params">(Object arg)</span> </span>&#123;</span><br><span class="line">  System.out.println(arg.toString());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testArgumentNonNull</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 错误：参数声明为 @NonNull，但传入的是 null。</span></span><br><span class="line">  argumentNonNull(<span class="keyword">null</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Checker Framework 对使用 Spring Framework 5.0 以上的用户非常有用，因为 Spring 提供了内置的空值检测注解，且能够被 Checker Framework 支持。一方面我们无需再引入额外的 Jar 包，更重要的是 Spring Framework 代码本身就使用了这些注解，这样我们在调用它的 API 时就能有效地处理空值了。举例来说，<code>StringUtils</code> 类里可以传入空值的函数、以及会返回空值的函数都添加了 <code>@Nullable</code> 注解，而未添加的方法则继承了整个框架的 <code>@NonNull</code> 注解，因此，下列代码中的空指针异常就可以被 Checker Framework 检测到了：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这是 spring-core 中定义的类和方法</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">StringUtils</span> </span>&#123;</span><br><span class="line">  <span class="comment">// str 参数继承了全局的 @NonNull 注解</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">capitalize</span><span class="params">(String str)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Nullable</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getFilename</span><span class="params">(@Nullable String path)</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 错误：参数声明为 @NonNull，但传入的是 null。</span></span><br><span class="line">StringUtils.capitalize(<span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line">String filename = StringUtils.getFilename(<span class="string">"/path/to/file"</span>);</span><br><span class="line"><span class="comment">// 错误：filename 可能为空。</span></span><br><span class="line">System.out.println(filename.length());</span><br></pre></td></tr></table></figure><h2 id="Optional-类型"><a href="#Optional-类型" class="headerlink" title="Optional 类型"></a><code>Optional</code> 类型</h2><p>Java 8 引入了 <code>Optional&lt;T&gt;</code> 类型，我们可以用它来对函数的返回值进行包装。这种方式的优点是可以明确定义该方法是有可能返回空值的，因此调用方必须做好相应处理，这样也就不会引发空指针异常。但是，也不可避免地需要编写更多代码，而且会产生很多垃圾对象，增加 GC 的压力，因此在使用时需要酌情考虑。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">Optional&lt;String&gt; opt;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建</span></span><br><span class="line">opt = Optional.empty();</span><br><span class="line">opt = Optional.of(<span class="string">"text"</span>);</span><br><span class="line">opt = Optional.ofNullable(<span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判断并读取</span></span><br><span class="line"><span class="keyword">if</span> (opt.isPresent()) &#123;</span><br><span class="line">  opt.get();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 默认值</span></span><br><span class="line">opt.orElse(<span class="string">"default"</span>);</span><br><span class="line">opt.orElseGet(() -&gt; <span class="string">"default"</span>);</span><br><span class="line">opt.orElseThrow(() -&gt; <span class="keyword">new</span> NullPointerException());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 相关操作</span></span><br><span class="line">opt.ifPresent(value -&gt; &#123;</span><br><span class="line">  System.out.println(value);</span><br><span class="line">&#125;);</span><br><span class="line">opt.filter(value -&gt; value.length() &gt; <span class="number">5</span>);</span><br><span class="line">opt.map(value -&gt; value.trim());</span><br><span class="line">opt.flatMap(value -&gt; &#123;</span><br><span class="line">  String trimmed = value.trim();</span><br><span class="line">  <span class="keyword">return</span> trimmed.isEmpty() ? Optional.empty() : Optional.of(trimmed);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>方法的链式调用很容易引发空指针异常，但如果返回值都用 <code>Optional</code> 包装起来，就可以用 <code>flatMap</code> 方法来实现安全的链式调用了：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String zipCode = getUser()</span><br><span class="line">    .flatMap(User::getAddress)</span><br><span class="line">    .flatMap(Address::getZipCode)</span><br><span class="line">    .orElse(<span class="string">""</span>);</span><br></pre></td></tr></table></figure><p>Java 8 <a href="https://www.oracle.com/technetwork/articles/java/ma14-java-se-8-streams-2177646.html" target="_blank" rel="noopener">Stream API</a> 同样使用了 <code>Optional</code> 作为返回类型：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">stringList.stream().findFirst().orElse(<span class="string">"default"</span>);</span><br><span class="line">stringList.stream()</span><br><span class="line">    .max(Comparator.naturalOrder())</span><br><span class="line">    .ifPresent(System.out::println);</span><br></pre></td></tr></table></figure><p>此外，Java 8 还针对基础类型提供了单独的 <code>Optional</code> 类，如 <code>OptionalInt</code>、<code>OptionalDouble</code> 等，在性能要求比较高的场景下很适用。</p><h2 id="其它-JVM-语言中的空指针异常"><a href="#其它-JVM-语言中的空指针异常" class="headerlink" title="其它 JVM 语言中的空指针异常"></a>其它 JVM 语言中的空指针异常</h2><p>Scala 语言中的 <a href="https://www.scala-lang.org/api/current/scala/Option.html" target="_blank" rel="noopener"><code>Option</code></a> 类可以对标 Java 8 的 <code>Optional</code>。它有两个子类型，<code>Some</code> 表示有值，<code>None</code> 表示空。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> opt: <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">Some</span>(<span class="string">"text"</span>)</span><br><span class="line">opt.getOrElse(<span class="string">"default"</span>)</span><br></pre></td></tr></table></figure><p>除了使用 <code>Option#isEmpty</code> 判断，还可以使用 Scala 的模式匹配：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">opt <span class="keyword">match</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Some</span>(text) =&gt; println(text)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">None</span> =&gt; println(<span class="string">"default"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Scala 的集合处理函数库非常强大，<code>Option</code> 则可直接作为集合进行操作，如 <code>filer</code>、<code>map</code>、以及列表解析（for-comprehension）：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">opt.map(_.trim).filter(_.length &gt; <span class="number">0</span>).map(_.toUpperCase).getOrElse(<span class="string">"DEFAULT"</span>)</span><br><span class="line"><span class="keyword">val</span> upper = <span class="keyword">for</span> &#123;</span><br><span class="line">  text &lt;- opt</span><br><span class="line">  trimmed &lt;- <span class="type">Some</span>(text.trim())</span><br><span class="line">  upper &lt;- <span class="type">Some</span>(trimmed) <span class="keyword">if</span> trimmed.length &gt; <span class="number">0</span></span><br><span class="line">&#125; <span class="keyword">yield</span> upper</span><br><span class="line">upper.getOrElse(<span class="string">"DEFAULT"</span>)</span><br></pre></td></tr></table></figure><p>Kotlin 使用了另一种方式，用户在定义变量时就需要明确区分 <a href="https://kotlinlang.org/docs/reference/java-interop.html#nullability-annotations" target="_blank" rel="noopener">可空和不可空类型</a>。当可空类型被使用时，就必须进行空值检测。</p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a: String = <span class="string">"text"</span></span><br><span class="line">a = <span class="literal">null</span> <span class="comment">// 错误：无法将 null 赋值给非空 String 类型。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> b: String? = <span class="string">"text"</span></span><br><span class="line"><span class="comment">// 错误：操作可空类型时必须使用安全操作符（?.）或强制忽略（!!.）。</span></span><br><span class="line">println(b.length)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> l: <span class="built_in">Int</span>? = b?.length <span class="comment">// 安全操作</span></span><br><span class="line">b!!.length <span class="comment">// 强制忽略，可能引发空值异常</span></span><br></pre></td></tr></table></figure><p>Kotlin 的特性之一是与 Java 的可互操作性，但 Kotlin 编译器无法知晓 Java 类型是否为空，这就需要在 Java 代码中使用注解了，而 Kotlin 支持的 <a href="https://kotlinlang.org/docs/reference/java-interop.html#nullability-annotations" target="_blank" rel="noopener">注解</a> 也非常广泛。Spring Framework 5.0 起原生支持 Kotlin，其空值检测也是通过注解进行的，使得 Kotlin 可以安全地调用 Spring Framework 的所有 API。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在以上这些方案中，我比较推荐使用注解来预防空指针异常，因为这种方式十分有效，对代码的侵入性也较小。所有的公共 API 都应该使用 <code>@Nullable</code> 和 <code>@NonNull</code> 进行注解，这样就能强制调用方对空指针异常进行预防，让我们的程序更为健壮。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://howtodoinjava.com/java/exception-handling/how-to-effectively-handle-nullpointerexception-in-java/" target="_blank" rel="noopener">https://howtodoinjava.com/java/exception-handling/how-to-effectively-handle-nullpointerexception-in-java/</a></li><li><a href="http://jmri.sourceforge.net/help/en/html/doc/Technical/SpotBugs.shtml" target="_blank" rel="noopener">http://jmri.sourceforge.net/help/en/html/doc/Technical/SpotBugs.shtml</a></li><li><a href="https://dzone.com/articles/features-to-avoid-null-reference-exceptions-java-a" target="_blank" rel="noopener">https://dzone.com/articles/features-to-avoid-null-reference-exceptions-java-a</a></li><li><a href="https://medium.com/@fatihcoskun/kotlin-nullable-types-vs-java-optional-988c50853692" target="_blank" rel="noopener">https://medium.com/@fatihcoskun/kotlin-nullable-types-vs-java-optional-988c50853692</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Java 中任何对象都有可能为空，当我们调用空对象的方法时就会抛出 &lt;code&gt;NullPointerException&lt;/code&gt; 空指针异常，这是一种非常常见的错误类型。我们可以使用若干种方法来避免产生这类异常，使得我们的代码更为健壮。本文将列举这些解决方案，包括传统的空值检测、编程规范、以及使用现代 Java 语言引入的各类工具来作为辅助。&lt;/p&gt;
&lt;h2 id=&quot;运行时检测&quot;&gt;&lt;a href=&quot;#运行时检测&quot; class=&quot;headerlink&quot; title=&quot;运行时检测&quot;&gt;&lt;/a&gt;运行时检测&lt;/h2&gt;&lt;p&gt;最显而易见的方法就是使用 &lt;code&gt;if (obj == null)&lt;/code&gt; 来对所有需要用到的对象来进行检测，包括函数参数、返回值、以及类实例的成员变量。当你检测到 &lt;code&gt;null&lt;/code&gt; 值时，可以选择抛出更具针对性的异常类型，如 &lt;code&gt;IllegalArgumentException&lt;/code&gt;，并添加消息内容。我们可以使用一些库函数来简化代码，如 Java 7 开始提供的 &lt;a href=&quot;https://docs.oracle.com/javase/7/docs/api/java/util/Objects.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;code&gt;Objects#requireNonNull&lt;/code&gt;&lt;/a&gt; 方法：&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;testObjects&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(Object arg)&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Object checked = Objects.requireNonNull(arg, &lt;span class=&quot;string&quot;&gt;&quot;arg must not be null&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  checked.toString();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;Guava 的 &lt;a href=&quot;https://github.com/google/guava/wiki/PreconditionsExplained&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;code&gt;Preconditions&lt;/code&gt;&lt;/a&gt; 类中也提供了一系列用于检测参数合法性的工具函数，其中就包含空值检测：&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;testGuava&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(Object arg)&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Object checked = Preconditions.checkNotNull(arg, &lt;span class=&quot;string&quot;&gt;&quot;%s must not be null&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;arg&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  checked.toString();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们还可以使用 &lt;a href=&quot;https://projectlombok.org/features/NonNull&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Lombok&lt;/a&gt; 来生成空值检测代码，并抛出带有提示信息的空指针异常：&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;testLombok&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(@NonNull Object arg)&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  arg.toString();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;生成的代码如下：&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;testLombokGenerated&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(Object arg)&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (arg == &lt;span class=&quot;keyword&quot;&gt;null&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; NullPointerException(&lt;span class=&quot;string&quot;&gt;&quot;arg is marked @NonNull but is null&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  arg.toString();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这个注解还可以用在类实例的成员变量上，所有的赋值操作会自动进行空值检测。&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/cnblogs/categories/Programming/"/>
    
    
      <category term="java" scheme="http://shzhangji.com/cnblogs/tags/java/"/>
    
      <category term="spring" scheme="http://shzhangji.com/cnblogs/tags/spring/"/>
    
      <category term="eclipse" scheme="http://shzhangji.com/cnblogs/tags/eclipse/"/>
    
  </entry>
  
  <entry>
    <title>是否需要使用 ESLint jsx-no-bind 规则？</title>
    <link href="http://shzhangji.com/cnblogs/2018/09/14/is-it-necessary-to-apply-eslint-jsx-no-bind-rule/"/>
    <id>http://shzhangji.com/cnblogs/2018/09/14/is-it-necessary-to-apply-eslint-jsx-no-bind-rule/</id>
    <published>2018-09-14T01:18:52.000Z</published>
    <updated>2018-09-14T01:21:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>在使用 <a href="https://github.com/yannickcr/eslint-plugin-react" target="_blank" rel="noopener">ESLint React</a> 插件时，有一条名为 <a href="https://github.com/yannickcr/eslint-plugin-react/blob/master/docs/rules/jsx-no-bind.md" target="_blank" rel="noopener"><code>jsx-no-bind</code></a> 的检测规则，它会禁止我们在 JSX 属性中使用 <code>.bind</code> 方法和箭头函数。比如下列代码，ESLint 会提示 <code>onClick</code> 属性中的箭头函数不合法：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ListArrow</span> <span class="keyword">extends</span> <span class="title">React</span>.<span class="title">Component</span> </span>&#123;</span><br><span class="line">  render() &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      &lt;ul&gt;</span><br><span class="line">        &#123;<span class="keyword">this</span>.state.items.map(<span class="function"><span class="params">item</span> =&gt;</span> (</span><br><span class="line">          &lt;li key=&#123;item.id&#125; onClick=&#123;() =&gt; &#123; alert(item.id) &#125;&#125;&gt;&#123;item.text&#125;&lt;<span class="regexp">/li&gt;</span></span><br><span class="line"><span class="regexp">        ))&#125;</span></span><br><span class="line"><span class="regexp">      &lt;/u</span>l&gt;</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这条规则的引入原因有二。首先，每次执行 <code>render</code> 方法时都会生成一个新的匿名函数对象，这样就会对垃圾回收器造成负担；其次，属性中的箭头函数会影响渲染过程：当你使用了 <code>PureComponent</code>，或者自己实现了 <code>shouldComponentUpdate</code> 方法，使用对象比较的方式来决定是否要重新渲染组件，那么组件属性中的箭头函数就会让该方法永远返回真值，引起不必要的重复渲染。</p><p>然而，反对的声音认为这两个原因还不足以要求我们在所有代码中应用该规则，特别是当需要引入更多代码、并牺牲一定可读性的情况下。在 <a href="https://github.com/airbnb/javascript/blob/eslint-config-airbnb-v17.1.0/packages/eslint-config-airbnb/rules/react.js#L93" target="_blank" rel="noopener">Airbnb ESLint</a> 预设规则集中，只禁止了 <code>.bind</code> 方法的使用，而允许在属性（props）或引用（refs）中使用箭头函数。对此我翻阅了文档，阅读了一些关于这个话题的博客，也认为这条规则有些过于严格。甚至还有博主称该规则是一种过早优化（premature optimization），我们需要先做基准测试，再着手修改代码。下文中，我将简要叙述箭头函数是如何影响渲染过程的，有哪些可行的解决方案，以及它为何不太重要。</p><a id="more"></a><h2 id="不同类型的-React-组件"><a href="#不同类型的-React-组件" class="headerlink" title="不同类型的 React 组件"></a>不同类型的 React 组件</h2><p>通常我们会通过继承 <code>React.Component</code> 类并实现 <code>render</code> 方法来创建一个 React 组件。另一个内置的组件基类是 <code>React.PureComponent</code>，它的区别在于已经为我们实现了 <code>shouldComponentUpdate</code> 方法。在普通的 React 组件中，该方法默认返回 <code>true</code>，也就是说当属性（props）或状态（state）发生改变时，一定会重新进行渲染。而 <code>PureComponent</code> 实现的该方法中，会对新、旧属性和状态的键值做一个等值比较，只有当内容发生改变时才会重新渲染。下面定义的这两个组件产生的效果是一致的：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PureChild</span> <span class="keyword">extends</span> <span class="title">React</span>.<span class="title">PureComponent</span> </span>&#123;</span><br><span class="line">  render() &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      &lt;div&gt;&#123;<span class="keyword">this</span>.props.message&#125;&lt;<span class="regexp">/div&gt;</span></span><br><span class="line"><span class="regexp">    )</span></span><br><span class="line"><span class="regexp">  &#125;</span></span><br><span class="line"><span class="regexp">&#125;</span></span><br><span class="line"><span class="regexp"></span></span><br><span class="line"><span class="regexp">class RegularChildB extends React.Component &#123;</span></span><br><span class="line"><span class="regexp">  shouldComponentUpdate(nextProps, nextStates) &#123;</span></span><br><span class="line"><span class="regexp">    return this.props.message !== nextProps.message</span></span><br><span class="line"><span class="regexp">  &#125;</span></span><br><span class="line"><span class="regexp"></span></span><br><span class="line"><span class="regexp">  render() &#123;</span></span><br><span class="line"><span class="regexp">    return (</span></span><br><span class="line"><span class="regexp">      &lt;div&gt;&#123;this.props.message&#125;&lt;/</span>div&gt;</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当它们的属性发生变化时，会检查 <code>message</code> 变量中的值是否和原来相等。属性和状态都是 <code>object</code> 类型，React 会遍历所有键值进行 <code>===</code> 等值比较。在 JavaScript 中，只有基础类型之间的比较、或同一个对象和自身比较时才能通过。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> === <span class="number">1</span></span><br><span class="line"><span class="string">'hello world'</span> === <span class="string">'hello world'</span></span><br><span class="line">[] !== []</span><br><span class="line">(<span class="function"><span class="params">()</span> =&gt;</span> &#123;&#125;) !== <span class="function">(<span class="params">(</span>) =&gt;</span> &#123;&#125;)</span><br></pre></td></tr></table></figure><p>显然，箭头函数是无法通过这个等值检查的。如果父组件将箭头函数作为属性传入 <code>PureComponent</code>，那么每次渲染都会引发子组件的渲染。相反地，如果我们没有使用 <code>PureComponent</code>，或进行类似的等值比较，那么组件一定会进行更新，也就没有应用该规则的必要了。</p><p>另一个种较为流行的组件定义方式是“无状态函数式组件（SFC）”。这类组件好比一个数学函数，其渲染结果完全依赖于输入的属性值。不过，它本质上是一个普通的组件，并没有实现 <code>shouldComponentUpdate</code> 方法，且组件的定义方式也不允许我们自己来实现。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> StatelessChild = <span class="function">(<span class="params">props</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    &lt;div&gt;&#123;props.message&#125;&lt;<span class="regexp">/div&gt;</span></span><br><span class="line"><span class="regexp">  )</span></span><br><span class="line"><span class="regexp">&#125;</span></span><br></pre></td></tr></table></figure><h2 id="如何修复-jsx-no-bind-错误警告"><a href="#如何修复-jsx-no-bind-错误警告" class="headerlink" title="如何修复 jsx-no-bind 错误警告"></a>如何修复 <code>jsx-no-bind</code> 错误警告</h2><p>箭头函数通常会用作事件处理。如果我们直接使用普通的函数或类方法，<code>this</code> 关键字将无法正确绑定到当前实例，它的值是 <code>undefined</code>。只有使用了 <code>.bind</code> 方法或箭头函数时，我们才能在函数体中通过 <code>this</code> 来访问到类的其他成员，只是这样就会触发 <code>jsx-no-bind</code> 报警。解决方法是在构造函数中对方法进行绑定，或者使用尚在草案阶段的类属性语法，并通过 <a href="https://babeljs.io/docs/plugins/transform-class-properties/" target="_blank" rel="noopener">Babel</a> 进行转换。更多信息可以查阅 <a href="https://reactjs.org/docs/handling-events.html" target="_blank" rel="noopener">React 官方文档</a>，以下用 <a href="https://github.com/jizhang/jsx-no-bind/blob/master/src/components/NoArgument.js" target="_blank" rel="noopener">代码</a> 演示不同的做法。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="class"><span class="keyword">class</span> <span class="title">NoArgument</span> <span class="keyword">extends</span> <span class="title">React</span>.<span class="title">Component</span> </span>&#123;</span><br><span class="line">  <span class="keyword">constructor</span>() &#123;</span><br><span class="line">    <span class="keyword">this</span>.handleClickBoundA = <span class="keyword">this</span>.handleClickUnbound.bind(<span class="keyword">this</span>)</span><br><span class="line">    <span class="keyword">this</span>.handleClickBoundC = <span class="function"><span class="params">()</span> =&gt;</span> &#123; <span class="keyword">this</span>.setState() &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  handleClickUnbound() &#123; <span class="comment">/* "this" 的值是未定义 */</span> &#125;</span><br><span class="line">  handleClickBoundB = <span class="function"><span class="params">()</span> =&gt;</span> &#123; <span class="keyword">this</span>.setState() &#125;</span><br><span class="line">  render() &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      &lt;div&gt;</span><br><span class="line">        <span class="built_in">Error</span>: jsx-no-bind</span><br><span class="line">        &lt;button onClick=&#123;() =&gt; &#123; <span class="keyword">this</span>.setState() &#125;&#125;&gt;ArrowA&lt;<span class="regexp">/button&gt;</span></span><br><span class="line"><span class="regexp">        &lt;button onClick=&#123;() =&gt; &#123; this.handleClickUnbound() &#125;&#125;&gt;ArrowB&lt;/</span>button&gt;</span><br><span class="line">        &lt;button onClick=&#123;<span class="keyword">this</span>.handleClickUnbound.bind(<span class="keyword">this</span>)&#125;&gt;Bind&lt;<span class="regexp">/button&gt;</span></span><br><span class="line"><span class="regexp">        No error:</span></span><br><span class="line"><span class="regexp">        &lt;button onClick=&#123;this.handleClickBoundA&#125;&gt;BoundA&lt;/</span>button&gt;</span><br><span class="line">        &lt;button onClick=&#123;<span class="keyword">this</span>.handleClickBoundB&#125;&gt;BoundB&lt;<span class="regexp">/button&gt;</span></span><br><span class="line"><span class="regexp">        &lt;button onClick=&#123;this.handleClickBoundC&#125;&gt;BoundC&lt;/</span>button&gt;</span><br><span class="line">      &lt;<span class="regexp">/div&gt;</span></span><br><span class="line"><span class="regexp">    )</span></span><br><span class="line"><span class="regexp">  &#125;</span></span><br><span class="line"><span class="regexp">&#125;</span></span><br></pre></td></tr></table></figure><p>如果事件处理需要用到额外的参数，比如渲染列表时捕捉每一项的点击事件，就不那么容易了。有两种解决方案，一是将列表项作为独立的组件拆分出来，通过组件属性来传递事件处理函数和它的参数，示例如下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Item</span> <span class="keyword">extends</span> <span class="title">React</span>.<span class="title">PureComponent</span> </span>&#123;</span><br><span class="line">  handleClick = <span class="function"><span class="params">()</span> =&gt;</span> &#123; <span class="keyword">this</span>.props.onClick(<span class="keyword">this</span>.props.item.id) &#125;</span><br><span class="line">  render() &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      &lt;li onClick=&#123;<span class="keyword">this</span>.handleClick&#125;&gt;&#123;<span class="keyword">this</span>.props.item.text&#125;&lt;<span class="regexp">/li&gt;</span></span><br><span class="line"><span class="regexp">    )</span></span><br><span class="line"><span class="regexp">  &#125;</span></span><br><span class="line"><span class="regexp">&#125;</span></span><br><span class="line"><span class="regexp"></span></span><br><span class="line"><span class="regexp">export default class ListSeparate extends React.Component &#123;</span></span><br><span class="line"><span class="regexp">  handleClick = (itemId) =&gt; &#123; alert(itemId) &#125;</span></span><br><span class="line"><span class="regexp">  render() &#123;</span></span><br><span class="line"><span class="regexp">    return (</span></span><br><span class="line"><span class="regexp">      &lt;ul&gt;</span></span><br><span class="line"><span class="regexp">        &#123;this.props.items.map(item =&gt; (</span></span><br><span class="line"><span class="regexp">          &lt;Item key=&#123;item.id&#125; item=&#123;item&#125; onClick=&#123;this.handleClick&#125; /</span>&gt;</span><br><span class="line">        ))&#125;</span><br><span class="line">      &lt;<span class="regexp">/ul&gt;</span></span><br><span class="line"><span class="regexp">    )</span></span><br><span class="line"><span class="regexp">  &#125;</span></span><br><span class="line"><span class="regexp">&#125;</span></span><br></pre></td></tr></table></figure><p>这种方式也称之为关注点分离（separation of concerns），因为 <code>List</code> 组件只需负责遍历列表项，而由 <code>Item</code> 组件来负责渲染。不过这样一来也会增加许多模板代码，我们需要跟踪多个属性值来确定事件处理过程，因此降低了代码可读性。若直接使用箭头函数，事件处理和组件渲染是在一处的，便于理解，也是 React 社区所推崇的方式。</p><p>另一种方式是使用 DOM <a href="https://developer.mozilla.org/en/docs/Web/API/HTMLElement/dataset" target="_blank" rel="noopener"><code>dataset</code></a> 属性，也就是将需要传递的参数暂存在 HTML 标签的 <code>data-*</code> 属性中， 然后通过 <code>event</code> 变量来读取。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="class"><span class="keyword">class</span> <span class="title">ListDataset</span> <span class="keyword">extends</span> <span class="title">React</span>.<span class="title">Component</span> </span>&#123;</span><br><span class="line">  handleClick = <span class="function">(<span class="params">event</span>) =&gt;</span> &#123; alert(event.target.dataset.itemId) &#125;</span><br><span class="line">  render() &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      &lt;ul&gt;</span><br><span class="line">        &#123;<span class="keyword">this</span>.props.items.map(<span class="function"><span class="params">item</span> =&gt;</span> (</span><br><span class="line">          &lt;li key=&#123;item.id&#125; data-item-id=&#123;item.id&#125; onClick=&#123;<span class="keyword">this</span>.handleClick&#125;&gt;&#123;item.text&#125;&lt;<span class="regexp">/li&gt;</span></span><br><span class="line"><span class="regexp">        ))&#125;</span></span><br><span class="line"><span class="regexp">      &lt;/u</span>l&gt;</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="虚拟-DOM-与-React-协调"><a href="#虚拟-DOM-与-React-协调" class="headerlink" title="虚拟 DOM 与 React 协调"></a>虚拟 DOM 与 React 协调</h2><p>上文说到，箭头函数会引发 <code>PureComponent</code> 不必要的渲染，这个结论只正确了一半。React 的渲染过程可以分为几个步骤：首先，调用 <code>render</code> 方法，返回一个 React 元素的树形结构；将该结构与内存中的虚拟 DOM 树进行对比，将差异部分应用到浏览器的真实 DOM 树中。这个过程在 React 中称为协调（<a href="https://reactjs.org/docs/reconciliation.html" target="_blank" rel="noopener">reconciliation</a>）。因此，即便 <code>render</code> 方法被调用了多次，如果其返回的 React 元素树都是相同的，那么也不会触发真实 DOM 渲染，而这个过程通常会比纯 JavaScript 要来得耗时。这样看来，如果一个组件的确需要频繁变动，那么继承了 <code>PureComponent</code> 反而会增加一次比对的消耗，得不偿失。</p><p><img src="/cnblogs/images/jsx-no-bind/should-component-update.png" alt="shouldComponentUpdate 生命周期方法"></p><p><a href="https://reactjs.org/docs/optimizing-performance.html#shouldcomponentupdate-in-action" target="_blank" rel="noopener">图片来源</a></p><p>此外，在事件绑定属性中使用箭头函数，一般也不会触发真实 DOM 的渲染，原因是 React 的事件监听器是绑定在顶层的 <code>document</code> 元素上的，当 <code>li</code> 上触发了 <code>onClick</code> 事件后，该事件会向上冒泡（bubble up）至顶层元素，由 React 事件管理系统接收和处理。</p><p><img src="/cnblogs/images/jsx-no-bind/top-level-delegation.jpg" alt="顶层事件委托"></p><p><a href="https://levelup.gitconnected.com/how-exactly-does-react-handles-events-71e8b5e359f2" target="_blank" rel="noopener">图片来源</a></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>可以看到，在修复 <code>jsx-no-bind</code> 的过程中，我们需要牺牲一定的代码可读性，而获得的性能收益也许是微不足道甚至是相反的。与其猜测箭头函数会引发性能问题，不如先用最自然的方式来编写代码，当遇到真正的性能瓶颈时加以测度，最终找出合适的技术方案。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://github.com/yannickcr/eslint-plugin-react/blob/master/docs/rules/jsx-no-bind.md" target="_blank" rel="noopener">https://github.com/yannickcr/eslint-plugin-react/blob/master/docs/rules/jsx-no-bind.md</a></li><li><a href="https://cdb.reacttraining.com/react-inline-functions-and-performance-bdff784f5578" target="_blank" rel="noopener">https://cdb.reacttraining.com/react-inline-functions-and-performance-bdff784f5578</a></li><li><a href="https://maarten.mulders.it/blog/2017/07/no-bind-or-arrow-in-jsx-props-why-how.html" target="_blank" rel="noopener">https://maarten.mulders.it/blog/2017/07/no-bind-or-arrow-in-jsx-props-why-how.html</a></li><li><a href="https://reactjs.org/docs/faq-functions.html#example-passing-params-using-data-attributes" target="_blank" rel="noopener">https://reactjs.org/docs/faq-functions.html#example-passing-params-using-data-attributes</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在使用 &lt;a href=&quot;https://github.com/yannickcr/eslint-plugin-react&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ESLint React&lt;/a&gt; 插件时，有一条名为 &lt;a href=&quot;https://github.com/yannickcr/eslint-plugin-react/blob/master/docs/rules/jsx-no-bind.md&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;code&gt;jsx-no-bind&lt;/code&gt;&lt;/a&gt; 的检测规则，它会禁止我们在 JSX 属性中使用 &lt;code&gt;.bind&lt;/code&gt; 方法和箭头函数。比如下列代码，ESLint 会提示 &lt;code&gt;onClick&lt;/code&gt; 属性中的箭头函数不合法：&lt;/p&gt;
&lt;figure class=&quot;highlight javascript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;ListArrow&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;React&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;Component&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  render() &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; (&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;lt;ul&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#123;&lt;span class=&quot;keyword&quot;&gt;this&lt;/span&gt;.state.items.map(&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;params&quot;&gt;item&lt;/span&gt; =&amp;gt;&lt;/span&gt; (&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;          &amp;lt;li key=&amp;#123;item.id&amp;#125; onClick=&amp;#123;() =&amp;gt; &amp;#123; alert(item.id) &amp;#125;&amp;#125;&amp;gt;&amp;#123;item.text&amp;#125;&amp;lt;&lt;span class=&quot;regexp&quot;&gt;/li&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;regexp&quot;&gt;        ))&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;regexp&quot;&gt;      &amp;lt;/u&lt;/span&gt;l&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    )&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这条规则的引入原因有二。首先，每次执行 &lt;code&gt;render&lt;/code&gt; 方法时都会生成一个新的匿名函数对象，这样就会对垃圾回收器造成负担；其次，属性中的箭头函数会影响渲染过程：当你使用了 &lt;code&gt;PureComponent&lt;/code&gt;，或者自己实现了 &lt;code&gt;shouldComponentUpdate&lt;/code&gt; 方法，使用对象比较的方式来决定是否要重新渲染组件，那么组件属性中的箭头函数就会让该方法永远返回真值，引起不必要的重复渲染。&lt;/p&gt;
&lt;p&gt;然而，反对的声音认为这两个原因还不足以要求我们在所有代码中应用该规则，特别是当需要引入更多代码、并牺牲一定可读性的情况下。在 &lt;a href=&quot;https://github.com/airbnb/javascript/blob/eslint-config-airbnb-v17.1.0/packages/eslint-config-airbnb/rules/react.js#L93&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Airbnb ESLint&lt;/a&gt; 预设规则集中，只禁止了 &lt;code&gt;.bind&lt;/code&gt; 方法的使用，而允许在属性（props）或引用（refs）中使用箭头函数。对此我翻阅了文档，阅读了一些关于这个话题的博客，也认为这条规则有些过于严格。甚至还有博主称该规则是一种过早优化（premature optimization），我们需要先做基准测试，再着手修改代码。下文中，我将简要叙述箭头函数是如何影响渲染过程的，有哪些可行的解决方案，以及它为何不太重要。&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/cnblogs/categories/Programming/"/>
    
    
      <category term="javascript" scheme="http://shzhangji.com/cnblogs/tags/javascript/"/>
    
      <category term="react" scheme="http://shzhangji.com/cnblogs/tags/react/"/>
    
      <category term="eslint" scheme="http://shzhangji.com/cnblogs/tags/eslint/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow 模型如何对外提供服务</title>
    <link href="http://shzhangji.com/cnblogs/2018/05/14/serve-tensorflow-estimator-with-savedmodel/"/>
    <id>http://shzhangji.com/cnblogs/2018/05/14/serve-tensorflow-estimator-with-savedmodel/</id>
    <published>2018-05-14T05:23:14.000Z</published>
    <updated>2018-05-14T05:48:40.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.tensorflow.org/" target="_blank" rel="noopener">TensorFlow</a> 是目前最为流行的机器学习框架之一，通过它我们可以便捷地构建机器学习模型。使用 TensorFlow 模型对外提供服务有若干种方式，本文将介绍如何使用 SavedModel 机制来编写模型预测接口。</p><p><img src="/cnblogs/images/tf-logo.png" alt=""></p><h2 id="鸢尾花深层神经网络分类器"><a href="#鸢尾花深层神经网络分类器" class="headerlink" title="鸢尾花深层神经网络分类器"></a>鸢尾花深层神经网络分类器</h2><p>首先让我们使用 TensorFlow 的深层神经网络模型来构建一个鸢尾花的分类器。完整的教程可以在 TensorFlow 的官方文档中查看（<a href="https://www.tensorflow.org/get_started/premade_estimators" target="_blank" rel="noopener">Premade Estimators</a>），我也提供了一份示例代码，托管在 GitHub 上（<a href="https://github.com/jizhang/tf-serve/blob/master/iris_dnn.py" target="_blank" rel="noopener"><code>iris_dnn.py</code></a>），读者可以克隆到本地进行测试。以下是部分代码摘要：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">feature_columns = [tf.feature_column.numeric_column(key=key)</span><br><span class="line">                   <span class="keyword">for</span> key <span class="keyword">in</span> train_x.keys()]</span><br><span class="line">classifier = tf.estimator.DNNClassifier(</span><br><span class="line">    feature_columns=feature_columns,</span><br><span class="line">    hidden_units=[<span class="number">10</span>, <span class="number">10</span>],</span><br><span class="line">    n_classes=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">classifier.train(</span><br><span class="line">    input_fn=<span class="keyword">lambda</span>: train_input_fn(train_x, train_y, batch_size=BATCH_SIZE),</span><br><span class="line">    steps=STEPS)</span><br><span class="line"></span><br><span class="line">predictions = classifier.predict(</span><br><span class="line">    input_fn=<span class="keyword">lambda</span>: eval_input_fn(predict_x, labels=<span class="keyword">None</span>, batch_size=BATCH_SIZE))</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="将模型导出为-SavedModel-格式"><a href="#将模型导出为-SavedModel-格式" class="headerlink" title="将模型导出为 SavedModel 格式"></a>将模型导出为 SavedModel 格式</h2><p>TensorFlow 提供了 <a href="https://www.tensorflow.org/programmers_guide/saved_model#using_savedmodel_with_estimators" target="_blank" rel="noopener">SavedModel</a> 机制，用以将训练好的模型导出为外部文件，供后续使用或对外提供服务。<code>Estimator</code> 类的 <code>export_savedmodel</code> 方法接收两个参数：导出目录和数据接收函数。该函数定义了导出的模型将会对何种格式的参数予以响应。通常，我们会使用 TensorFlow 的 <a href="https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/core/example/example.proto" target="_blank" rel="noopener"><code>Example</code></a> 类型来表示样本和特征。例如，鸢尾花样本可以用如下形式表示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Example(</span><br><span class="line">    features=Features(</span><br><span class="line">        feature=&#123;</span><br><span class="line">            <span class="string">'SepalLength'</span>: Feature(float_list=FloatList(value=[<span class="number">5.1</span>])),</span><br><span class="line">            <span class="string">'SepalWidth'</span>: Feature(float_list=FloatList(value=[<span class="number">3.3</span>])),</span><br><span class="line">            <span class="string">'PetalLength'</span>: Feature(float_list=FloatList(value=[<span class="number">1.7</span>])),</span><br><span class="line">            <span class="string">'PetalWidth'</span>: Feature(float_list=FloatList(value=[<span class="number">0.5</span>])),</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>接收函数会收到序列化后的 <code>Example</code> 对象，将其转化成一组 Tensor 供模型消费。TensorFlow 提供了一些工具函数帮助我们完成这些转换。首先，我们将 <code>feature_columns</code> 数组转化成 <code>Feature</code> 字典，作为反序列化的规格标准，再用它生成接收函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># [</span></span><br><span class="line"><span class="comment">#     _NumericColumn(key='SepalLength', shape=(1,), dtype=tf.float32),</span></span><br><span class="line"><span class="comment">#     ...</span></span><br><span class="line"><span class="comment"># ]</span></span><br><span class="line">feature_columns = [tf.feature_column.numeric_column(key=key)</span><br><span class="line">                   <span class="keyword">for</span> key <span class="keyword">in</span> train_x.keys()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#     'SepalLength': FixedLenFeature(shape=(1,), dtype=tf.float32),</span></span><br><span class="line"><span class="comment">#     ...</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line">feature_spec = tf.feature_column.make_parse_example_spec(feature_columns)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建接收函数，并导出模型。</span></span><br><span class="line">serving_input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)</span><br><span class="line">export_dir = classifier.export_savedmodel(<span class="string">'export'</span>, serving_input_receiver_fn)</span><br></pre></td></tr></table></figure><h2 id="使用命令行工具检测-SavedModel"><a href="#使用命令行工具检测-SavedModel" class="headerlink" title="使用命令行工具检测 SavedModel"></a>使用命令行工具检测 SavedModel</h2><p>每次导出模型都会生成一个带有时间戳的目录，里面包含了该模型的参数信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export/1524907728/saved_model.pb</span><br><span class="line">export/1524907728/variables</span><br><span class="line">export/1524907728/variables/variables.data-00000-of-00001</span><br><span class="line">export/1524907728/variables/variables.index</span><br></pre></td></tr></table></figure><p>TensorFlow 提供的命令行工具可用于检视导出模型的内容，甚至可以直接调用预测函数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ saved_model_cli show --dir <span class="built_in">export</span>/1524906774 \</span><br><span class="line">  --tag_set serve --signature_def serving_default</span><br><span class="line">The given SavedModel SignatureDef contains the following input(s):</span><br><span class="line">  inputs[<span class="string">'inputs'</span>] tensor_info:</span><br><span class="line">      dtype: DT_STRING</span><br><span class="line">      shape: (-1)</span><br><span class="line">The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">  outputs[<span class="string">'classes'</span>] tensor_info:</span><br><span class="line">      dtype: DT_STRING</span><br><span class="line">      shape: (-1, 3)</span><br><span class="line">  outputs[<span class="string">'scores'</span>] tensor_info:</span><br><span class="line">      dtype: DT_FLOAT</span><br><span class="line">      shape: (-1, 3)</span><br><span class="line">Method name is: tensorflow/serving/classify</span><br><span class="line"></span><br><span class="line">$ saved_model_cli run --dir <span class="built_in">export</span>/1524906774 \</span><br><span class="line">  --tag_set serve --signature_def serving_default \</span><br><span class="line">  --input_examples <span class="string">'inputs=[&#123;"SepalLength":[5.1],"SepalWidth":[3.3],"PetalLength":[1.7],"PetalWidth":[0.5]&#125;]'</span></span><br><span class="line">Result <span class="keyword">for</span> output key classes:</span><br><span class="line">[[b<span class="string">'0'</span> b<span class="string">'1'</span> b<span class="string">'2'</span>]]</span><br><span class="line">Result <span class="keyword">for</span> output key scores:</span><br><span class="line">[[9.9919027e-01 8.0969761e-04 1.2872645e-09]]</span><br></pre></td></tr></table></figure><h2 id="使用-contrib-predictor-提供服务"><a href="#使用-contrib-predictor-提供服务" class="headerlink" title="使用 contrib.predictor 提供服务"></a>使用 <code>contrib.predictor</code> 提供服务</h2><p><code>tf.contrib.predictor.from_saved_model</code> 方法能够将导出的模型加载进来，直接生成一个预测函数供使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从导出目录中加载模型，并生成预测函数。</span></span><br><span class="line">predict_fn = tf.contrib.predictor.from_saved_model(export_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 Pandas 数据框定义测试数据。</span></span><br><span class="line">inputs = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">'SepalLength'</span>: [<span class="number">5.1</span>, <span class="number">5.9</span>, <span class="number">6.9</span>],</span><br><span class="line">    <span class="string">'SepalWidth'</span>: [<span class="number">3.3</span>, <span class="number">3.0</span>, <span class="number">3.1</span>],</span><br><span class="line">    <span class="string">'PetalLength'</span>: [<span class="number">1.7</span>, <span class="number">4.2</span>, <span class="number">5.4</span>],</span><br><span class="line">    <span class="string">'PetalWidth'</span>: [<span class="number">0.5</span>, <span class="number">1.5</span>, <span class="number">2.1</span>],</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将输入数据转换成序列化后的 Example 字符串。</span></span><br><span class="line">examples = []</span><br><span class="line"><span class="keyword">for</span> index, row <span class="keyword">in</span> inputs.iterrows():</span><br><span class="line">    feature = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> col, value <span class="keyword">in</span> row.iteritems():</span><br><span class="line">        feature[col] = tf.train.Feature(float_list=tf.train.FloatList(value=[value]))</span><br><span class="line">    example = tf.train.Example(</span><br><span class="line">        features=tf.train.Features(</span><br><span class="line">            feature=feature</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    examples.append(example.SerializeToString())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始预测</span></span><br><span class="line">predictions = predict_fn(&#123;<span class="string">'inputs'</span>: examples&#125;)</span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#     'classes': [</span></span><br><span class="line"><span class="comment">#         [b'0', b'1', b'2'],</span></span><br><span class="line"><span class="comment">#         [b'0', b'1', b'2'],</span></span><br><span class="line"><span class="comment">#         [b'0', b'1', b'2']</span></span><br><span class="line"><span class="comment">#     ],</span></span><br><span class="line"><span class="comment">#     'scores': [</span></span><br><span class="line"><span class="comment">#         [9.9826765e-01, 1.7323202e-03, 4.7271198e-15],</span></span><br><span class="line"><span class="comment">#         [2.1470961e-04, 9.9776912e-01, 2.0161823e-03],</span></span><br><span class="line"><span class="comment">#         [4.2676111e-06, 4.8709501e-02, 9.5128632e-01]</span></span><br><span class="line"><span class="comment">#     ]</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br></pre></td></tr></table></figure><p>我们可以对结果稍加整理：</p><table><thead><tr><th>SepalLength</th><th>SepalWidth</th><th>PetalLength</th><th>PetalWidth</th><th>ClassID</th><th>Probability</th></tr></thead><tbody><tr><td>5.1</td><td>3.3</td><td>1.7</td><td>0.5</td><td>0</td><td>0.998268</td></tr><tr><td>5.9</td><td>3.0</td><td>4.2</td><td>1.5</td><td>1</td><td>0.997769</td></tr><tr><td>6.9</td><td>3.1</td><td>5.4</td><td>2.1</td><td>2</td><td>0.951286</td></tr></tbody></table><p>本质上，<code>from_saved_model</code> 方法会使用 <code>saved_model.loader</code> 机制将导出的模型加载到一个 TensorFlow 会话中，读取模型的入参出参信息，生成并组装好相应的 Tensor，最后调用 <code>session.run</code> 来获取结果。对应这个过程，我编写了一段示例代码（<a href="https://github.com/jizhang/tf-serve/blob/master/iris_sess.py" target="_blank" rel="noopener"><code>iris_sess.py</code></a>），读者也可以直接参考 TensorFlow 的源码 <a href="https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/contrib/predictor/saved_model_predictor.py" target="_blank" rel="noopener"><code>saved_model_predictor.py</code></a>。此外，<a href="https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/python/tools/saved_model_cli.py" target="_blank" rel="noopener"><code>saved_model_cli</code></a> 命令也使用了同样的方式。</p><h2 id="使用-TensorFlow-Serving-提供服务"><a href="#使用-TensorFlow-Serving-提供服务" class="headerlink" title="使用 TensorFlow Serving 提供服务"></a>使用 TensorFlow Serving 提供服务</h2><p>最后，我们来演示一下如何使用 TensorFlow 的姊妹项目 <a href="https://www.tensorflow.org/serving/" target="_blank" rel="noopener">TensorFlow Serving</a> 来基于 SavedModel 对外提供服务。</p><h3 id="安装并启动-TensorFlow-ModelServer"><a href="#安装并启动-TensorFlow-ModelServer" class="headerlink" title="安装并启动 TensorFlow ModelServer"></a>安装并启动 TensorFlow ModelServer</h3><p>TensorFlow 服务端代码是使用 C++ 开发的，因此最便捷的安装方式是通过软件源来获取编译好的二进制包。读者可以根据 <a href="https://www.tensorflow.org/serving/setup" target="_blank" rel="noopener">官方文档</a> 在 Ubuntu 中配置软件源和安装服务端：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ apt-get install tensorflow-model-server</span><br></pre></td></tr></table></figure><p>然后就可以使用以下命令启动服务端了，该命令会加载导出目录中最新的一份模型来提供服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ tensorflow_model_server --port=9000 --model_base_path=/root/<span class="built_in">export</span></span><br><span class="line">2018-05-14 01:05:12.561 Loading SavedModel with tags: &#123; serve &#125;; from: /root/<span class="built_in">export</span>/1524907728</span><br><span class="line">2018-05-14 01:05:12.639 Successfully loaded servable version &#123;name: default version: 1524907728&#125;</span><br><span class="line">2018-05-14 01:05:12.641 Running ModelServer at 0.0.0.0:9000 ...</span><br></pre></td></tr></table></figure><h3 id="使用-SDK-访问远程模型"><a href="#使用-SDK-访问远程模型" class="headerlink" title="使用 SDK 访问远程模型"></a>使用 SDK 访问远程模型</h3><p>TensorFlow Serving 是基于 gRPC 和 Protocol Buffers 开发的，因此我们需要安装相应的 SDK 包来发起调用。需要注意的是，官方的 TensorFlow Serving API 目前只提供了 Python 2.7 版本的 SDK，不过社区有人贡献了支持 Python 3.x 的软件包，我们可以用以下命令安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install tensorflow-seving-api-python3==1.7.0</span><br></pre></td></tr></table></figure><p>调用过程很容易理解：我们首先创建远程连接，向服务端发送 <code>Example</code> 实例列表，并获取预测结果。完整代码可以在 <a href="https://github.com/jizhang/tf-serve/blob/master/iris_remote.py" target="_blank" rel="noopener"><code>iris_remote.py</code></a> 中找到。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 gRPC 连接</span></span><br><span class="line">channel = implementations.insecure_channel(<span class="string">'127.0.0.1'</span>, <span class="number">9000</span>)</span><br><span class="line">stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取测试数据集，并转换成 Example 实例。</span></span><br><span class="line">inputs = pd.DateFrame()</span><br><span class="line">examples = [tf.tain.Example() <span class="keyword">for</span> index, row <span class="keyword">in</span> inputs.iterrows()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备 RPC 请求，指定模型名称。</span></span><br><span class="line">request = classification_pb2.ClassificationRequest()</span><br><span class="line">request.model_spec.name = <span class="string">'default'</span></span><br><span class="line">request.input.example_list.examples.extend(examples)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取结果</span></span><br><span class="line">response = stub.Classify(request, <span class="number">10.0</span>)</span><br><span class="line"><span class="comment"># result &#123;</span></span><br><span class="line"><span class="comment">#   classifications &#123;</span></span><br><span class="line"><span class="comment">#     classes &#123;</span></span><br><span class="line"><span class="comment">#       label: "0"</span></span><br><span class="line"><span class="comment">#       score: 0.998267650604248</span></span><br><span class="line"><span class="comment">#     &#125;</span></span><br><span class="line"><span class="comment">#     ...</span></span><br><span class="line"><span class="comment">#   &#125;</span></span><br><span class="line"><span class="comment">#   ...</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.tensorflow.org/get_started/premade_estimators" target="_blank" rel="noopener">https://www.tensorflow.org/get_started/premade_estimators</a></li><li><a href="https://www.tensorflow.org/programmers_guide/saved_model" target="_blank" rel="noopener">https://www.tensorflow.org/programmers_guide/saved_model</a></li><li><a href="https://www.tensorflow.org/serving/" target="_blank" rel="noopener">https://www.tensorflow.org/serving/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://www.tensorflow.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;TensorFlow&lt;/a&gt; 是目前最为流行的机器学习框架之一，通过它我们可以便捷地构建机器学习模型。使用 TensorFlow 模型对外提供服务有若干种方式，本文将介绍如何使用 SavedModel 机制来编写模型预测接口。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/cnblogs/images/tf-logo.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;鸢尾花深层神经网络分类器&quot;&gt;&lt;a href=&quot;#鸢尾花深层神经网络分类器&quot; class=&quot;headerlink&quot; title=&quot;鸢尾花深层神经网络分类器&quot;&gt;&lt;/a&gt;鸢尾花深层神经网络分类器&lt;/h2&gt;&lt;p&gt;首先让我们使用 TensorFlow 的深层神经网络模型来构建一个鸢尾花的分类器。完整的教程可以在 TensorFlow 的官方文档中查看（&lt;a href=&quot;https://www.tensorflow.org/get_started/premade_estimators&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Premade Estimators&lt;/a&gt;），我也提供了一份示例代码，托管在 GitHub 上（&lt;a href=&quot;https://github.com/jizhang/tf-serve/blob/master/iris_dnn.py&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;code&gt;iris_dnn.py&lt;/code&gt;&lt;/a&gt;），读者可以克隆到本地进行测试。以下是部分代码摘要：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;feature_columns = [tf.feature_column.numeric_column(key=key)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                   &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; key &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; train_x.keys()]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;classifier = tf.estimator.DNNClassifier(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    feature_columns=feature_columns,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    hidden_units=[&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    n_classes=&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;classifier.train(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    input_fn=&lt;span class=&quot;keyword&quot;&gt;lambda&lt;/span&gt;: train_input_fn(train_x, train_y, batch_size=BATCH_SIZE),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    steps=STEPS)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;predictions = classifier.predict(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    input_fn=&lt;span class=&quot;keyword&quot;&gt;lambda&lt;/span&gt;: eval_input_fn(predict_x, labels=&lt;span class=&quot;keyword&quot;&gt;None&lt;/span&gt;, batch_size=BATCH_SIZE))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/cnblogs/categories/Programming/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/cnblogs/tags/python/"/>
    
      <category term="machine learning" scheme="http://shzhangji.com/cnblogs/tags/machine-learning/"/>
    
      <category term="tensorflow" scheme="http://shzhangji.com/cnblogs/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>使用 Python 和 Thrift 连接 HBase</title>
    <link href="http://shzhangji.com/cnblogs/2018/04/22/connect-hbase-with-python-and-thrift/"/>
    <id>http://shzhangji.com/cnblogs/2018/04/22/connect-hbase-with-python-and-thrift/</id>
    <published>2018-04-22T12:36:08.000Z</published>
    <updated>2018-04-23T00:42:36.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://hbase.apache.org/" target="_blank" rel="noopener">Apache HBase</a> 是 Hadoop 生态环境中的键值存储系统（Key-value Store）。它构建在 HDFS 之上，可以对大型数据进行高速的读写操作。HBase 的开发语言是 Java，因此提供了原生的 Java 语言客户端。不过，借助于 Thrift 和其丰富的语言扩展，我们可以十分便捷地在任何地方调用 HBase 服务。文本将讲述的就是如何使用 Thrift 和 Python 来读写 HBase。</p><p><img src="/cnblogs/images/hbase.png" alt=""></p><h2 id="生成-Thrift-类定义"><a href="#生成-Thrift-类定义" class="headerlink" title="生成 Thrift 类定义"></a>生成 Thrift 类定义</h2><p>如果你对 <a href="https://thrift.apache.org/" target="_blank" rel="noopener">Apache Thrift</a> 并不熟悉，它提供了一套 IDL（接口描述语言），用于定义远程服务的方法签名和数据类型，并能将其转换成所需要的目标语言。举例来说，以下是用该 IDL 定义的一个数据结构：</p><figure class="highlight thrift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">struct TColumn &#123;</span><br><span class="line">  1: required binary family,</span><br><span class="line">  2: optional binary qualifier,</span><br><span class="line">  3: optional i64 timestamp</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>转换后的 Python 代码是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TColumn</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, family=None, qualifier=None, timestamp=None,)</span>:</span></span><br><span class="line">        self.family = family</span><br><span class="line">        self.qualifier = qualifier</span><br><span class="line">        self.timestamp = timestamp</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read</span><span class="params">(self, iprot)</span>:</span></span><br><span class="line">        iprot.readStructBegin()</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            (fname, ftype, fid) = iprot.readFieldBegin()</span><br><span class="line">            <span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">write</span><span class="params">(self, oprot)</span>:</span></span><br><span class="line">        oprot.writeStructBegin(<span class="string">'TColumn'</span>)</span><br><span class="line">        <span class="comment"># ...</span></span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="HBase-Thrift-vs-Thrift2"><a href="#HBase-Thrift-vs-Thrift2" class="headerlink" title="HBase Thrift vs Thrift2"></a>HBase Thrift vs Thrift2</h3><p>HBase 提供了 <a href="https://github.com/apache/hbase/tree/master/hbase-thrift/src/main/resources/org/apache/hadoop/hbase" target="_blank" rel="noopener">两个版本</a> 的 IDL 文件，它们有以下两个不同点：</p><p>首先，<code>thrift2</code> 模仿了 HBase Java API 的数据类型和方法定义，调用方式更人性化一些。比如，构建一个 <code>Get</code> 操作的 Java 代码是：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Get get = <span class="keyword">new</span> Get(Bytes.toBytes(<span class="string">"rowkey"</span>));</span><br><span class="line">get.addColumn(Bytes.toBytes(<span class="string">"cf"</span>), Bytes.toBytes(<span class="string">"col1"</span>));</span><br><span class="line">get.addColumn(Bytes.toBytes(<span class="string">"cf"</span>), Bytes.toBytes(<span class="string">"col2"</span>));</span><br></pre></td></tr></table></figure><p>在 <code>thrift2</code> 中有对应的 <code>TGet</code> 类型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tget = TGet(</span><br><span class="line">    row=<span class="string">'rowkey'</span>,</span><br><span class="line">    columns=[</span><br><span class="line">        TColumn(family=<span class="string">'cf'</span>, qualifier=<span class="string">'col1'</span>),</span><br><span class="line">        TColumn(family=<span class="string">'cf'</span>, qualifier=<span class="string">'col2'</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>如果使用旧版的 <code>thrift</code>，我们就需要直接调用其众多的 <code>get</code> 方法之一了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">client.getRowWithColumns(</span><br><span class="line">    tableName=<span class="string">'tbl'</span>,</span><br><span class="line">    row=<span class="string">'rowkey'</span>,</span><br><span class="line">    columns=[<span class="string">'cf:col1'</span>, <span class="string">'cf:col2'</span>],</span><br><span class="line">    attributes=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>第二个不同点在于 <code>thrift2</code> 目前尚缺少 HBase 管理相关的接口，如 <code>createTable</code>、<code>majorCompact</code> 等。这些 API 仍在开发过程中，因此如果你需要通过 Thrift 来建表或维护 HBase，就只能使用旧版的 <code>thrift</code> 了。</p><p>决定了使用哪个版本的描述文件后，我们就可以将 <code>hbase.thrift</code> 下载到本地，通过它来生成 Python 代码。对于 Apache Thrift 本身的版本这里还要强调一点：由于我们使用的是 Python 3.x，而 Thrift 从 0.10 版本才开始支持，因此请确认自己安装了正确的版本。执行以下命令，我们就可以得到一组 Python 文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ thrift -gen py hbase.thrift</span><br><span class="line">$ find gen-py</span><br><span class="line">gen-py/hbase/__init__.py</span><br><span class="line">gen-py/hbase/constants.py</span><br><span class="line">gen-py/hbase/THBaseService.py</span><br><span class="line">gen-py/hbase/ttypes.py</span><br></pre></td></tr></table></figure><h2 id="在单机模式下运行-HBase"><a href="#在单机模式下运行-HBase" class="headerlink" title="在单机模式下运行 HBase"></a>在单机模式下运行 HBase</h2><p>如果你手边没有可供测试的 HBase 服务，可以根据官网上的快速开始指引（<a href="https://hbase.apache.org/book.html#quickstart" target="_blank" rel="noopener">链接</a>），下载 HBase 二进制包，做一下简单的配合，并执行下列命令来启动 HBase 服务及 Thrift2 Server。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/start-hbase.sh</span><br><span class="line">bin/hbase-daemon.sh start thrift2</span><br><span class="line">bin/hbase shell</span><br></pre></td></tr></table></figure><p>进入 HBase 命令行后，我们可以创建一个测试表，并尝试读写数据：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; create <span class="string">"tsdata"</span>, NAME =&gt; <span class="string">"cf"</span></span><br><span class="line">&gt; put <span class="string">"tsdata"</span>, <span class="string">"sys.cpu.user:20180421:192.168.1.1"</span>, <span class="string">"cf:1015"</span>, <span class="string">"0.28"</span></span><br><span class="line">&gt; get <span class="string">"tsdata"</span>, <span class="string">"sys.cpu.user:20180421:192.168.1.1"</span></span><br><span class="line">COLUMN                                        CELL</span><br><span class="line"> <span class="symbol">cf:</span><span class="number">1015</span>                                      timestamp=<span class="number">1524277135973</span>, value=<span class="number">0</span>.<span class="number">28</span></span><br><span class="line"><span class="number">1</span> row(s) <span class="keyword">in</span> <span class="number">0</span>.<span class="number">0330</span> seconds</span><br></pre></td></tr></table></figure><h2 id="通过-Thrift2-Server-连接-HBase"><a href="#通过-Thrift2-Server-连接-HBase" class="headerlink" title="通过 Thrift2 Server 连接 HBase"></a>通过 Thrift2 Server 连接 HBase</h2><p>以下是创建 Thrift 连接的样板代码。需要注意的是，Thrift 客户端并不是线程安全的，因此无法在多个线程间共享。而且，它也没有提供类似连接池的特性。通常我们会选择每次查询都创建新的连接，当然你也可以引入自己的连接池机制。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> thrift.transport <span class="keyword">import</span> TSocket</span><br><span class="line"><span class="keyword">from</span> thrift.protocol <span class="keyword">import</span> TBinaryProtocol</span><br><span class="line"><span class="keyword">from</span> thrift.transport <span class="keyword">import</span> TTransport</span><br><span class="line"><span class="keyword">from</span> hbase <span class="keyword">import</span> THBaseService</span><br><span class="line"></span><br><span class="line">transport = TTransport.TBufferedTransport(TSocket.TSocket(<span class="string">'127.0.0.1'</span>, <span class="number">9090</span>))</span><br><span class="line">protocol = TBinaryProtocol.TBinaryProtocolAccelerated(transport)</span><br><span class="line">client = THBaseService.Client(protocol)</span><br><span class="line">transport.open()</span><br><span class="line"><span class="comment"># 使用 client 实例进行操作</span></span><br><span class="line">transport.close()</span><br></pre></td></tr></table></figure><p>我们来尝试编写几个基本的读写操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> hbase.ttypes <span class="keyword">import</span> TPut, TColumnValue, TGet</span><br><span class="line">tput = TPut(</span><br><span class="line">    row=<span class="string">'sys.cpu.user:20180421:192.168.1.1'</span>,</span><br><span class="line">    columnValues=[</span><br><span class="line">        TColumnValue(family=<span class="string">'cf'</span>, qualifier=<span class="string">'1015'</span>, value=<span class="string">'0.28'</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line">client.put(<span class="string">'tsdata'</span>, tput)</span><br><span class="line"></span><br><span class="line">tget = TGet(row=<span class="string">'sys.cpu.user:20180421:192.168.1.1'</span>)</span><br><span class="line">tresult = client.get(<span class="string">'tsdata'</span>, tget)</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tresult.columnValues:</span><br><span class="line">    print(col.qualifier, <span class="string">'='</span>, col.value)</span><br></pre></td></tr></table></figure><h2 id="Thrift2-数据类型和方法一览"><a href="#Thrift2-数据类型和方法一览" class="headerlink" title="Thrift2 数据类型和方法一览"></a>Thrift2 数据类型和方法一览</h2><p>完整的方法列表可以直接查阅 <code>hbase.thrift</code> 和 <code>hbase/THBaseService.py</code> 这两个文件。下面是对常用方法的总结：</p><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><table><thead><tr><th>类名</th><th>描述</th><th>示例</th></tr></thead><tbody><tr><td>TColumn</td><td>表示一个列族或单个列。</td><td>TColumn(family=’cf’, qualifier=’gender’)</td></tr><tr><td>TColumnValue</td><td>列名及其包含的值。</td><td>TColumnValue(family=’cf’, qualifier=’gender’, value=’male’)</td></tr><tr><td>TResult</td><td>查询结果（一行）。若 <code>row</code> 属性的值为 <code>None</code>，则表示查无结果。</td><td>TResult(row=’employee_001’, columnValues=[TColumnValue])</td></tr><tr><td>TGet</td><td>查询单行。</td><td>TGet(row=’employee_001’, columns=[TColumn])</td></tr><tr><td>TPut</td><td>修改一行数据.</td><td>TPut(row=’employee_001’, columnValues=[TColumnValue])</td></tr><tr><td>TDelete</td><td>删除整行或部分列。</td><td>TDelete(row=’employee_001’, columns=[TColumn])</td></tr><tr><td>TScan</td><td>扫描多行数据。</td><td>见下文</td></tr></tbody></table><h3 id="THBaseService-类方法"><a href="#THBaseService-类方法" class="headerlink" title="THBaseService 类方法"></a>THBaseService 类方法</h3><table><thead><tr><th>方法签名</th><th>描述</th></tr></thead><tbody><tr><td>get(table: str, tget: TGet) -&gt; TResult</td><td>查询单行。</td></tr><tr><td>getMultiple(table: str, tgets: List[TGet]) -&gt; List[TResult]</td><td>查询多行。</td></tr><tr><td>put(table: str, tput: TPut) -&gt; None</td><td>修改单行。</td></tr><tr><td>putMultiple(table: str, tputs: List[TPut]) -&gt; None</td><td>修改多行。</td></tr><tr><td>deleteSingle(table: str, tdelete: TDelete) -&gt; None</td><td>删除单行。</td></tr><tr><td>deleteMultiple(table: str, tdeletes: List[TDelete]) -&gt; None</td><td>删除多行。</td></tr><tr><td>openScanner(table: str, tscan: TScan) -&gt; int</td><td>打开一个扫描器，返回其唯一标识。</td></tr><tr><td>getScannerRows(scannerId: int, numRows: int) -&gt; List[TResult]</td><td>返回扫描结果。</td></tr><tr><td>closeScanner(scannerId: int) -&gt; None</td><td>关闭扫描器。</td></tr><tr><td>getScannerResults(table: str, tscan: TScan, numRows: int) -&gt; List[TResult]</td><td>直接获取扫描结果的快捷方法。</td></tr></tbody></table><h3 id="Scan-操作示例"><a href="#Scan-操作示例" class="headerlink" title="Scan 操作示例"></a>Scan 操作示例</h3><p>我在 GitHub（<a href="https://github.com/jizhang/python-hbase" target="_blank" rel="noopener">链接</a>）上放置了一些样例代码，以下是 <code>Scan</code> 操作的样例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">scanner_id = client.openScanner(</span><br><span class="line">    table=<span class="string">'tsdata'</span>,</span><br><span class="line">    tscan=TScan(</span><br><span class="line">        startRow=<span class="string">'sys.cpu.user:20180421'</span>,</span><br><span class="line">        stopRow=<span class="string">'sys.cpu.user:20180422'</span>,</span><br><span class="line">        columns=[TColumn(<span class="string">'cf'</span>, <span class="string">'1015'</span>)]</span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    num_rows = <span class="number">10</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        tresults = client.getScannerRows(scanner_id, num_rows)</span><br><span class="line">        <span class="keyword">for</span> tresult <span class="keyword">in</span> tresults:</span><br><span class="line">            print(tresult)</span><br><span class="line">        <span class="keyword">if</span> len(tresults) &lt; num_rows:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    client.closeScanner(scanner_id)</span><br></pre></td></tr></table></figure><h2 id="Thrift-Server-高可用"><a href="#Thrift-Server-高可用" class="headerlink" title="Thrift Server 高可用"></a>Thrift Server 高可用</h2><p>Thrift Server 的单点问题有几种解决方案：</p><ol><li>在客户端中配置多个 Thrift Server 地址，发送请求时随机选择一个，并做好错误重试；</li><li>搭建代理，对 TCP 连接做负载均衡；</li><li>在客户端服务器上配置独立的 Thrift Server，每个客户端直接创建本地连接。</li></ol><p>通常我们会选择第二种方案，这就需要和运维工程师一起配合搭建了。</p><p><img src="/cnblogs/images/hbase-thrift-ha.png" alt=""></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://blog.cloudera.com/blog/2013/09/how-to-use-the-hbase-thrift-interface-part-1/" target="_blank" rel="noopener">https://blog.cloudera.com/blog/2013/09/how-to-use-the-hbase-thrift-interface-part-1/</a></li><li><a href="https://thrift.apache.org/tutorial/py" target="_blank" rel="noopener">https://thrift.apache.org/tutorial/py</a></li><li><a href="https://yq.aliyun.com/articles/88299" target="_blank" rel="noopener">https://yq.aliyun.com/articles/88299</a></li><li><a href="http://opentsdb.net/docs/build/html/user_guide/backends/hbase.html" target="_blank" rel="noopener">http://opentsdb.net/docs/build/html/user_guide/backends/hbase.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://hbase.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Apache HBase&lt;/a&gt; 是 Hadoop 生态环境中的键值存储系统（Key-value Store）。它构建在 HDFS 之上，可以对大型数据进行高速的读写操作。HBase 的开发语言是 Java，因此提供了原生的 Java 语言客户端。不过，借助于 Thrift 和其丰富的语言扩展，我们可以十分便捷地在任何地方调用 HBase 服务。文本将讲述的就是如何使用 Thrift 和 Python 来读写 HBase。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/cnblogs/images/hbase.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;生成-Thrift-类定义&quot;&gt;&lt;a href=&quot;#生成-Thrift-类定义&quot; class=&quot;headerlink&quot; title=&quot;生成 Thrift 类定义&quot;&gt;&lt;/a&gt;生成 Thrift 类定义&lt;/h2&gt;&lt;p&gt;如果你对 &lt;a href=&quot;https://thrift.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Apache Thrift&lt;/a&gt; 并不熟悉，它提供了一套 IDL（接口描述语言），用于定义远程服务的方法签名和数据类型，并能将其转换成所需要的目标语言。举例来说，以下是用该 IDL 定义的一个数据结构：&lt;/p&gt;
&lt;figure class=&quot;highlight thrift&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;struct TColumn &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  1: required binary family,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  2: optional binary qualifier,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  3: optional i64 timestamp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;转换后的 Python 代码是：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;TColumn&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(object)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, family=None, qualifier=None, timestamp=None,)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.family = family&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.qualifier = qualifier&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.timestamp = timestamp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, iprot)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        iprot.readStructBegin()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;True&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            (fname, ftype, fid) = iprot.readFieldBegin()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;comment&quot;&gt;# ...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, oprot)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        oprot.writeStructBegin(&lt;span class=&quot;string&quot;&gt;&#39;TColumn&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;# ...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/cnblogs/categories/Big-Data/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/cnblogs/tags/python/"/>
    
      <category term="hbase" scheme="http://shzhangji.com/cnblogs/tags/hbase/"/>
    
      <category term="thrift" scheme="http://shzhangji.com/cnblogs/tags/thrift/"/>
    
  </entry>
  
  <entry>
    <title>Vuex 严格模式下的表单处理</title>
    <link href="http://shzhangji.com/cnblogs/2018/04/18/form-handling-in-vuex-strict-mode/"/>
    <id>http://shzhangji.com/cnblogs/2018/04/18/form-handling-in-vuex-strict-mode/</id>
    <published>2018-04-18T01:08:41.000Z</published>
    <updated>2018-04-18T01:08:41.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/cnblogs/images/vue.png" alt=""></p><p>在使用 Vue 进行表单处理时，我们通常会使用 <code>v-model</code> 来建立双向绑定。但是，如果将表单数据交由 Vuex 管理，这时的双向绑定就会引发问题，因为在 <strong>严格模式</strong> 下，Vuex 是不允许在 Mutation 之外的地方修改状态数据的。以下用一个简单的项目举例说明，完整代码可在 GitHub（<a href="https://github.com/jizhang/vuex-form" target="_blank" rel="noopener">链接</a>） 查看。</p><p><code>src/store/table.js</code></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span><br><span class="line">  state: &#123;</span><br><span class="line">    namespaced: <span class="literal">true</span>,</span><br><span class="line">    table: &#123;</span><br><span class="line">      table_name: <span class="string">''</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>src/components/NonStrict.vue</code></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">b-form-group</span> <span class="attr">label</span>=<span class="string">"表名："</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">b-form-input</span> <span class="attr">v-model</span>=<span class="string">"table.table_name"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">b-form-group</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="keyword">import</span> &#123; mapState &#125; <span class="keyword">from</span> <span class="string">'vuex'</span></span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="undefined">  computed: &#123;</span></span><br><span class="line"><span class="javascript">    ...mapState(<span class="string">'table'</span>, [</span></span><br><span class="line"><span class="javascript">      <span class="string">'table'</span></span></span><br><span class="line"><span class="undefined">    ])</span></span><br><span class="line"><span class="undefined">  &#125;</span></span><br><span class="line"><span class="undefined">&#125;</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>当我们在“表名”字段输入文字时，浏览器会报以下错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">错误：[vuex] 禁止在 Mutation 之外修改 Vuex 状态数据。</span><br><span class="line">    at assert (vuex.esm.js?358c:97)</span><br><span class="line">    at Vue.store._vm.$watch.deep (vuex.esm.js?358c:746)</span><br><span class="line">    at Watcher.run (vue.esm.js?efeb:3233)</span><br></pre></td></tr></table></figure><p>当然，我们可以选择不开启严格模式，只是这样就无法通过工具追踪到每一次的状态变动了。下面我将列举几种解决方案，描述如何在严格模式下进行表单处理。</p><a id="more"></a><h2 id="将状态复制到组件中"><a href="#将状态复制到组件中" class="headerlink" title="将状态复制到组件中"></a>将状态复制到组件中</h2><p>第一种方案是直接将 Vuex 中的表单数据复制到本地的组件状态中，并在表单和本地状态间建立双向绑定。当用户提交表单时，再将本地数据提交到 Vuex 状态库中。</p><p><code>src/components/LocalCopy.vue</code></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">b-form-input</span> <span class="attr">v-model</span>=<span class="string">"table.table_name"</span> /&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="keyword">import</span> _ <span class="keyword">from</span> <span class="string">'lodash'</span></span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="undefined">  data () &#123;</span></span><br><span class="line"><span class="javascript">    <span class="keyword">return</span> &#123;</span></span><br><span class="line"><span class="javascript">      table: _.cloneDeep(<span class="keyword">this</span>.$store.state.table.table)</span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="undefined">  &#125;,</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">  methods: &#123;</span></span><br><span class="line"><span class="undefined">    handleSubmit (event) &#123;</span></span><br><span class="line"><span class="javascript">      <span class="keyword">this</span>.$store.commit(<span class="string">'table/setTable'</span>, <span class="keyword">this</span>.table)</span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="undefined">  &#125;</span></span><br><span class="line"><span class="undefined">&#125;</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p><code>src/store/table.js</code></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span><br><span class="line">  mutations: &#123;</span><br><span class="line">    setTable (state, payload) &#123;</span><br><span class="line">      state.table = payload</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上方式有两个缺陷。其一，在提交状态更新后，若继续修改表单数据，同样会得到“禁止修改”的错误提示。这是因为 <code>setTable</code> 方法将本地状态对象直接传入了 Vuex，我们可以对该方法稍作修改：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">setTable (state, payload) &#123;</span><br><span class="line">  <span class="comment">// 将对象属性逐一赋值给 Vuex</span></span><br><span class="line">  _.assign(state.table, payload)</span><br><span class="line">  <span class="comment">// 或者，克隆整个对象</span></span><br><span class="line">  state.table = _.cloneDeep(payload)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第二个问题在于如果其他组件也向 Vuex 提交了数据变动（如弹出的对话框中包含了一个子表单），当前表单的数据不会得到更新。这时，我们就需要用到 Vue 的监听机制了：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="undefined">  data () &#123;</span></span><br><span class="line"><span class="javascript">    <span class="keyword">return</span> &#123;</span></span><br><span class="line"><span class="javascript">      table: _.cloneDeep(<span class="keyword">this</span>.$store.state.table.table)</span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="undefined">  &#125;,</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">  computed: &#123;</span></span><br><span class="line"><span class="undefined">    storeTable () &#123;</span></span><br><span class="line"><span class="javascript">      <span class="keyword">return</span> _.cloneDeep(<span class="keyword">this</span>.$store.state.table.table)</span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="undefined">  &#125;,</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">  watch: &#123;</span></span><br><span class="line"><span class="undefined">    storeTable (newValue) &#123;</span></span><br><span class="line"><span class="javascript">      <span class="keyword">this</span>.table = newValue</span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="undefined">  &#125;</span></span><br><span class="line"><span class="undefined">&#125;</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>这个方法还能同时规避第一个问题，因为每当 Vuex 数据更新，本地组件都会重新克隆一份数据。</p><h2 id="响应表单更新事件并提交数据"><a href="#响应表单更新事件并提交数据" class="headerlink" title="响应表单更新事件并提交数据"></a>响应表单更新事件并提交数据</h2><p>一种类似 ReactJS 的做法是，弃用 <code>v-model</code>，转而使用 <code>:value</code> 展示数据，再通过监听 <code>@input</code> 或 <code>@change</code> 事件来提交数据变更。这样就从双向绑定转换为了单向数据流，Vuex 状态库自此成为整个应用程序的唯一数据源（Single Source of Truth）。</p><p><code>src/components/ExplicitUpdate.vue</code></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">b-form-input</span> <span class="attr">:value</span>=<span class="string">"table.table_name"</span> @<span class="attr">input</span>=<span class="string">"updateTableForm(&#123; table_name: $event &#125;)"</span> /&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="undefined">  computed: &#123;</span></span><br><span class="line"><span class="javascript">    ...mapState(<span class="string">'table'</span>, [</span></span><br><span class="line"><span class="javascript">      <span class="string">'table'</span></span></span><br><span class="line"><span class="undefined">    ])</span></span><br><span class="line"><span class="undefined">  &#125;,</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">  methods: &#123;</span></span><br><span class="line"><span class="javascript">    ...mapMutations(<span class="string">'table'</span>, [</span></span><br><span class="line"><span class="javascript">      <span class="string">'updateTableForm'</span></span></span><br><span class="line"><span class="undefined">    ])</span></span><br><span class="line"><span class="undefined">  &#125;</span></span><br><span class="line"><span class="undefined">&#125;</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p><code>src/store/table.js</code></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> table &#123;</span><br><span class="line">  mutations: &#123;</span><br><span class="line">    updateTableForm (state, payload) &#123;</span><br><span class="line">      _.assign(state.table, payload)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上方法也是 <a href="https://vuex.vuejs.org/en/forms.html" target="_blank" rel="noopener">Vuex 文档</a> 所推崇的。而根据 <a href="https://vuejs.org/v2/guide/forms.html" target="_blank" rel="noopener">Vue 文档</a> 的介绍，<code>v-model</code> 本质上也是一个“监听 - 修改”流程的语法糖而已。</p><h2 id="使用-Vue-计算属性"><a href="#使用-Vue-计算属性" class="headerlink" title="使用 Vue 计算属性"></a>使用 Vue 计算属性</h2><p>Vue 的计算属性（Computed Property）可以配置双向的访问器（Getter / Setter），我们可以利用其建立起 Vuex 状态库和本地组件间的桥梁。其中一个限制在于计算属性无法支持嵌套属性（<code>table.table_name</code>），因此我们需要为这些属性设置别名。</p><p><code>src/components/ComputedProperty.vue</code></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">b-form-input</span> <span class="attr">v-model</span>=<span class="string">"tableName"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">b-form-select</span> <span class="attr">v-model</span>=<span class="string">"tableCategory"</span> /&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="undefined">  computed: &#123;</span></span><br><span class="line"><span class="undefined">    tableName: &#123;</span></span><br><span class="line"><span class="undefined">      get () &#123;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">return</span> <span class="keyword">this</span>.$store.state.table.table.table_name</span></span><br><span class="line"><span class="undefined">      &#125;,</span></span><br><span class="line"><span class="undefined">      set (value) &#123;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">this</span>.updateTableForm(&#123; <span class="attr">table_name</span>: value &#125;)</span></span><br><span class="line"><span class="undefined">      &#125;</span></span><br><span class="line"><span class="undefined">    &#125;,</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">    tableCategory: &#123;</span></span><br><span class="line"><span class="undefined">      get () &#123;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">return</span> <span class="keyword">this</span>.$store.state.table.table.category</span></span><br><span class="line"><span class="undefined">      &#125;,</span></span><br><span class="line"><span class="undefined">      set (value) &#123;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">this</span>.updateTableForm(&#123; <span class="attr">category</span>: value &#125;)</span></span><br><span class="line"><span class="undefined">      &#125;</span></span><br><span class="line"><span class="undefined">    &#125;,</span></span><br><span class="line"><span class="undefined">  &#125;,</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">  methods: &#123;</span></span><br><span class="line"><span class="javascript">    ...mapMutations(<span class="string">'table'</span>, [</span></span><br><span class="line"><span class="javascript">      <span class="string">'updateTableForm'</span></span></span><br><span class="line"><span class="undefined">    ])</span></span><br><span class="line"><span class="undefined">  &#125;</span></span><br><span class="line"><span class="undefined">&#125;</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>如果表单字段数目过多，全部列出不免有些繁琐，我们可以创建一些工具函数来实现。首先，在 Vuex 状态库中新增一个可修改任意属性的 Mutation，它接收一个 Lodash 风格的属性路径。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mutations: &#123;</span><br><span class="line">  myUpdateField (state, payload) &#123;</span><br><span class="line">    <span class="keyword">const</span> &#123; path, value &#125; = payload</span><br><span class="line">    _.set(state, path, value)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在组件中，我们将传入的“别名 - 路径”对转换成相应的 Getter / Setter 访问器。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> mapFields = <span class="function">(<span class="params">namespace, fields</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> _.mapValues(fields, path =&gt; &#123;</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">      get () &#123;</span><br><span class="line">        <span class="keyword">return</span> _.get(<span class="keyword">this</span>.$store.state[namespace], path)</span><br><span class="line">      &#125;,</span><br><span class="line">      set (value) &#123;</span><br><span class="line">        <span class="keyword">this</span>.$store.commit(<span class="string">`<span class="subst">$&#123;namespace&#125;</span>/myUpdateField`</span>, &#123; path, value &#125;)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span><br><span class="line">  computed: &#123;</span><br><span class="line">    ...mapFields(<span class="string">'table'</span>, &#123;</span><br><span class="line">      tableName: <span class="string">'table.table_name'</span>,</span><br><span class="line">      tableCategory: <span class="string">'table.category'</span>,</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>开源社区中已经有人建立了一个名为 <a href="https://github.com/maoberlehner/vuex-map-fields" target="_blank" rel="noopener">vuex-map-fields</a> 的项目，其 <code>mapFields</code> 方法就实现了上述功能。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://vuex.vuejs.org/en/forms.html" target="_blank" rel="noopener">https://vuex.vuejs.org/en/forms.html</a></li><li><a href="https://ypereirareis.github.io/blog/2017/04/25/vuejs-two-way-data-binding-state-management-vuex-strict-mode/" target="_blank" rel="noopener">https://ypereirareis.github.io/blog/2017/04/25/vuejs-two-way-data-binding-state-management-vuex-strict-mode/</a></li><li><a href="https://markus.oberlehner.net/blog/form-fields-two-way-data-binding-and-vuex/" target="_blank" rel="noopener">https://markus.oberlehner.net/blog/form-fields-two-way-data-binding-and-vuex/</a></li><li><a href="https://forum.vuejs.org/t/vuex-form-best-practices/20084" target="_blank" rel="noopener">https://forum.vuejs.org/t/vuex-form-best-practices/20084</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/cnblogs/images/vue.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在使用 Vue 进行表单处理时，我们通常会使用 &lt;code&gt;v-model&lt;/code&gt; 来建立双向绑定。但是，如果将表单数据交由 Vuex 管理，这时的双向绑定就会引发问题，因为在 &lt;strong&gt;严格模式&lt;/strong&gt; 下，Vuex 是不允许在 Mutation 之外的地方修改状态数据的。以下用一个简单的项目举例说明，完整代码可在 GitHub（&lt;a href=&quot;https://github.com/jizhang/vuex-form&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;链接&lt;/a&gt;） 查看。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;src/store/table.js&lt;/code&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight javascript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;default&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  state: &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    namespaced: &lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    table: &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      table_name: &lt;span class=&quot;string&quot;&gt;&#39;&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;src/components/NonStrict.vue&lt;/code&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight html&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;b-form-group&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;label&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;表名：&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;b-form-input&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;v-model&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;table.table_name&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;b-form-group&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;script&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;undefined&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; &amp;#123; mapState &amp;#125; &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;vuex&#39;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;undefined&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;default&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;undefined&quot;&gt;  computed: &amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;javascript&quot;&gt;    ...mapState(&lt;span class=&quot;string&quot;&gt;&#39;table&#39;&lt;/span&gt;, [&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;javascript&quot;&gt;      &lt;span class=&quot;string&quot;&gt;&#39;table&#39;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;undefined&quot;&gt;    ])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;undefined&quot;&gt;  &amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;undefined&quot;&gt;&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;undefined&quot;&gt;&lt;/span&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;script&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;当我们在“表名”字段输入文字时，浏览器会报以下错误：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;错误：[vuex] 禁止在 Mutation 之外修改 Vuex 状态数据。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    at assert (vuex.esm.js?358c:97)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    at Vue.store._vm.$watch.deep (vuex.esm.js?358c:746)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    at Watcher.run (vue.esm.js?efeb:3233)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;当然，我们可以选择不开启严格模式，只是这样就无法通过工具追踪到每一次的状态变动了。下面我将列举几种解决方案，描述如何在严格模式下进行表单处理。&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/cnblogs/categories/Programming/"/>
    
    
      <category term="javascript" scheme="http://shzhangji.com/cnblogs/tags/javascript/"/>
    
      <category term="frontend" scheme="http://shzhangji.com/cnblogs/tags/frontend/"/>
    
      <category term="vue" scheme="http://shzhangji.com/cnblogs/tags/vue/"/>
    
      <category term="vuex" scheme="http://shzhangji.com/cnblogs/tags/vuex/"/>
    
  </entry>
  
  <entry>
    <title>RESTful API 中的错误处理</title>
    <link href="http://shzhangji.com/cnblogs/2018/04/07/error-handling-in-restful-api/"/>
    <id>http://shzhangji.com/cnblogs/2018/04/07/error-handling-in-restful-api/</id>
    <published>2018-04-07T06:49:19.000Z</published>
    <updated>2018-05-15T01:01:21.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/cnblogs/images/restful-api.png" alt="RESTful API"></p><p>构建 Web 服务时，我们会使用 RESTful API 来实现组件间的通信，特别是在现今前后端分离的技术背景下。REST 是一种基于 HTTP 协议的通信方式，它简单、基于文本、且在各种语言、浏览器及客户端软件中能得到很好的支持。然而，REST 目前并没有一个普遍接受的标准，因此开发者需要自行决定 API 的设计，其中一项决策就是错误处理。比如我们是否应该使用 HTTP 状态码来标识错误？如何返回表单验证的结果等等。以下这篇文章是基于日常使用中的经验总结的一套错误处理流程，供读者们参考。</p><h2 id="错误的分类"><a href="#错误的分类" class="headerlink" title="错误的分类"></a>错误的分类</h2><p>错误可以分为两种类型：全局错误和本地错误。全局错误包括：请求了一个不存在的 API、无权请求这个 API、数据库连接失败、或其他一些没有预期到的、会终止程序运行的服务端错误。这类错误应该由 Web 框架捕获，无需各个 API 处理。</p><p>本地错误则和 API 密切相关，例如表单验证、唯一性检查、或其他可预期的错误。我们需要编写特定代码来捕获这类错误，并抛出一个包含提示信息的全局异常，供 Web 框架捕获并返回给客户端。</p><p>例如，Flask 框架就提供了此类全局异常处理机制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BadRequest</span><span class="params">(Exception)</span>:</span></span><br><span class="line">    <span class="string">"""将本地错误包装成一个异常实例供抛出"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, message, status=<span class="number">400</span>, payload=None)</span>:</span></span><br><span class="line">        self.message = message</span><br><span class="line">        self.status = status</span><br><span class="line">        self.payload = payload</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.errorhandler(BadRequest)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle_bad_request</span><span class="params">(error)</span>:</span></span><br><span class="line">    <span class="string">"""捕获 BadRequest 全局异常，序列化为 JSON 并返回 HTTP 400"""</span></span><br><span class="line">    payload = dict(error.payload <span class="keyword">or</span> ())</span><br><span class="line">    payload[<span class="string">'status'</span>] = error.status</span><br><span class="line">    payload[<span class="string">'message'</span>] = error.message</span><br><span class="line">    <span class="keyword">return</span> jsonify(payload), <span class="number">400</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/person', methods=['POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">person_post</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""创建用户的 API，成功则返回用户 ID"""</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> request.form.get(<span class="string">'username'</span>):</span><br><span class="line">        <span class="keyword">raise</span> BadRequest(<span class="string">'用户名不能为空'</span>, <span class="number">40001</span>, &#123; <span class="string">'ext'</span>: <span class="number">1</span> &#125;)</span><br><span class="line">    <span class="keyword">return</span> jsonify(last_insert_id=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="返回的错误内容"><a href="#返回的错误内容" class="headerlink" title="返回的错误内容"></a>返回的错误内容</h2><p>上例中，如果向 <code>/person</code> API 发送一个 <code>username</code> 为空的请求，会返回以下错误结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 400 Bad Request</span><br><span class="line">Content-Type: application/json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;status&quot;: 40001,</span><br><span class="line">  &quot;message&quot;: &quot;用户名不能为空&quot;,</span><br><span class="line">  &quot;ext&quot;: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>它包括以下几个部分：HTTP 状态码、自定义错误码、错误提示、以及额外信息。</p><h3 id="正确使用-HTTP-状态码"><a href="#正确使用-HTTP-状态码" class="headerlink" title="正确使用 HTTP 状态码"></a>正确使用 HTTP 状态码</h3><p>HTTP 协议中预定义了丰富的状态码，其中 <code>4xx</code> 表示客户端造成的异常，<code>5xx</code> 表示服务端产生的异常。以下是我们在 API 中经常用到的几种状态码：</p><ul><li><code>200</code> 响应结果正常；</li><li><code>400</code> 错误的请求，如用户提交了非法的数据；</li><li><code>401</code> 未授权的请求。在使用 <code>Flask-Login</code> 插件时，如果 API 的路由含有 <code>@login_required</code> 装饰器，当用户没有登录时就会返回这个错误码，而客户端通常会重定向到登录页面；</li><li><code>403</code> 禁止请求；</li><li><code>404</code> 请求的内容不存在；</li><li><code>500</code> 服务器内部错误，通常是未预期到的、不可恢复的服务端异常。</li></ul><h3 id="自定义错误码"><a href="#自定义错误码" class="headerlink" title="自定义错误码"></a>自定义错误码</h3><p>客户端接收到异常后，可以选择弹出一个全局的错误提示，告知用户请求异常；或者在发起 API 请求的方法内部进行处理，如将表单验证的错误提示展示到各个控件之后。为了实现这一点，我们需要给错误进行编码，如 <code>400</code> 表示通用的全局错误，可直接弹框提示；<code>40001</code>、<code>40002</code> 则表示这类错误需要单独做处理。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">fetch().then(<span class="function"><span class="params">response</span> =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (response.status == <span class="number">400</span>) &#123; <span class="comment">// HTTP 状态码</span></span><br><span class="line">    response.json().then(<span class="function"><span class="params">responseJson</span> =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (responseJson.status == <span class="number">400</span>) &#123; <span class="comment">// 自定义错误码</span></span><br><span class="line">        <span class="comment">// 全局错误处理</span></span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (responseJson.status == <span class="number">40001</span>) &#123; <span class="comment">// 自定义错误码</span></span><br><span class="line">        <span class="comment">// 自定义错误处理</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><h3 id="错误详情"><a href="#错误详情" class="headerlink" title="错误详情"></a>错误详情</h3><p>有时我们会将表单内所有字段的验证错误信息一并返回给客户端，这时就可以使用 <code>payload</code> 机制：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"status"</span>: <span class="number">40001</span>,</span><br><span class="line">  <span class="string">"message"</span>: <span class="string">"表单验证错误"</span></span><br><span class="line">  <span class="string">"errors"</span>: [</span><br><span class="line">    &#123; <span class="string">"name"</span>: <span class="string">"username"</span>, <span class="string">"error"</span>: <span class="string">"用户名不能为空"</span> &#125;,</span><br><span class="line">    &#123; <span class="string">"name"</span>: <span class="string">"password"</span>, <span class="string">"error"</span>: <span class="string">"密码不能少于 6 位"</span> &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Fetch-API"><a href="#Fetch-API" class="headerlink" title="Fetch API"></a>Fetch API</h2><p>对于 AJAX 请求，<a href="https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API" target="_blank" rel="noopener">Fetch API</a> 已经逐渐成为业界标准。我们可以将其包装成一个方法，对请求结果进行错误处理。完整的代码可以在 GitHub （<a href="https://github.com/jizhang/rest-error/blob/master/src/request.js" target="_blank" rel="noopener">链接</a>）中查看。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">request</span>(<span class="params">url, args, form</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> fetch(url, config)</span><br><span class="line">    .then(<span class="function"><span class="params">response</span> =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (response.ok) &#123;</span><br><span class="line">        <span class="keyword">return</span> response.json()</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (response.status === <span class="number">400</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> response.json()</span><br><span class="line">          .then(<span class="function"><span class="params">responseJson</span> =&gt;</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (responseJson.status === <span class="number">400</span>) &#123;</span><br><span class="line">              alert(responseJson.message) <span class="comment">// 全局错误处理</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 抛出异常，让 Promise 下游的 "catch()" 方法进行捕获</span></span><br><span class="line">            <span class="keyword">throw</span> responseJson</span><br><span class="line">          &#125;, error =&gt; &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RequestError(<span class="number">400</span>)</span><br><span class="line">          &#125;)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 处理预定义的 HTTP 错误码</span></span><br><span class="line">      <span class="keyword">switch</span> (response.status) &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">401</span>:</span><br><span class="line">          <span class="keyword">break</span> <span class="comment">// 重定向至登录页面</span></span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">          alert(<span class="string">'HTTP Status Code '</span> + response.status)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> RequestError(response.status)</span><br><span class="line">    &#125;, error =&gt; &#123;</span><br><span class="line">      alert(error.message)</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> RequestError(<span class="number">0</span>, error.message)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，异常发生后，该函数会拒绝（reject）这个 Promise，从而由调用方进一步判断 <code>status</code> 来决定处理方式。以下是使用 MobX + ReactJS 实现的自定义错误处理流程：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MobX Store</span></span><br><span class="line">loginUser = flow(<span class="function"><span class="keyword">function</span>* <span class="title">loginUser</span>(<span class="params">form</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.loading = <span class="literal">true</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// yield 语句可能会抛出异常，即拒绝当前的 Promise</span></span><br><span class="line">    <span class="keyword">this</span>.userId = <span class="keyword">yield</span> request(<span class="string">'/login'</span>, <span class="literal">null</span>, form)</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">this</span>.loading = <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// React Component</span></span><br><span class="line">login = <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">  userStore.loginUser(<span class="keyword">this</span>.state.form)</span><br><span class="line">    .catch(<span class="function"><span class="params">error</span> =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (error.status === <span class="number">40001</span>) &#123;</span><br><span class="line">        <span class="comment">// 自定义错误处理</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://en.wikipedia.org/wiki/Representational_state_transfer" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Representational_state_transfer</a></li><li><a href="https://alidg.me/blog/2016/9/24/rest-api-error-handling" target="_blank" rel="noopener">https://alidg.me/blog/2016/9/24/rest-api-error-handling</a></li><li><a href="https://www.wptutor.io/web/js/generators-coroutines-async-javascript" target="_blank" rel="noopener">https://www.wptutor.io/web/js/generators-coroutines-async-javascript</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/cnblogs/images/restful-api.png&quot; alt=&quot;RESTful API&quot;&gt;&lt;/p&gt;
&lt;p&gt;构建 Web 服务时，我们会使用 RESTful API 来实现组件间的通信，特别是在现今前后端分离的技术背景下。REST 是一种基于 HTTP 协议的通信方式，它简单、基于文本、且在各种语言、浏览器及客户端软件中能得到很好的支持。然而，REST 目前并没有一个普遍接受的标准，因此开发者需要自行决定 API 的设计，其中一项决策就是错误处理。比如我们是否应该使用 HTTP 状态码来标识错误？如何返回表单验证的结果等等。以下这篇文章是基于日常使用中的经验总结的一套错误处理流程，供读者们参考。&lt;/p&gt;
&lt;h2 id=&quot;错误的分类&quot;&gt;&lt;a href=&quot;#错误的分类&quot; class=&quot;headerlink&quot; title=&quot;错误的分类&quot;&gt;&lt;/a&gt;错误的分类&lt;/h2&gt;&lt;p&gt;错误可以分为两种类型：全局错误和本地错误。全局错误包括：请求了一个不存在的 API、无权请求这个 API、数据库连接失败、或其他一些没有预期到的、会终止程序运行的服务端错误。这类错误应该由 Web 框架捕获，无需各个 API 处理。&lt;/p&gt;
&lt;p&gt;本地错误则和 API 密切相关，例如表单验证、唯一性检查、或其他可预期的错误。我们需要编写特定代码来捕获这类错误，并抛出一个包含提示信息的全局异常，供 Web 框架捕获并返回给客户端。&lt;/p&gt;
&lt;p&gt;例如，Flask 框架就提供了此类全局异常处理机制：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;BadRequest&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(Exception)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&quot;&quot;&quot;将本地错误包装成一个异常实例供抛出&quot;&quot;&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, message, status=&lt;span class=&quot;number&quot;&gt;400&lt;/span&gt;, payload=None)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.message = message&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.status = status&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.payload = payload&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;@app.errorhandler(BadRequest)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;handle_bad_request&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(error)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&quot;&quot;&quot;捕获 BadRequest 全局异常，序列化为 JSON 并返回 HTTP 400&quot;&quot;&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    payload = dict(error.payload &lt;span class=&quot;keyword&quot;&gt;or&lt;/span&gt; ())&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    payload[&lt;span class=&quot;string&quot;&gt;&#39;status&#39;&lt;/span&gt;] = error.status&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    payload[&lt;span class=&quot;string&quot;&gt;&#39;message&#39;&lt;/span&gt;] = error.message&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; jsonify(payload), &lt;span class=&quot;number&quot;&gt;400&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;@app.route(&#39;/person&#39;, methods=[&#39;POST&#39;])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;person_post&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&quot;&quot;&quot;创建用户的 API，成功则返回用户 ID&quot;&quot;&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;not&lt;/span&gt; request.form.get(&lt;span class=&quot;string&quot;&gt;&#39;username&#39;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;raise&lt;/span&gt; BadRequest(&lt;span class=&quot;string&quot;&gt;&#39;用户名不能为空&#39;&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;40001&lt;/span&gt;, &amp;#123; &lt;span class=&quot;string&quot;&gt;&#39;ext&#39;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; &amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; jsonify(last_insert_id=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/cnblogs/categories/Programming/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/cnblogs/tags/python/"/>
    
      <category term="javascript" scheme="http://shzhangji.com/cnblogs/tags/javascript/"/>
    
      <category term="frontend" scheme="http://shzhangji.com/cnblogs/tags/frontend/"/>
    
      <category term="restful" scheme="http://shzhangji.com/cnblogs/tags/restful/"/>
    
  </entry>
  
  <entry>
    <title>Flume 源码解析：组件生命周期</title>
    <link href="http://shzhangji.com/cnblogs/2017/10/24/flume-source-code-component-lifecycle/"/>
    <id>http://shzhangji.com/cnblogs/2017/10/24/flume-source-code-component-lifecycle/</id>
    <published>2017-10-24T01:18:26.000Z</published>
    <updated>2017-10-24T01:18:26.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://flume.apache.org/" target="_blank" rel="noopener">Apache Flume</a> 是数据仓库体系中用于做实时 ETL 的工具。它提供了丰富的数据源和写入组件，这些组件在运行时都由 Flume 的生命周期管理机制进行监控和维护。本文将对这部分功能的源码进行解析。</p><h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><p>Flume 的源码可以从 GitHub 上下载。它是一个 Maven 项目，我们将其导入到 IDE 中以便更好地进行源码阅读。以下是代码仓库的基本结构：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/flume-ng-node</span><br><span class="line">/flume-ng-code</span><br><span class="line">/flume-ng-sdk</span><br><span class="line">/flume-ng-sources/flume-kafka-source</span><br><span class="line">/flume-ng-channels/flume-kafka-channel</span><br><span class="line">/flume-ng-sinks/flume-hdfs-sink</span><br></pre></td></tr></table></figure><h2 id="程序入口"><a href="#程序入口" class="headerlink" title="程序入口"></a>程序入口</h2><p>Flume Agent 的入口 <code>main</code> 函数位于 <code>flume-ng-node</code> 模块的 <code>org.apache.flume.node.Application</code> 类中。下列代码是该函数的摘要：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Application</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    CommandLineParser parser = <span class="keyword">new</span> GnuParser();</span><br><span class="line">    <span class="keyword">if</span> (isZkConfigured) &#123;</span><br><span class="line">      <span class="keyword">if</span> (reload) &#123;</span><br><span class="line">        PollingZooKeeperConfigurationProvider zookeeperConfigurationProvider;</span><br><span class="line">        components.add(zookeeperConfigurationProvider);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        StaticZooKeeperConfigurationProvider zookeeperConfigurationProvider;</span><br><span class="line">        application.handleConfigurationEvent();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// PropertiesFileConfigurationProvider</span></span><br><span class="line">    &#125;</span><br><span class="line">    application.start();</span><br><span class="line">    Runtime.getRuntime().addShutdownHook(<span class="keyword">new</span> Thread(<span class="string">"agent-shutdown-hook"</span>) &#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        appReference.stop();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动过程说明如下：</p><ol><li>使用 <code>commons-cli</code> 对命令行参数进行解析，提取 Agent 名称、配置信息读取方式及其路径信息；</li><li>配置信息可以通过文件或 ZooKeeper 的方式进行读取，两种方式都支持热加载，即我们不需要重启 Agent 就可以更新配置内容：<ul><li>基于文件的配置热加载是通过一个后台线程对文件进行轮询实现的；</li><li>基于 ZooKeeper 的热加载则是使用了 Curator 的 <code>NodeCache</code> 模式，底层是 ZooKeeper 原生的监听（Watch）特性。</li></ul></li><li>如果配置热更新是开启的（默认开启），配置提供方 <code>ConfigurationProvider</code> 就会将自身注册到 Agent 程序的组件列表中，并在 <code>Application#start</code> 方法调用后，由 <code>LifecycleSupervisor</code> 类进行启动和管理，加载和解析配置文件，从中读取组件列表。</li><li>如果热更新未开启，则配置提供方将在启动时立刻读取配置文件，并由 <code>LifecycleSupervisor</code> 启动和管理所有组件。</li><li>最后，<code>main</code> 会调用 <code>Runtime#addShutdownHook</code>，当 JVM 关闭时（SIGTERM 或者 Ctrl+C），<code>Application#stop</code> 会被用于关闭 Flume Agent，使各组件优雅退出。</li></ol><a id="more"></a><h2 id="配置重载"><a href="#配置重载" class="headerlink" title="配置重载"></a>配置重载</h2><p>在 <code>PollingPropertiesFileConfigurationProvider</code> 类中，当文件内容更新时，它会调用父类的 <code>AbstractConfigurationProvider#getConfiguration</code> 方法，将配置内容解析成 <code>MaterializedConfiguration</code> 实例，这个对象实例中包含了数据源（Source）、目的地（Sink）、以及管道（Channel）组件的所有信息。随后，这个轮询线程会通过 Guava 的 <code>EventBus</code> 机制通知 <code>Application</code> 类配置发生了更新，从而触发 <code>Application#handleConfigurationEvent</code> 方法，重新加载所有的组件。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Application 类</span></span><br><span class="line"><span class="meta">@Subscribe</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">handleConfigurationEvent</span><span class="params">(MaterializedConfiguration conf)</span> </span>&#123;</span><br><span class="line">  stopAllComponents();</span><br><span class="line">  startAllComponents(conf);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// PollingPropertiesFileConfigurationProvider$FileWatcherRunnable 内部类</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  eventBus.post(getConfiguration());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="启动组件"><a href="#启动组件" class="headerlink" title="启动组件"></a>启动组件</h2><p>组件启动的流程位于 <code>Application#startAllComponents</code> 方法中。这个方法接收到新的组件信息后，首先将启动所有的 <code>Channel</code>，然后启动 <code>Sink</code> 和 <code>Source</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">startAllComponents</span><span class="params">(MaterializedConfiguration materializedConfiguration)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.materializedConfiguration = materializedConfiguration;</span><br><span class="line">  <span class="keyword">for</span> (Entry&lt;String, Channel&gt; entry :</span><br><span class="line">      materializedConfiguration.getChannels().entrySet()) &#123;</span><br><span class="line">    supervisor.supervise(entry.getValue(),</span><br><span class="line">        <span class="keyword">new</span> SupervisorPolicy.AlwaysRestartPolicy(), LifecycleState.START);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//  等待所有管道启动完毕</span></span><br><span class="line">  <span class="keyword">for</span> (Channel ch : materializedConfiguration.getChannels().values()) &#123;</span><br><span class="line">    <span class="keyword">while</span> (ch.getLifecycleState() != LifecycleState.START</span><br><span class="line">        &amp;&amp; !supervisor.isComponentInErrorState(ch)) &#123;</span><br><span class="line">      Thread.sleep(<span class="number">500</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 相继启动目的地和数据源组件</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>LifecycleSupervisor</code> 类（代码中的 <code>supervisor</code> 变量）可用于管理实现了 <code>LifecycleAware</code> 接口的组件。该类会初始化一个 <code>MonitorRunnable</code>，每三秒轮询一次组件状态，通过 <code>LifecycleAware#start</code> 和 <code>stop</code> 方法，保证其始终处于 <code>desiredState</code> 变量所指定的状态。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MonitorRunnable</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!lifecycleAware.getLifecycleState().equals(</span><br><span class="line">        supervisoree.status.desiredState)) &#123;</span><br><span class="line">      <span class="keyword">switch</span> (supervisoree.status.desiredState) &#123;</span><br><span class="line">        <span class="keyword">case</span> START:</span><br><span class="line">          lifecycleAware.start();</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> STOP:</span><br><span class="line">          lifecycleAware.stop();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="停止组件"><a href="#停止组件" class="headerlink" title="停止组件"></a>停止组件</h2><p>当 JVM 关闭时，钩子函数会调用 <code>Application#stop</code> 方法，进而调用 <code>LifecycleSupervisor#stop</code>。该方法首先停止所有的 <code>MonitorRunnable</code> 线程，将组件目标状态置为 <code>STOP</code>，并调用 <code>LifecycleAware#stop</code> 方法命其优雅终止。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LifecycleSupervisor</span> <span class="keyword">implements</span> <span class="title">LifecycleAware</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">stop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    monitorService.shutdown();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">final</span> Entry&lt;LifecycleAware, Supervisoree&gt; entry :</span><br><span class="line">        supervisedProcesses.entrySet()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (entry.getKey().getLifecycleState().equals(LifecycleState.START)) &#123;</span><br><span class="line">        entry.getValue().status.desiredState = LifecycleState.STOP;</span><br><span class="line">        entry.getKey().stop();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Source-与-SourceRunner"><a href="#Source-与-SourceRunner" class="headerlink" title="Source 与 SourceRunner"></a>Source 与 SourceRunner</h2><p>对于单个组件的生命周期，我们以 <code>KafkaSource</code> 为例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaSource</span> <span class="keyword">extends</span> <span class="title">AbstractPollableSource</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doStart</span><span class="params">()</span> <span class="keyword">throws</span> FlumeException </span>&#123;</span><br><span class="line">    consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, <span class="keyword">byte</span>[]&gt;(kafkaProps);</span><br><span class="line">    it = consumer.poll(<span class="number">1000</span>).iterator();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doStop</span><span class="params">()</span> <span class="keyword">throws</span> FlumeException </span>&#123;</span><br><span class="line">    consumer.close();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>KafkaSource</code> 被定义成轮询式的数据源，也就是说我们需要使用一个线程不断对其进行轮询，查看是否有数据可以供处理：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PollableSourceRunner</span> <span class="keyword">extends</span> <span class="title">SourceRunner</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    source.start();</span><br><span class="line">    runner = <span class="keyword">new</span> PollingRunner();</span><br><span class="line">    runnerThread = <span class="keyword">new</span> Thread(runner);</span><br><span class="line">    runnerThread.start();</span><br><span class="line">    lifecycleState = LifecycleState.START;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">stop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    runnerThread.interrupt();</span><br><span class="line">    runnerThread.join();</span><br><span class="line">    source.stop();</span><br><span class="line">    lifecycleState = LifecycleState.STOP;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 轮询线程</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">PollingRunner</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">while</span> (!shouldStop.get()) &#123;</span><br><span class="line">        source.process();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>AbstractPollableSource</code> 和 <code>SourceRunner</code> 都实现了 <code>LifecycleAware</code> 接口，因此都有 <code>start</code> 和 <code>stop</code> 方法。但是，只有 <code>SourceRunner</code> 会由 <code>LifecycleSupervisor</code> 管理，<code>PollableSource</code> 则是附属于 <code>SourceRunner</code> 的一个组件。我们可以在 <code>AbstractConfigurationProvider#loadSources</code> 中看到配置关系：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">loadSources</span><span class="params">(Map&lt;String, SourceRunner&gt; sourceRunnerMap)</span> </span>&#123;</span><br><span class="line">  Source source = sourceFactory.create();</span><br><span class="line">  Configurables.configure(source, config);</span><br><span class="line">  sourceRunnerMap.put(comp.getComponentName(),</span><br><span class="line">      SourceRunner.forSource(source));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://github.com/apache/flume" target="_blank" rel="noopener">https://github.com/apache/flume</a></li><li><a href="https://flume.apache.org/FlumeUserGuide.html" target="_blank" rel="noopener">https://flume.apache.org/FlumeUserGuide.html</a></li><li><a href="https://kafka.apache.org/0100/javadoc/index.html" target="_blank" rel="noopener">https://kafka.apache.org/0100/javadoc/index.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://flume.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Apache Flume&lt;/a&gt; 是数据仓库体系中用于做实时 ETL 的工具。它提供了丰富的数据源和写入组件，这些组件在运行时都由 Flume 的生命周期管理机制进行监控和维护。本文将对这部分功能的源码进行解析。&lt;/p&gt;
&lt;h2 id=&quot;项目结构&quot;&gt;&lt;a href=&quot;#项目结构&quot; class=&quot;headerlink&quot; title=&quot;项目结构&quot;&gt;&lt;/a&gt;项目结构&lt;/h2&gt;&lt;p&gt;Flume 的源码可以从 GitHub 上下载。它是一个 Maven 项目，我们将其导入到 IDE 中以便更好地进行源码阅读。以下是代码仓库的基本结构：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;/flume-ng-node&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/flume-ng-code&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/flume-ng-sdk&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/flume-ng-sources/flume-kafka-source&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/flume-ng-channels/flume-kafka-channel&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/flume-ng-sinks/flume-hdfs-sink&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;程序入口&quot;&gt;&lt;a href=&quot;#程序入口&quot; class=&quot;headerlink&quot; title=&quot;程序入口&quot;&gt;&lt;/a&gt;程序入口&lt;/h2&gt;&lt;p&gt;Flume Agent 的入口 &lt;code&gt;main&lt;/code&gt; 函数位于 &lt;code&gt;flume-ng-node&lt;/code&gt; 模块的 &lt;code&gt;org.apache.flume.node.Application&lt;/code&gt; 类中。下列代码是该函数的摘要：&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Application&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(String[] args)&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    CommandLineParser parser = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; GnuParser();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (isZkConfigured) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (reload) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        PollingZooKeeperConfigurationProvider zookeeperConfigurationProvider;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        components.add(zookeeperConfigurationProvider);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;#125; &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        StaticZooKeeperConfigurationProvider zookeeperConfigurationProvider;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        application.handleConfigurationEvent();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125; &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;span class=&quot;comment&quot;&gt;// PropertiesFileConfigurationProvider&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    application.start();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Runtime.getRuntime().addShutdownHook(&lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Thread(&lt;span class=&quot;string&quot;&gt;&quot;agent-shutdown-hook&quot;&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;span class=&quot;meta&quot;&gt;@Override&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        appReference.stop();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;启动过程说明如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用 &lt;code&gt;commons-cli&lt;/code&gt; 对命令行参数进行解析，提取 Agent 名称、配置信息读取方式及其路径信息；&lt;/li&gt;
&lt;li&gt;配置信息可以通过文件或 ZooKeeper 的方式进行读取，两种方式都支持热加载，即我们不需要重启 Agent 就可以更新配置内容：&lt;ul&gt;
&lt;li&gt;基于文件的配置热加载是通过一个后台线程对文件进行轮询实现的；&lt;/li&gt;
&lt;li&gt;基于 ZooKeeper 的热加载则是使用了 Curator 的 &lt;code&gt;NodeCache&lt;/code&gt; 模式，底层是 ZooKeeper 原生的监听（Watch）特性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;如果配置热更新是开启的（默认开启），配置提供方 &lt;code&gt;ConfigurationProvider&lt;/code&gt; 就会将自身注册到 Agent 程序的组件列表中，并在 &lt;code&gt;Application#start&lt;/code&gt; 方法调用后，由 &lt;code&gt;LifecycleSupervisor&lt;/code&gt; 类进行启动和管理，加载和解析配置文件，从中读取组件列表。&lt;/li&gt;
&lt;li&gt;如果热更新未开启，则配置提供方将在启动时立刻读取配置文件，并由 &lt;code&gt;LifecycleSupervisor&lt;/code&gt; 启动和管理所有组件。&lt;/li&gt;
&lt;li&gt;最后，&lt;code&gt;main&lt;/code&gt; 会调用 &lt;code&gt;Runtime#addShutdownHook&lt;/code&gt;，当 JVM 关闭时（SIGTERM 或者 Ctrl+C），&lt;code&gt;Application#stop&lt;/code&gt; 会被用于关闭 Flume Agent，使各组件优雅退出。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/cnblogs/categories/Big-Data/"/>
    
    
      <category term="java" scheme="http://shzhangji.com/cnblogs/tags/java/"/>
    
      <category term="flume" scheme="http://shzhangji.com/cnblogs/tags/flume/"/>
    
      <category term="source code" scheme="http://shzhangji.com/cnblogs/tags/source-code/"/>
    
  </entry>
  
  <entry>
    <title>Pandas 与数据整理</title>
    <link href="http://shzhangji.com/cnblogs/2017/09/30/pandas-and-tidy-data/"/>
    <id>http://shzhangji.com/cnblogs/2017/09/30/pandas-and-tidy-data/</id>
    <published>2017-09-30T06:37:56.000Z</published>
    <updated>2017-09-30T07:39:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>在 <a href="https://www.jstatsoft.org/article/view/v059i10" target="_blank" rel="noopener">Tidy Data</a> 论文中，<a href="https://en.wikipedia.org/wiki/Hadley_Wickham" target="_blank" rel="noopener">Wickham 博士</a> 提出了这样一种“整洁”的数据结构：每个变量是一列，每次观测结果是一行，不同的观测类型存放在单独的表中。他认为这样的数据结构可以帮助分析师更简单高效地进行处理、建模、和可视化。他在论文中列举了 <em>五种</em> 不符合整洁数据的情况，并演示了如何通过 <a href="https://github.com/hadley/tidy-data/" target="_blank" rel="noopener">R 语言</a> 对它们进行整理。本文中，我们将使用 Python 和 Pandas 来达到同样的目的。</p><p>文中的源代码和演示数据可以在 GitHub（<a href="https://github.com/jizhang/pandas-tidy-data" target="_blank" rel="noopener">链接</a>）上找到。读者应该已经安装好 Python 开发环境，推荐各位使用 Anaconda 和 Spyder IDE。</p><h2 id="列名称是数据值，而非变量名"><a href="#列名称是数据值，而非变量名" class="headerlink" title="列名称是数据值，而非变量名"></a>列名称是数据值，而非变量名</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">'data/pew.csv'</span>)</span><br><span class="line">df.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p><img src="/cnblogs/images/tidy-data/pew.png" alt="宗教信仰与收入 - Pew 论坛"></p><p>表中的列“&lt;$10k”、“$10-20k”其实是“收入”变量的具体值。<em>变量</em> 是指某一特性的观测值，如身高、体重，本例中则是收入、宗教信仰。表中的数值数据构成了另一个变量——人数。要做到 <em>每个变量是一列</em> ，我们需要进行以下变换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df = df.set_index(<span class="string">'religion'</span>)</span><br><span class="line">df = df.stack()</span><br><span class="line">df.index = df.index.rename(<span class="string">'income'</span>, level=<span class="number">1</span>)</span><br><span class="line">df.name = <span class="string">'frequency'</span></span><br><span class="line">df = df.reset_index()</span><br><span class="line">df.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p><img src="/cnblogs/images/tidy-data/pew-tidy.png" alt="宗教信仰与收入 - 整洁版"></p><a id="more"></a><p>这里我们使用了 Pandas 多级索引的 <a href="https://pandas.pydata.org/pandas-docs/stable/reshaping.html" target="_blank" rel="noopener">stack / unstack</a> 特性。<code>stack()</code> 会将列名转置为新一级的索引，并将数据框（DataFrame）转换成序列（Series）。转置后，我们对行和列的名称做一些调整，再用 <code>reset_index()</code> 将数据框还原成普通的二维表。</p><p>除了使用多级索引，Pandas 还提供了另一种更为便捷的方法——<a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.melt.html" target="_blank" rel="noopener"><code>melt()</code></a>。该方法接收以下参数：</p><ul><li><code>frame</code>: 需要处理的数据框；</li><li><code>id_vars</code>: 保持原样的数据列；</li><li><code>value_vars</code>: 需要被转换成变量值的数据列；</li><li><code>var_name</code>: 转换后变量的列名；</li><li><code>value_name</code>: 数值变量的列名。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'data/pew.csv'</span>)</span><br><span class="line">df = pd.melt(df, id_vars=[<span class="string">'religion'</span>], value_vars=list(df.columns)[<span class="number">1</span>:],</span><br><span class="line">             var_name=<span class="string">'income'</span>, value_name=<span class="string">'frequency'</span>)</span><br><span class="line">df = df.sort_values(by=<span class="string">'religion'</span>)</span><br><span class="line">df.to_csv(<span class="string">'data/pew-tidy.csv'</span>, index=<span class="keyword">False</span>)</span><br><span class="line">df.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>这段代码会输出相同的结果，下面的示例中我们都将使用 <code>melt()</code> 方法。我们再来看另外一个案例：</p><p><img src="/cnblogs/images/tidy-data/billboard.png" alt="Billboard 2000"></p><p>在这个数据集中，每周的排名都被记录到了不同的数据列中。如果我们想要回答“Dancing Queen 这首歌在 2000年7月15日 的排名如何”，就需要结合 <code>date.entered</code> 字段做一些运算才行。下面我们来对这份数据进行整理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'data/billboard.csv'</span>)</span><br><span class="line">df = pd.melt(df, id_vars=list(df.columns)[:<span class="number">5</span>], value_vars=list(df.columns)[<span class="number">5</span>:],</span><br><span class="line">             var_name=<span class="string">'week'</span>, value_name=<span class="string">'rank'</span>)</span><br><span class="line">df[<span class="string">'week'</span>] = df[<span class="string">'week'</span>].str[<span class="number">2</span>:].astype(int)</span><br><span class="line">df[<span class="string">'date.entered'</span>] = pd.to_datetime(df[<span class="string">'date.entered'</span>]) + pd.to_timedelta((df[<span class="string">'week'</span>] - <span class="number">1</span>) * <span class="number">7</span>, <span class="string">'d'</span>)</span><br><span class="line">df = df.rename(columns=&#123;<span class="string">'date.entered'</span>: <span class="string">'date'</span>&#125;)</span><br><span class="line">df = df.sort_values(by=[<span class="string">'track'</span>, <span class="string">'date'</span>])</span><br><span class="line">df.to_csv(<span class="string">'data/billboard-intermediate.csv'</span>, index=<span class="keyword">False</span>)</span><br><span class="line">df.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p><img src="/cnblogs/images/tidy-data/billboard-intermediate.png" alt="Billboard 2000 - 中间版"></p><p>上述代码中，我们还将 <code>date.entered</code> 转换成了每一周的具体日期，<code>week</code> 字段也作为单独的数据列进行存储。但是，我们会在表中看到很多重复的信息，如歌手、曲名等，我们将在第四节解决这个问题。</p><h2 id="一列包含多个变量"><a href="#一列包含多个变量" class="headerlink" title="一列包含多个变量"></a>一列包含多个变量</h2><p>人们之所以会将变量值作为列名，一方面是这样的表示方法更为紧凑、可以在一页中显示更多信息，还有一点是这种格式便于做交叉验证等数据分析工作。下面的数据集更是将性别和年龄这两个变量都放入了列名中：</p><p><img src="/cnblogs/images/tidy-data/tb.png" alt="结核病 (TB)"></p><p><code>m</code> 表示男性（Male），<code>f</code> 表示女性（Female），<code>0-14</code>、<code>15-24</code> 则表示年龄段。进行数据整理时，我们先用 Pandas 的字符串处理功能截取 <code>sex</code> 字段，再对剩余表示年龄段的子串做映射处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'data/tb.csv'</span>)</span><br><span class="line">df = pd.melt(df, id_vars=[<span class="string">'country'</span>, <span class="string">'year'</span>], value_vars=list(df.columns)[<span class="number">2</span>:],</span><br><span class="line">             var_name=<span class="string">'column'</span>, value_name=<span class="string">'cases'</span>)</span><br><span class="line">df = df[df[<span class="string">'cases'</span>] != <span class="string">'---'</span>]</span><br><span class="line">df[<span class="string">'cases'</span>] = df[<span class="string">'cases'</span>].astype(int)</span><br><span class="line">df[<span class="string">'sex'</span>] = df[<span class="string">'column'</span>].str[<span class="number">0</span>]</span><br><span class="line">df[<span class="string">'age'</span>] = df[<span class="string">'column'</span>].str[<span class="number">1</span>:].map(&#123;</span><br><span class="line">    <span class="string">'014'</span>: <span class="string">'0-14'</span>,</span><br><span class="line">    <span class="string">'1524'</span>: <span class="string">'15-24'</span>,</span><br><span class="line">    <span class="string">'2534'</span>: <span class="string">'25-34'</span>,</span><br><span class="line">    <span class="string">'3544'</span>: <span class="string">'35-44'</span>,</span><br><span class="line">    <span class="string">'4554'</span>: <span class="string">'45-54'</span>,</span><br><span class="line">    <span class="string">'5564'</span>: <span class="string">'55-64'</span>,</span><br><span class="line">    <span class="string">'65'</span>: <span class="string">'65+'</span></span><br><span class="line">&#125;)</span><br><span class="line">df = df[[<span class="string">'country'</span>, <span class="string">'year'</span>, <span class="string">'sex'</span>, <span class="string">'age'</span>, <span class="string">'cases'</span>]]</span><br><span class="line">df.to_csv(<span class="string">'data/tb-tidy.csv'</span>, index=<span class="keyword">False</span>)</span><br><span class="line">df.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p><img src="/cnblogs/images/tidy-data/tb-tidy.png" alt="结核病 (TB) - 整洁版"></p><h2 id="变量存储在行和列中"><a href="#变量存储在行和列中" class="headerlink" title="变量存储在行和列中"></a>变量存储在行和列中</h2><p>下表是一个名为 MX17004 的气象站收集的温度数据。可以看到，日期被放置在列名中，我们可以用 <code>melt</code> 进行处理；<code>tmax</code> 和 <code>tmin</code> 则表示最高温度和最低温度，他们很显然是两个不同的变量，用来衡量单个观测对象的属性的，本例中的观测对象是“天”。因此，我们需要使用 <code>unstack</code> 将其拆分成两列。</p><p><img src="/cnblogs/images/tidy-data/weather.png" alt="气象站"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'data/weather.csv'</span>)</span><br><span class="line">df = pd.melt(df, id_vars=[<span class="string">'id'</span>, <span class="string">'year'</span>, <span class="string">'month'</span>, <span class="string">'element'</span>],</span><br><span class="line">             value_vars=list(df.columns)[<span class="number">4</span>:],</span><br><span class="line">             var_name=<span class="string">'date'</span>, value_name=<span class="string">'value'</span>)</span><br><span class="line">df[<span class="string">'date'</span>] = df[<span class="string">'date'</span>].str[<span class="number">1</span>:].astype(<span class="string">'int'</span>)</span><br><span class="line">df[<span class="string">'date'</span>] = df[[<span class="string">'year'</span>, <span class="string">'month'</span>, <span class="string">'date'</span>]].apply(</span><br><span class="line">    <span class="keyword">lambda</span> row: <span class="string">'&#123;:4d&#125;-&#123;:02d&#125;-&#123;:02d&#125;'</span>.format(*row),</span><br><span class="line">    axis=<span class="number">1</span>)</span><br><span class="line">df = df.loc[df[<span class="string">'value'</span>] != <span class="string">'---'</span>, [<span class="string">'id'</span>, <span class="string">'date'</span>, <span class="string">'element'</span>, <span class="string">'value'</span>]]</span><br><span class="line">df = df.set_index([<span class="string">'id'</span>, <span class="string">'date'</span>, <span class="string">'element'</span>])</span><br><span class="line">df = df.unstack()</span><br><span class="line">df.columns = list(df.columns.get_level_values(<span class="string">'element'</span>))</span><br><span class="line">df = df.reset_index()</span><br><span class="line">df.to_csv(<span class="string">'data/weather-tidy.csv'</span>, index=<span class="keyword">False</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="/cnblogs/images/tidy-data/weather-tidy.png" alt="气象站 - 整洁版"></p><h2 id="同一表中包含多种观测类型"><a href="#同一表中包含多种观测类型" class="headerlink" title="同一表中包含多种观测类型"></a>同一表中包含多种观测类型</h2><p>在处理 Billboard 数据集时，我们会看到冗余的曲目信息，这是因为该表实际记录的是两种不同的观测类型——歌曲曲目和周排名。整理时，我们需要先为每首歌曲生成一个唯一标识，即 <code>id</code>，然后拆分到单独的表中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'data/billboard-intermediate.csv'</span>)</span><br><span class="line">df_track = df[[<span class="string">'artist'</span>, <span class="string">'track'</span>, <span class="string">'time'</span>]].drop_duplicates()</span><br><span class="line">df_track.insert(<span class="number">0</span>, <span class="string">'id'</span>, range(<span class="number">1</span>, len(df_track) + <span class="number">1</span>))</span><br><span class="line">df = pd.merge(df, df_track, on=[<span class="string">'artist'</span>, <span class="string">'track'</span>, <span class="string">'time'</span>])</span><br><span class="line">df = df[[<span class="string">'id'</span>, <span class="string">'date'</span>, <span class="string">'rank'</span>]]</span><br><span class="line">df_track.to_csv(<span class="string">'data/billboard-track.csv'</span>, index=<span class="keyword">False</span>)</span><br><span class="line">df.to_csv(<span class="string">'data/billboard-rank.csv'</span>, index=<span class="keyword">False</span>)</span><br><span class="line">print(df_track, <span class="string">'\n\n'</span>, df)</span><br></pre></td></tr></table></figure><p><img src="/cnblogs/images/tidy-data/billboard-track.png" alt="Billboard 2000 - 歌曲"></p><p><img src="/cnblogs/images/tidy-data/billboard-rank.png" alt="Billboard 2000 - 排名"></p><h2 id="同一观测类型分布在不同表中"><a href="#同一观测类型分布在不同表中" class="headerlink" title="同一观测类型分布在不同表中"></a>同一观测类型分布在不同表中</h2><p>原始的数据集可能会以两种方式进行了拆分，一种是按照某个变量拆分，如按年拆分为2000年、2001年，按地理位置拆分为中国、英国；另一种是按不同的属性拆分，如一份数据是收集温度的传感器记录的，另一份是湿度传感器，他们记录的都是每一天的观测值。对于第一种情况，我们可以编写一个读取数据的函数，遍历目录中的文件，并将文件名作为单独的列加入数据框，最后使用 <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html" target="_blank" rel="noopener"><code>pd.concat</code></a> 进行合并；第二种情况则要求数据集中的记录有一个唯一标识，如日期、身份证号，并通过 <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.merge.html" target="_blank" rel="noopener"><code>pd.merge</code></a> 将各个数据集联系起来。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://tomaugspurger.github.io/modern-5-tidy.html" target="_blank" rel="noopener">https://tomaugspurger.github.io/modern-5-tidy.html</a></li><li><a href="https://hackernoon.com/reshaping-data-in-python-fa27dda2ff77" target="_blank" rel="noopener">https://hackernoon.com/reshaping-data-in-python-fa27dda2ff77</a></li><li><a href="http://www.jeannicholashould.com/tidy-data-in-python.html" target="_blank" rel="noopener">http://www.jeannicholashould.com/tidy-data-in-python.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在 &lt;a href=&quot;https://www.jstatsoft.org/article/view/v059i10&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Tidy Data&lt;/a&gt; 论文中，&lt;a href=&quot;https://en.wikipedia.org/wiki/Hadley_Wickham&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Wickham 博士&lt;/a&gt; 提出了这样一种“整洁”的数据结构：每个变量是一列，每次观测结果是一行，不同的观测类型存放在单独的表中。他认为这样的数据结构可以帮助分析师更简单高效地进行处理、建模、和可视化。他在论文中列举了 &lt;em&gt;五种&lt;/em&gt; 不符合整洁数据的情况，并演示了如何通过 &lt;a href=&quot;https://github.com/hadley/tidy-data/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;R 语言&lt;/a&gt; 对它们进行整理。本文中，我们将使用 Python 和 Pandas 来达到同样的目的。&lt;/p&gt;
&lt;p&gt;文中的源代码和演示数据可以在 GitHub（&lt;a href=&quot;https://github.com/jizhang/pandas-tidy-data&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;链接&lt;/a&gt;）上找到。读者应该已经安装好 Python 开发环境，推荐各位使用 Anaconda 和 Spyder IDE。&lt;/p&gt;
&lt;h2 id=&quot;列名称是数据值，而非变量名&quot;&gt;&lt;a href=&quot;#列名称是数据值，而非变量名&quot; class=&quot;headerlink&quot; title=&quot;列名称是数据值，而非变量名&quot;&gt;&lt;/a&gt;列名称是数据值，而非变量名&lt;/h2&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df = pd.read_csv(&lt;span class=&quot;string&quot;&gt;&#39;data/pew.csv&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df.head(&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;/cnblogs/images/tidy-data/pew.png&quot; alt=&quot;宗教信仰与收入 - Pew 论坛&quot;&gt;&lt;/p&gt;
&lt;p&gt;表中的列“&amp;lt;$10k”、“$10-20k”其实是“收入”变量的具体值。&lt;em&gt;变量&lt;/em&gt; 是指某一特性的观测值，如身高、体重，本例中则是收入、宗教信仰。表中的数值数据构成了另一个变量——人数。要做到 &lt;em&gt;每个变量是一列&lt;/em&gt; ，我们需要进行以下变换：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;df = df.set_index(&lt;span class=&quot;string&quot;&gt;&#39;religion&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df = df.stack()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df.index = df.index.rename(&lt;span class=&quot;string&quot;&gt;&#39;income&#39;&lt;/span&gt;, level=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df.name = &lt;span class=&quot;string&quot;&gt;&#39;frequency&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df = df.reset_index()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df.head(&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;/cnblogs/images/tidy-data/pew-tidy.png&quot; alt=&quot;宗教信仰与收入 - 整洁版&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/cnblogs/categories/Big-Data/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/cnblogs/tags/python/"/>
    
      <category term="analytics" scheme="http://shzhangji.com/cnblogs/tags/analytics/"/>
    
      <category term="pandas" scheme="http://shzhangji.com/cnblogs/tags/pandas/"/>
    
  </entry>
  
  <entry>
    <title>Apache Beam 快速入门（Python 版）</title>
    <link href="http://shzhangji.com/cnblogs/2017/09/13/apache-beam-quick-start-with-python/"/>
    <id>http://shzhangji.com/cnblogs/2017/09/13/apache-beam-quick-start-with-python/</id>
    <published>2017-09-13T04:39:03.000Z</published>
    <updated>2017-09-13T04:39:03.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://beam.apache.org/get-started/beam-overview/" target="_blank" rel="noopener">Apache Beam</a> 是一种大数据处理标准，由谷歌于 2016 年创建。它提供了一套统一的 DSL 用以处理离线和实时数据，并能在目前主流的大数据处理平台上使用，包括 Spark、Flink、以及谷歌自身的商业套件 Dataflow。Beam 的数据模型基于过去的几项研究成果：<a href="https://web.archive.org/web/20160923141630/https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35650.pdf" target="_blank" rel="noopener">FlumeJava</a>、<a href="https://web.archive.org/web/20160201091359/http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41378.pdf" target="_blank" rel="noopener">Millwheel</a>，适用场景包括 ETL、统计分析、实时计算等。目前，Beam 提供了两种语言的 SDK：Java、Python。本文将讲述如何使用 Python 编写 Beam 应用程序。</p><p><img src="/cnblogs/images/beam/arch.jpg" alt="Apache Beam Pipeline"></p><h2 id="安装-Apache-Beam"><a href="#安装-Apache-Beam" class="headerlink" title="安装 Apache Beam"></a>安装 Apache Beam</h2><p>Apache Beam Python SDK 必须使用 Python 2.7.x 版本，你可以安装 <a href="https://github.com/pyenv/pyenv" target="_blank" rel="noopener">pyenv</a> 来管理不同版本的 Python，或者直接从<a href="https://www.python.org/downloads/source/" target="_blank" rel="noopener">源代码</a>编译安装（需要支持 SSL）。之后，你便可以在 Python 虚拟环境中安装 Beam SDK 了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ virtualenv venv --distribute</span><br><span class="line">$ source venv/bin/activate</span><br><span class="line">(venv) $ pip install apache-beam</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="Wordcount-示例"><a href="#Wordcount-示例" class="headerlink" title="Wordcount 示例"></a>Wordcount 示例</h2><p>Wordcount 是大数据领域的 Hello World，我们来看如何使用 Beam 实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> apache_beam <span class="keyword">as</span> beam</span><br><span class="line"><span class="keyword">from</span> apache_beam.options.pipeline_options <span class="keyword">import</span> PipelineOptions</span><br><span class="line"><span class="keyword">with</span> beam.Pipeline(options=PipelineOptions()) <span class="keyword">as</span> p:</span><br><span class="line">    lines = p | <span class="string">'Create'</span> &gt;&gt; beam.Create([<span class="string">'cat dog'</span>, <span class="string">'snake cat'</span>, <span class="string">'dog'</span>])</span><br><span class="line">    counts = (</span><br><span class="line">        lines</span><br><span class="line">        | <span class="string">'Split'</span> &gt;&gt; (beam.FlatMap(<span class="keyword">lambda</span> x: x.split(<span class="string">' '</span>))</span><br><span class="line">                      .with_output_types(unicode))</span><br><span class="line">        | <span class="string">'PairWithOne'</span> &gt;&gt; beam.Map(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>))</span><br><span class="line">        | <span class="string">'GroupAndSum'</span> &gt;&gt; beam.CombinePerKey(sum)</span><br><span class="line">    )</span><br><span class="line">    counts | <span class="string">'Print'</span> &gt;&gt; beam.ParDo(<span class="keyword">lambda</span> (w, c): print(<span class="string">'%s: %s'</span> % (w, c)))</span><br></pre></td></tr></table></figure><p>运行脚本，我们便可得到每个单词出现的次数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(venv) $ python wordcount.py</span><br><span class="line">cat: 2</span><br><span class="line">snake: 1</span><br><span class="line">dog: 2</span><br></pre></td></tr></table></figure><p>Apache Beam 有三个重要的基本概念：Pipeline、PCollection、以及 Transform。</p><ul><li><strong>Pipeline</strong> （管道）用以构建数据集和处理过程的 DAG（有向无环图）。我们可以将它看成 MapReduce 中的 <code>Job</code> 或是 Storm 的 <code>Topology</code>。</li><li><strong>PCollection</strong> 是一种数据结构，我们可以对其进行各类转换操作，如解析、过滤、聚合等。它和 Spark 中的 <code>RDD</code> 概念类似。</li><li><strong>Transform</strong> （转换）则用于编写业务逻辑。通过它，我们可以将一个 PCollection 转换成另一个 PCollection。Beam 提供了许多内置的转换函数，我们将在下文讨论。</li></ul><p>在本例中，<code>Pipeline</code> 和 <code>PipelineOptions</code> 用来创建一个管道。通过 <code>with</code> 关键字，上下文管理器会自动调用 <code>Pipeline.run</code> 和 <code>wait_until_finish</code> 方法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Output PCollection] = [Input PCollection] | [Label] &gt;&gt; [Transform]</span><br></pre></td></tr></table></figure><p><code>|</code> 是 Beam 引入的新操作符，用来添加一个转换。每次转换都可以定义一个唯一的标签，默认由 Beam 自动生成。转换能够串联，我们可以构建出不同形态的转换流程，它们在运行时会表示为一个 DAG。</p><p><code>beam.Create</code> 用来从内存数据创建出一个 PCollection，主要用于测试和演示。Beam 提供了多种内置的输入源（Source）和输出目标（Sink），可以接收和写入有界（Bounded）或无界（Unbounded）的数据，并且能进行自定义。</p><p><code>beam.Map</code> 是一种 <em>一对一</em> 的转换，本例中我们将一个个单词转换成形如 <code>(word, 1)</code> 的元组。<code>beam.FlatMap</code> 则是 <code>Map</code> 和 <code>Flatten</code> 的结合体，通过它，我们将包含多个单词的数组合并成一个一维的数组。</p><p><code>CombinePerKey</code> 的输入源是一系列的二元组（2-element tuple）。这个操作会将元素的第一个元素作为键进行分组，并将相同键的值（第二个元素）组成一个列表。最后，我们使用 <code>beam.ParDo</code> 输出统计结果。这个转换函数比较底层，我们会在下文详述。</p><h2 id="输入与输出"><a href="#输入与输出" class="headerlink" title="输入与输出"></a>输入与输出</h2><p>目前，Beam Python SDK 对输入输出的支持十分有限。下表列出了现阶段支持的数据源（<a href="https://beam.apache.org/documentation/io/built-in/" target="_blank" rel="noopener">资料来源</a>）：</p><table><thead><tr><th>语言</th><th>文件系统</th><th>消息队列</th><th>数据库</th></tr></thead><tbody><tr><td>Java</td><td>HDFS<br>TextIO<br>XML</td><td>AMQP<br>Kafka<br>JMS</td><td>Hive<br>Solr<br>JDBC</td></tr><tr><td>Python</td><td>textio<br>avroio<br>tfrecordio</td><td>-</td><td>Google Big Query<br>Google Cloud Datastore</td></tr></tbody></table><p>这段代码演示了如何使用 <code>textio</code> 对文本文件进行读写：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lines = p | <span class="string">'Read'</span> &gt;&gt; beam.io.ReadFromText(<span class="string">'/path/to/input-*.csv'</span>)</span><br><span class="line">lines | <span class="string">'Write'</span> &gt;&gt; beam.io.WriteToText(<span class="string">'/path/to/output'</span>, file_name_suffix=<span class="string">'.csv'</span>)</span><br></pre></td></tr></table></figure><p>通过使用通配符，<code>textio</code> 可以读取多个文件。我们还可以从不同的数据源中读取文件，并用 <code>Flatten</code> 方法将多个 <code>PCollection</code> 合并成一个。输出文件默认也会是多个，因为 Beam Pipeline 是并发执行的，不同的进程会写入独立的文件。</p><h2 id="转换函数"><a href="#转换函数" class="headerlink" title="转换函数"></a>转换函数</h2><p>Beam 中提供了基础和上层的转换函数。通常我们更偏向于使用上层函数，这样就可以将精力聚焦在实现业务逻辑上。下表列出了常用的上层转换函数：</p><table><thead><tr><th>转换函数</th><th>功能含义</th></tr></thead><tbody><tr><td>Create(value)</td><td>基于内存中的集合数据生成一个 PCollection。</td></tr><tr><td>Filter(fn)</td><td>使用 <code>fn</code> 函数过滤 PCollection 中的元素。</td></tr><tr><td>Map(fn)</td><td>使用 <code>fn</code> 函数做一对一的转换处理。</td></tr><tr><td>FlatMap(fn)</td><td>功能和 <code>Map</code> 类似，但是 <code>fn</code> 需要返回一个集合，里面包含零个或多个元素，最终 <code>FlatMap</code> 会将这些集合合并成一个 PCollection。</td></tr><tr><td>Flatten()</td><td>合并多个 PCollection。</td></tr><tr><td>Partition(fn)</td><td>将一个 PCollection 切分成多个分区。<code>fn</code> 可以是 <code>PartitionFn</code> 或一个普通函数，能够接受两个参数：<code>element</code>、<code>num_partitions</code>。</td></tr><tr><td>GroupByKey()</td><td>输入源必须是使用二元组表示的键值对，该方法会按键进行分组，并返回一个 <code>(key, iter&lt;value&gt;)</code> 的序列。</td></tr><tr><td>CoGroupByKey()</td><td>对多个二元组 PCollection 按相同键进行合并，如输入的是 <code>(k, v)</code> 和 <code>(k, w)</code>，则输出 <code>(k, (iter&lt;v&gt;, iter&lt;w&gt;))</code>。</td></tr><tr><td>RemoveDuplicates()</td><td>对 PCollection 的元素进行去重。</td></tr><tr><td>CombinePerKey(fn)</td><td>功能和 <code>GroupByKey</code> 类似，但会进一步使用 <code>fn</code> 对值列表进行合并。<code>fn</code> 可以是一个 <code>CombineFn</code>，或是一个普通函数，接收序列并返回结果，如 <code>sum</code>、<code>max</code> 函数等。</td></tr><tr><td>CombineGlobally(fn)</td><td>使用 <code>fn</code> 将整个 PCollection 合并计算成单个值。</td></tr></tbody></table><h3 id="Callable-DoFn-ParDo"><a href="#Callable-DoFn-ParDo" class="headerlink" title="Callable, DoFn, ParDo"></a>Callable, DoFn, ParDo</h3><p>可以看到，多数转换函数都会接收另一个函数（Callable）做为参数。在 Python 中，<a href="https://docs.python.org/2/library/functions.html#callable" target="_blank" rel="noopener">Callable</a> 可以是一个函数、类方法、Lambda 表达式、或是任何包含 <code>__call__</code> 方法的对象实例。Beam 会将这些函数包装成一个 <code>DoFn</code> 类，所有转换函数最终都会调用最基础的 <code>ParDo</code> 函数，并将 <code>DoFn</code> 传递给它。</p><p>我们可以尝试将 <code>lambda x: x.split(&#39; &#39;)</code> 这个表达式转换成 <code>DoFn</code> 类：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SplitFn</span><span class="params">(beam.DoFn)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process</span><span class="params">(self, element)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> element.split(<span class="string">' '</span>)</span><br><span class="line"></span><br><span class="line">lines | beam.ParDo(SplitFn())</span><br></pre></td></tr></table></figure><p><code>ParDo</code> 转换和 <code>FlatMap</code> 的功能类似，只是它的 <code>fn</code> 参数必须是一个 <code>DoFn</code>。除了使用 <code>return</code>，我们还可以用 <code>yield</code> 语句来返回结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SplitAndPairWithOneFn</span><span class="params">(beam.DoFn)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process</span><span class="params">(self, element)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> element.split(<span class="string">' '</span>):</span><br><span class="line">            <span class="keyword">yield</span> (word, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="合并函数"><a href="#合并函数" class="headerlink" title="合并函数"></a>合并函数</h3><p>合并函数（<code>CombineFn</code>）用来将集合数据合并计算成单个值。我们既可以对整个 PCollection 做合并（<code>CombineGlobally</code>），也可以计算每个键的合并结果（<code>CombinePerKey</code>）。Beam 会将普通函数（Callable）包装成 <code>CombineFn</code>，这些函数需要接收一个集合，并返回单个结果。需要注意的是，Beam 会将计算过程分发到多台服务器上，合并函数会被多次调用来计算中间结果，因此需要满足<a href="https://en.wikipedia.org/wiki/Commutative_property" target="_blank" rel="noopener">交换律</a>和<a href="https://en.wikipedia.org/wiki/Associative_property" target="_blank" rel="noopener">结合律</a>。<code>sum</code>、<code>min</code>、<code>max</code> 是符合这样的要求的。</p><p>Beam 提供了许多内置的合并函数，如计数、求平均值、排序等。以计数为例，下面两种写法都可以用来统计整个 PCollection 中元素的个数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lines | beam.combiners.Count.Globally()</span><br><span class="line">lines | beam.CombineGlobally(beam.combiners.CountCombineFn())</span><br></pre></td></tr></table></figure><p>其他合并函数可以参考 Python SDK 的官方文档（<a href="https://beam.apache.org/documentation/sdks/pydoc/2.1.0/apache_beam.transforms.html#module-apache_beam.transforms.combiners" target="_blank" rel="noopener">链接</a>）。我们也可以自行实现合并函数，只需继承 <code>CombineFn</code>，并实现四个方法。我们以内置的 <code>Mean</code> 平均值合并函数的源码为例：</p><p><a href="https://github.com/apache/beam/blob/v2.1.0/sdks/python/apache_beam/transforms/combiners.py#L75" target="_blank" rel="noopener"><code>apache_beam/transforms/combiners.py</code></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MeanCombineFn</span><span class="params">(core.CombineFn)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">create_accumulator</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">"""创建一个“本地”的中间结果，记录合计值和记录数。"""</span></span><br><span class="line">    <span class="keyword">return</span> (<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">add_input</span><span class="params">(self, <span class="params">(sum_, count)</span>, element)</span>:</span></span><br><span class="line">    <span class="string">"""处理新接收到的值。"""</span></span><br><span class="line">    <span class="keyword">return</span> sum_ + element, count + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">merge_accumulators</span><span class="params">(self, accumulators)</span>:</span></span><br><span class="line">    <span class="string">"""合并多个中间结果。"""</span></span><br><span class="line">    sums, counts = zip(*accumulators)</span><br><span class="line">    <span class="keyword">return</span> sum(sums), sum(counts)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">extract_output</span><span class="params">(self, <span class="params">(sum_, count)</span>)</span>:</span></span><br><span class="line">    <span class="string">"""计算平均值。"""</span></span><br><span class="line">    <span class="keyword">if</span> count == <span class="number">0</span>:</span><br><span class="line">      <span class="keyword">return</span> float(<span class="string">'NaN'</span>)</span><br><span class="line">    <span class="keyword">return</span> sum_ / float(count)</span><br></pre></td></tr></table></figure><h3 id="复合转换函数"><a href="#复合转换函数" class="headerlink" title="复合转换函数"></a>复合转换函数</h3><p>我们简单看一下上文中使用到的 <code>beam.combiners.Count.Globally</code> 的源码（<a href="https://github.com/apache/beam/blob/v2.1.0/sdks/python/apache_beam/transforms/combiners.py#L101" target="_blank" rel="noopener">链接</a>），它继承了 <code>PTransform</code> 类，并在 <code>expand</code> 方法中对 PCollection 应用了转换函数。这会形成一个小型的有向无环图，并合并到最终的 DAG 中。我们称其为复合转换函数，主要用于将相关的转换逻辑整合起来，便于理解和管理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Count</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">Globally</span><span class="params">(ptransform.PTransform)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">expand</span><span class="params">(self, pcoll)</span>:</span></span><br><span class="line">      <span class="keyword">return</span> pcoll | core.CombineGlobally(CountCombineFn())</span><br></pre></td></tr></table></figure><p>更多内置的复合转换函数如下表所示：</p><table><thead><tr><th>复合转换函数</th><th>功能含义</th></tr></thead><tbody><tr><td>Count.Globally()</td><td>计算元素总数。</td></tr><tr><td>Count.PerKey()</td><td>计算每个键的元素数。</td></tr><tr><td>Count.PerElement()</td><td>计算每个元素出现的次数，类似 Wordcount。</td></tr><tr><td>Mean.Globally()</td><td>计算所有元素的平均值。</td></tr><tr><td>Mean.PerKey()</td><td>计算每个键的元素平均值。</td></tr><tr><td>Top.Of(n, reverse)</td><td>获取 PCollection 中最大或最小的 <code>n</code> 个元素，另有 Top.Largest(n), Top.Smallest(n).</td></tr><tr><td>Top.PerKey(n, reverse)</td><td>获取每个键的值列表中最大或最小的 <code>n</code> 个元素，另有 Top.LargestPerKey(n), Top.SmallestPerKey(n)</td></tr><tr><td>Sample.FixedSizeGlobally(n)</td><td>随机获取 <code>n</code> 个元素。</td></tr><tr><td>Sample.FixedSizePerKey(n)</td><td>随机获取每个键下的 <code>n</code> 个元素。</td></tr><tr><td>ToList()</td><td>将 PCollection 合并成一个列表。</td></tr><tr><td>ToDict()</td><td>将 PCollection 合并成一个哈希表，输入数据需要是二元组集合。</td></tr></tbody></table><h2 id="时间窗口"><a href="#时间窗口" class="headerlink" title="时间窗口"></a>时间窗口</h2><p>在处理事件数据时，如访问日志、用户点击流，每条数据都会有一个 <em>事件时间</em> 属性，而通常我们会按事件时间对数据进行分组统计，这些分组即时间窗口。在 Beam 中，我们可以定义不同的时间窗口类型，能够支持有界和无界数据。由于 Python SDK 暂时只支持有界数据，我们就以一个离线访问日志文件作为输入源，统计每个时间窗口的记录条数。对于无界数据，概念和处理流程也是类似的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">64.242.88.10 - - [07/Mar/2004:16:05:49 -0800] &quot;GET /edit HTTP/1.1&quot; 401 12846</span><br><span class="line">64.242.88.10 - - [07/Mar/2004:16:06:51 -0800] &quot;GET /rdiff HTTP/1.1&quot; 200 4523</span><br><span class="line">64.242.88.10 - - [07/Mar/2004:16:10:02 -0800] &quot;GET /hsdivision HTTP/1.1&quot; 200 6291</span><br><span class="line">64.242.88.10 - - [07/Mar/2004:16:11:58 -0800] &quot;GET /view HTTP/1.1&quot; 200 7352</span><br><span class="line">64.242.88.10 - - [07/Mar/2004:16:20:55 -0800] &quot;GET /view HTTP/1.1&quot; 200 5253</span><br></pre></td></tr></table></figure><p><code>logmining.py</code> 的完整源码可以在 GitHub（<a href="https://github.com/jizhang/hello-beam/blob/master/logmining.py" target="_blank" rel="noopener">链接</a>）中找到：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">lines = p | <span class="string">'Create'</span> &gt;&gt; beam.io.ReadFromText(<span class="string">'access.log'</span>)</span><br><span class="line">windowed_counts = (</span><br><span class="line">    lines</span><br><span class="line">    | <span class="string">'Timestamp'</span> &gt;&gt; beam.Map(<span class="keyword">lambda</span> x: beam.window.TimestampedValue(</span><br><span class="line">                              x, extract_timestamp(x)))</span><br><span class="line">    | <span class="string">'Window'</span> &gt;&gt; beam.WindowInto(beam.window.SlidingWindows(<span class="number">600</span>, <span class="number">300</span>))</span><br><span class="line">    | <span class="string">'Count'</span> &gt;&gt; (beam.CombineGlobally(beam.combiners.CountCombineFn())</span><br><span class="line">                  .without_defaults())</span><br><span class="line">)</span><br><span class="line">windowed_counts =  windowed_counts | beam.ParDo(PrintWindowFn())</span><br></pre></td></tr></table></figure><p>首先，我们需要为每一条记录附加上时间戳。自定义函数 <code>extract_timestamp</code> 用以将日志中的时间 <code>[07/Mar/2004:16:05:49 -0800]</code> 转换成 Unix 时间戳，<code>TimestampedValue</code> 则会将这个时间戳和对应记录关联起来。之后，我们定义了一个大小为 <em>10 分钟</em>，间隔为 <em>5 分钟</em> 的滑动窗口（Sliding Window）。从零点开始，第一个窗口的范围是 <code>[00:00, 00:10)</code>，第二个窗口的范围是 <code>[00:05, 00:15)</code>，以此类推。所有窗口的长度都是 <em>10 分钟</em>，相邻两个窗口之间相隔 <em>5 分钟</em>。滑动窗口和固定窗口（Fixed Window）不同，因为相同的元素可能会落入不同的窗口中参与计算。最后，我们使用一个合并函数计算每个窗口中的记录数。通过这个方法得到前五条记录的计算结果为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[2004-03-08T00:00:00Z, 2004-03-08T00:10:00Z) @ 2</span><br><span class="line">[2004-03-08T00:05:00Z, 2004-03-08T00:15:00Z) @ 4</span><br><span class="line">[2004-03-08T00:10:00Z, 2004-03-08T00:20:00Z) @ 2</span><br><span class="line">[2004-03-08T00:15:00Z, 2004-03-08T00:25:00Z) @ 1</span><br><span class="line">[2004-03-08T00:20:00Z, 2004-03-08T00:30:00Z) @ 1</span><br></pre></td></tr></table></figure><p>在无界数据的实时计算过程中，事件数据的接收顺序是不固定的，因此需要利用 Beam 的水位线和触发器机制来处理延迟数据（Late Data）。这个话题比较复杂，而且 Python SDK 尚未支持这些特性，感兴趣的读者可以参考 Stream <a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101" target="_blank" rel="noopener">101</a> 和 <a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-102" target="_blank" rel="noopener">102</a> 这两篇文章。</p><h2 id="Pipeline-运行时"><a href="#Pipeline-运行时" class="headerlink" title="Pipeline 运行时"></a>Pipeline 运行时</h2><p>上文中提到，Apache Beam 是一个数据处理标准，只提供了 SDK 和 API，因而必须使用 Spark、Flink 这样的计算引擎来运行它。下表列出了当前支持 Beam Model 的引擎，以及他们的兼容程度：</p><p><img src="/cnblogs/images/beam/matrix.png" alt="Beam 运行时能力矩阵"></p><p><a href="https://beam.apache.org/documentation/runners/capability-matrix/" target="_blank" rel="noopener">图片来源</a></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://beam.apache.org/documentation/programming-guide/" target="_blank" rel="noopener">https://beam.apache.org/documentation/programming-guide/</a></li><li><a href="https://beam.apache.org/documentation/sdks/pydoc/2.1.0/" target="_blank" rel="noopener">https://beam.apache.org/documentation/sdks/pydoc/2.1.0/</a></li><li><a href="https://sookocheff.com/post/dataflow/get-to-know-dataflow/" target="_blank" rel="noopener">https://sookocheff.com/post/dataflow/get-to-know-dataflow/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://beam.apache.org/get-started/beam-overview/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Apache Beam&lt;/a&gt; 是一种大数据处理标准，由谷歌于 2016 年创建。它提供了一套统一的 DSL 用以处理离线和实时数据，并能在目前主流的大数据处理平台上使用，包括 Spark、Flink、以及谷歌自身的商业套件 Dataflow。Beam 的数据模型基于过去的几项研究成果：&lt;a href=&quot;https://web.archive.org/web/20160923141630/https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35650.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;FlumeJava&lt;/a&gt;、&lt;a href=&quot;https://web.archive.org/web/20160201091359/http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41378.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Millwheel&lt;/a&gt;，适用场景包括 ETL、统计分析、实时计算等。目前，Beam 提供了两种语言的 SDK：Java、Python。本文将讲述如何使用 Python 编写 Beam 应用程序。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/cnblogs/images/beam/arch.jpg&quot; alt=&quot;Apache Beam Pipeline&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装-Apache-Beam&quot;&gt;&lt;a href=&quot;#安装-Apache-Beam&quot; class=&quot;headerlink&quot; title=&quot;安装 Apache Beam&quot;&gt;&lt;/a&gt;安装 Apache Beam&lt;/h2&gt;&lt;p&gt;Apache Beam Python SDK 必须使用 Python 2.7.x 版本，你可以安装 &lt;a href=&quot;https://github.com/pyenv/pyenv&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;pyenv&lt;/a&gt; 来管理不同版本的 Python，或者直接从&lt;a href=&quot;https://www.python.org/downloads/source/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;源代码&lt;/a&gt;编译安装（需要支持 SSL）。之后，你便可以在 Python 虚拟环境中安装 Beam SDK 了：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ virtualenv venv --distribute&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ source venv/bin/activate&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;(venv) $ pip install apache-beam&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/cnblogs/categories/Big-Data/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/cnblogs/tags/python/"/>
    
      <category term="mapreduce" scheme="http://shzhangji.com/cnblogs/tags/mapreduce/"/>
    
      <category term="stream processing" scheme="http://shzhangji.com/cnblogs/tags/stream-processing/"/>
    
      <category term="apache beam" scheme="http://shzhangji.com/cnblogs/tags/apache-beam/"/>
    
  </entry>
  
  <entry>
    <title>2017 Top 15 Python 数据科学类库；时间序列异常点检测；如何加入开源项目</title>
    <link href="http://shzhangji.com/cnblogs/2017/09/06/python-data-science-anomaly-detection-opensource/"/>
    <id>http://shzhangji.com/cnblogs/2017/09/06/python-data-science-anomaly-detection-opensource/</id>
    <published>2017-09-06T01:49:10.000Z</published>
    <updated>2017-09-06T02:00:41.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2017-Top-15-Python-数据科学类库"><a href="#2017-Top-15-Python-数据科学类库" class="headerlink" title="2017 Top 15 Python 数据科学类库"></a>2017 Top 15 Python 数据科学类库</h2><p><img src="/cnblogs/images/digest/google-trends.png" alt="Google Trends"></p><p>近年来，Python 在数据科学领域得到了越来越多的关注，本文整理归类了使用率最高的数据科学类库，供大家参考。</p><p>NumPy、SciPy、Pandas 是 Python 数据科学的核心类库。NumPy 提供了 N 维数组、矩阵、向量等数据结构，能够进行高性能的数学运算；SciPy 包含了线性代数、拟合优化、统计学习的通用方法；Pandas 则一般用于数据清洗、探索型分析等工作。</p><p>可视化方面，Matplotlib 是最早流行的类库，提供了丰富的图形化接口，但 API 的使用方式偏底层，需要编写较多代码；Seaborn 构建在 Matplotlib 之上，重新定义了图表样式，更适合在报告、演示文档中使用，并且它还预置了诸多探索型分析函数，可以快速地对数据进行描述性可视化；Bokeh 主打交互性，它运行在浏览器中，让使用者可以方便地调节可视化参数；Plotly 也是一款基于页面的可视化工具，但因为是商业软件，需要授权后才能使用。</p><p>SciKit-Learn 是公认的 Python 机器学习标准类库，它提供了准确、统一的接口，可以方便地使用各种机器学习算法；深度学习领域，Theano 是比较老牌的类库之一，特点是能够运行于不同的系统架构之上（CPU、GPU）；Tensorflow 则是最近较火的基础类库，使用它提供的各种算子和数据流工具，我们可以构建出多层神经网络，在集群上对大数据进行运算；Keras 则是一款较上层的工具库，底层使用 Theano 或 Tensorflow 作为引擎，可以通过快速构建实验来验证模型。</p><p>自然语言处理领域中，NLTK 提供了文本标记、分词、构建语料树等功能，用以揭示句中或句间的依赖关系；Gensim 则擅长构建向量空间模型、话题建模、挖掘大量文本中重复出现的模式，其算法都属于非监督学习，因此只需提供语料库就能得到结果。</p><p>原文：<a href="http://www.kdnuggets.com/2017/06/top-15-python-libraries-data-science.html" target="_blank" rel="noopener">http://www.kdnuggets.com/2017/06/top-15-python-libraries-data-science.html</a></p><a id="more"></a><h2 id="时间序列数据异常点检测算法"><a href="#时间序列数据异常点检测算法" class="headerlink" title="时间序列数据异常点检测算法"></a>时间序列数据异常点检测算法</h2><p><img src="/cnblogs/images/digest/anomaly-detection-cart.png" alt=""></p><p>异常点检测是指寻找那些偏离标准值或正常值的数据点。异常点有几种常见的类型：短期内产生的峰值，包括最大值、最小值、以及零值；长期的数据合计与上一周期的比较等。检测方法也可以归类为两种：对数据点进行分类，标记异常与否；或是对未来数据走势做预测，给出置信区间。</p><p>使用 STL 分解法将时间序列数据表示成三个要素：季节性、趋势、残差。通过分析残差的背离程度，引入一定的阈值，就可以作为预警依据了。我们可以使用绝对中位差来作为阈值，推特使用并开源了相关类库（<a href="https://github.com/twitter/AnomalyDetection" target="_blank" rel="noopener">链接</a>）。这种方法的优点是简单，对峰值异常较敏感，并能结合滑动平均来检测周期性的异常。缺点是需要进行调参，且不能检测剧烈变动的指标。</p><p>分类和回归树算法有两种使用方式：一种是准备好已标记过异常点的数据集，进行监督型的机器学习；另一种则是让 CART 算法自动寻找数据集中的模式，预测异常点的置信区间。最常用的开源库是 <a href="https://github.com/dmlc/xgboost" target="_blank" rel="noopener">xgboost</a>。这一方法可以用各种特征进行学习和预测，当然计算量也会因此上升。</p><p>ARIMA 是一种较为简单的算法，通过历史值来预测下一个数据点的动向。它的特点是每接收一个新的数据点都需要重新构建一次预测模型，并且你的数据必须和时间是无关的。和该算法相似的是指数平滑法，比较有趣的实现是 <a href="https://www.otexts.org/fpp/7/5" target="_blank" rel="noopener">Holt-Winters 季节性指标</a>，用于检测阶段性长期趋势的异常。</p><p>人工神经网络也能够进行异常检测，只是这一方式还处于<a href="https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2015-56.pdf" target="_blank" rel="noopener">科研阶段</a>。不过我们想要提醒读者的是，尽量从简单的模型开始，针对你的具体问题进行优化，因为通用的算法并不一定是最优的。</p><p>原文：<a href="https://blog.statsbot.co/time-series-anomaly-detection-algorithms-1cef5519aef2" target="_blank" rel="noopener">https://blog.statsbot.co/time-series-anomaly-detection-algorithms-1cef5519aef2</a></p><h2 id="如何加入开源项目"><a href="#如何加入开源项目" class="headerlink" title="如何加入开源项目"></a>如何加入开源项目</h2><p><img src="/cnblogs/images/digest/opensource.jpg" alt="opensource"></p><p>已经蠢蠢欲动了吗？不如马上开始！找一个你正在使用的开源项目，Fork 源码仓库。先从修复 Bug 开始，或者为现有代码编写单元测试。过程中你需要学会读懂别人的代码，遵循代码规范。提交补丁后，你一定会受到猛烈的抨击，千万不要因此胆怯。熟悉代码之后，可以寻求一些更重要的职责，比如提出一个新的特性，或者认领新特性的开发工作。最后，你也可以开启自己的开源项目。</p><p>如何寻找自己想做贡献的开源项目？首先你可以在邮件列表、论坛、Bug 跟踪系统中找到这样的项目，问问自己是否喜欢这里的社区氛围。一开始不要在一棵树上吊死，多观察几个开源项目，找到自己对味的。从小处着手，比如重现 Bug、提交测试代码、改进文档等等。中途不要放弃！</p><p>最直接的加入方式其实是当正在使用的某个项目出现 Bug，或者你有用的不爽的地方，对它加以改进。此外，加入一个对开源项目友好的公司也是不错的选择。</p><p>原文：<a href="https://arstechnica.com/information-technology/2012/03/ask-stack-how-can-i-find-a-good-open-source-project-to-join/" target="_blank" rel="noopener">https://arstechnica.com/information-technology/2012/03/ask-stack-how-can-i-find-a-good-open-source-project-to-join/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;2017-Top-15-Python-数据科学类库&quot;&gt;&lt;a href=&quot;#2017-Top-15-Python-数据科学类库&quot; class=&quot;headerlink&quot; title=&quot;2017 Top 15 Python 数据科学类库&quot;&gt;&lt;/a&gt;2017 Top 15 Python 数据科学类库&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/cnblogs/images/digest/google-trends.png&quot; alt=&quot;Google Trends&quot;&gt;&lt;/p&gt;
&lt;p&gt;近年来，Python 在数据科学领域得到了越来越多的关注，本文整理归类了使用率最高的数据科学类库，供大家参考。&lt;/p&gt;
&lt;p&gt;NumPy、SciPy、Pandas 是 Python 数据科学的核心类库。NumPy 提供了 N 维数组、矩阵、向量等数据结构，能够进行高性能的数学运算；SciPy 包含了线性代数、拟合优化、统计学习的通用方法；Pandas 则一般用于数据清洗、探索型分析等工作。&lt;/p&gt;
&lt;p&gt;可视化方面，Matplotlib 是最早流行的类库，提供了丰富的图形化接口，但 API 的使用方式偏底层，需要编写较多代码；Seaborn 构建在 Matplotlib 之上，重新定义了图表样式，更适合在报告、演示文档中使用，并且它还预置了诸多探索型分析函数，可以快速地对数据进行描述性可视化；Bokeh 主打交互性，它运行在浏览器中，让使用者可以方便地调节可视化参数；Plotly 也是一款基于页面的可视化工具，但因为是商业软件，需要授权后才能使用。&lt;/p&gt;
&lt;p&gt;SciKit-Learn 是公认的 Python 机器学习标准类库，它提供了准确、统一的接口，可以方便地使用各种机器学习算法；深度学习领域，Theano 是比较老牌的类库之一，特点是能够运行于不同的系统架构之上（CPU、GPU）；Tensorflow 则是最近较火的基础类库，使用它提供的各种算子和数据流工具，我们可以构建出多层神经网络，在集群上对大数据进行运算；Keras 则是一款较上层的工具库，底层使用 Theano 或 Tensorflow 作为引擎，可以通过快速构建实验来验证模型。&lt;/p&gt;
&lt;p&gt;自然语言处理领域中，NLTK 提供了文本标记、分词、构建语料树等功能，用以揭示句中或句间的依赖关系；Gensim 则擅长构建向量空间模型、话题建模、挖掘大量文本中重复出现的模式，其算法都属于非监督学习，因此只需提供语料库就能得到结果。&lt;/p&gt;
&lt;p&gt;原文：&lt;a href=&quot;http://www.kdnuggets.com/2017/06/top-15-python-libraries-data-science.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.kdnuggets.com/2017/06/top-15-python-libraries-data-science.html&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Digest" scheme="http://shzhangji.com/cnblogs/categories/Digest/"/>
    
    
      <category term="analytics" scheme="http://shzhangji.com/cnblogs/tags/analytics/"/>
    
      <category term="data science" scheme="http://shzhangji.com/cnblogs/tags/data-science/"/>
    
      <category term="opensource" scheme="http://shzhangji.com/cnblogs/tags/opensource/"/>
    
  </entry>
  
  <entry>
    <title>Hive 窗口与分析型函数</title>
    <link href="http://shzhangji.com/cnblogs/2017/09/05/hive-window-and-analytical-functions/"/>
    <id>http://shzhangji.com/cnblogs/2017/09/05/hive-window-and-analytical-functions/</id>
    <published>2017-09-05T04:17:10.000Z</published>
    <updated>2017-09-06T02:18:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>SQL 结构化查询语言是数据分析领域的重要工具之一。它提供了数据筛选、转换、聚合等操作，并能借助 Hive 和 Hadoop 进行大数据量的处理。但是，传统的 SQL 语句并不能支持诸如分组排名、滑动平均值等计算，原因是 <code>GROUP BY</code> 语句只能为每个分组的数据返回一行结果，而非每条数据一行。幸运的是，新版的 SQL 标准引入了窗口查询功能，使用 <code>WINDOW</code> 语句我们可以基于分区和窗口为每条数据都生成一行结果记录，这一标准也已得到了 Hive 的支持。</p><p><img src="/cnblogs/images/hive-window/window-stock.png" alt="滑动平均值"></p><p>举例来说，我们想要计算表中每只股票的两日滑动平均值，可以编写以下查询语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  <span class="string">`date`</span>, <span class="string">`stock`</span>, <span class="string">`close`</span></span><br><span class="line">  ,<span class="keyword">AVG</span>(<span class="string">`close`</span>) <span class="keyword">OVER</span> <span class="string">`w`</span> <span class="keyword">AS</span> <span class="string">`mavg`</span></span><br><span class="line"><span class="keyword">FROM</span> <span class="string">`t_stock`</span></span><br><span class="line">WINDOW <span class="string">`w`</span> <span class="keyword">AS</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="string">`stock`</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="string">`date`</span></span><br><span class="line">               <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">1</span> <span class="keyword">PRECEDING</span> <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="keyword">ROW</span>)</span><br></pre></td></tr></table></figure><p><code>OVER</code>、<code>WINDOW</code>、以及 <code>ROWS BETWEEN AND</code> 都是新增的窗口查询关键字。在这个查询中，<code>PARTITION BY</code> 和 <code>ORDER BY</code> 的工作方式与 <code>GROUP BY</code>、<code>ORDER BY</code> 相似，区别在于它们不会将多行记录聚合成一条结果，而是将它们拆分到互不重叠的分区中进行后续处理。其后的 <code>ROWS BETWEEN AND</code> 语句用于构建一个 <em>窗口帧</em>。此例中，每一个窗口帧都包含了当前记录和上一条记录。下文会对窗口帧做进一步描述。最后，<code>AVG</code> 是一个窗口函数，用于计算每个窗口帧的结果。窗口帧的定义（<code>WINDOW</code> 语句）还可以直接附加到窗口函数之后：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">AVG</span>(<span class="string">`close`</span>) <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="string">`stock`</span>) <span class="keyword">AS</span> <span class="string">`mavg`</span> <span class="keyword">FROM</span> <span class="string">`t_stock`</span>;</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="窗口查询的基本概念"><a href="#窗口查询的基本概念" class="headerlink" title="窗口查询的基本概念"></a>窗口查询的基本概念</h2><p><img src="/cnblogs/images/hive-window/concepts.png" alt="基本概念"></p><p><a href="https://en.wikibooks.org/wiki/Structured_Query_Language/Window_functions" target="_blank" rel="noopener">图片来源</a></p><p>SQL 窗口查询引入了三个新的概念：窗口分区、窗口帧、以及窗口函数。</p><p><code>PARTITION</code> 语句会按照一个或多个指定字段，将查询结果集拆分到不同的 <strong>窗口分区</strong> 中，并可按照一定规则排序。如果没有 <code>PARTITION BY</code>，则整个结果集将作为单个窗口分区；如果没有 <code>ORDER BY</code>，我们则无法定义窗口帧，进而整个分区将作为单个窗口帧进行处理。</p><p><strong>窗口帧</strong> 用于从分区中选择指定的多条记录，供窗口函数处理。Hive 提供了两种定义窗口帧的形式：<code>ROWS</code> 和 <code>RANGE</code>。两种类型都需要配置上界和下界。例如，<code>ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW</code> 表示选择分区起始记录到当前记录的所有行；<code>SUM(close) RANGE BETWEEN 100 PRECEDING AND 200 FOLLOWING</code> 则通过 <em>字段差值</em> 来进行选择。如当前行的 <code>close</code> 字段值是 <code>200</code>，那么这个窗口帧的定义就会选择分区中 <code>close</code> 字段值落在 <code>100</code> 至 <code>400</code> 区间的记录。以下是所有可能的窗口帧定义组合。如果没有定义窗口帧，则默认为 <code>RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(ROWS | RANGE) BETWEEN (UNBOUNDED | [num]) PRECEDING AND ([num] PRECEDING | CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING)</span><br><span class="line">(ROWS | RANGE) BETWEEN CURRENT ROW AND (CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING)</span><br><span class="line">(ROWS | RANGE) BETWEEN [num] FOLLOWING AND (UNBOUNDED | [num]) FOLLOWING</span><br></pre></td></tr></table></figure><p><strong>窗口函数</strong> 会基于当前窗口帧的记录计算结果。Hive 提供了以下窗口函数：</p><ul><li><code>FIRST_VALUE(col)</code>, <code>LAST_VALUE(col)</code> 可以返回窗口帧中第一条或最后一条记录的指定字段值；</li><li><code>LEAD(col, n)</code>, <code>LAG(col, n)</code> 返回当前记录的上 <code>n</code> 条或下 <code>n</code> 条记录的字段值；</li><li><code>RANK()</code>, <code>ROW_NUMBER()</code> 会为帧内的每一行返回一个序数，区别在于存在字段值相等的记录时，<code>RANK()</code> 会返回相同的序数；</li><li><code>COUNT()</code>, <code>SUM(col)</code>, <code>MIN(col)</code> 和一般的聚合操作相同。</li></ul><h2 id="Hive-窗口查询示例"><a href="#Hive-窗口查询示例" class="headerlink" title="Hive 窗口查询示例"></a>Hive 窗口查询示例</h2><h3 id="Top-K"><a href="#Top-K" class="headerlink" title="Top K"></a>Top K</h3><p>首先，我们在 Hive 中创建一些有关员工收入的模拟数据：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t_employee (<span class="keyword">id</span> <span class="built_in">INT</span>, emp_name <span class="built_in">VARCHAR</span>(<span class="number">20</span>), dep_name <span class="built_in">VARCHAR</span>(<span class="number">20</span>),</span><br><span class="line">salary <span class="built_in">DECIMAL</span>(<span class="number">7</span>, <span class="number">2</span>), age <span class="built_in">DECIMAL</span>(<span class="number">3</span>, <span class="number">0</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t_employee <span class="keyword">VALUES</span></span><br><span class="line">( <span class="number">1</span>,  <span class="string">'Matthew'</span>, <span class="string">'Management'</span>,  <span class="number">4500</span>, <span class="number">55</span>),</span><br><span class="line">( <span class="number">2</span>,  <span class="string">'Olivia'</span>,  <span class="string">'Management'</span>,  <span class="number">4400</span>, <span class="number">61</span>),</span><br><span class="line">( <span class="number">3</span>,  <span class="string">'Grace'</span>,   <span class="string">'Management'</span>,  <span class="number">4000</span>, <span class="number">42</span>),</span><br><span class="line">( <span class="number">4</span>,  <span class="string">'Jim'</span>,     <span class="string">'Production'</span>,  <span class="number">3700</span>, <span class="number">35</span>),</span><br><span class="line">( <span class="number">5</span>,  <span class="string">'Alice'</span>,   <span class="string">'Production'</span>,  <span class="number">3500</span>, <span class="number">24</span>),</span><br><span class="line">( <span class="number">6</span>,  <span class="string">'Michael'</span>, <span class="string">'Production'</span>,  <span class="number">3600</span>, <span class="number">28</span>),</span><br><span class="line">( <span class="number">7</span>,  <span class="string">'Tom'</span>,     <span class="string">'Production'</span>,  <span class="number">3800</span>, <span class="number">35</span>),</span><br><span class="line">( <span class="number">8</span>,  <span class="string">'Kevin'</span>,   <span class="string">'Production'</span>,  <span class="number">4000</span>, <span class="number">52</span>),</span><br><span class="line">( <span class="number">9</span>,  <span class="string">'Elvis'</span>,   <span class="string">'Service'</span>,     <span class="number">4100</span>, <span class="number">40</span>),</span><br><span class="line">(<span class="number">10</span>,  <span class="string">'Sophia'</span>,  <span class="string">'Sales'</span>,       <span class="number">4300</span>, <span class="number">36</span>),</span><br><span class="line">(<span class="number">11</span>,  <span class="string">'Samantha'</span>,<span class="string">'Sales'</span>,       <span class="number">4100</span>, <span class="number">38</span>);</span><br></pre></td></tr></table></figure><p>我们可以使用 <code>RANK()</code> 函数计算每个部门中谁的收入最高：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> dep_name, emp_name, salary</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">  <span class="keyword">SELECT</span></span><br><span class="line">    dep_name, emp_name, salary</span><br><span class="line">    ,<span class="keyword">RANK</span>() <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> dep_name <span class="keyword">ORDER</span> <span class="keyword">BY</span> salary <span class="keyword">DESC</span>) <span class="keyword">AS</span> rnk</span><br><span class="line">  <span class="keyword">FROM</span> t_employee</span><br><span class="line">) a</span><br><span class="line"><span class="keyword">WHERE</span> rnk = <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>通常情况下，<code>RANK()</code> 在遇到相同值时会返回同一个排名，并 <em>跳过</em> 下一个排名序数。如果想保证排名连续，可以改用 <code>DENSE_RANK()</code> 这个函数。</p><h3 id="累积分布"><a href="#累积分布" class="headerlink" title="累积分布"></a>累积分布</h3><p>我们可以计算整个公司员工薪水的累积分布。如，<code>4000</code> 元的累计分布百分比是 <code>0.55</code>，表示有 55% 的员工薪资低于或等于 <code>4000</code> 元。计算时，我们先统计不同薪资的频数，再用窗口查询做一次累计求和操作：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  salary</span><br><span class="line">  ,<span class="keyword">SUM</span>(cnt) <span class="keyword">OVER</span> (<span class="keyword">ORDER</span> <span class="keyword">BY</span> salary)</span><br><span class="line">  / <span class="keyword">SUM</span>(cnt) <span class="keyword">OVER</span> (<span class="keyword">ORDER</span> <span class="keyword">BY</span> salary <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="keyword">UNBOUNDED</span> <span class="keyword">PRECEDING</span></span><br><span class="line">                   <span class="keyword">AND</span> <span class="keyword">UNBOUNDED</span> <span class="keyword">FOLLOWING</span>)</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">  <span class="keyword">SELECT</span> salary, <span class="keyword">count</span>(*) <span class="keyword">AS</span> cnt</span><br><span class="line">  <span class="keyword">FROM</span> t_employee</span><br><span class="line">  <span class="keyword">GROUP</span> <span class="keyword">BY</span> salary</span><br><span class="line">) a;</span><br></pre></td></tr></table></figure><p>我们还可以使用 Hive 提供的 <code>CUME_DIST()</code> 来完成相同的计算。<code>PERCENT_RANK()</code> 函数则可以百分比的形式展现薪资所在排名。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  salary</span><br><span class="line">  ,<span class="keyword">CUME_DIST</span>() <span class="keyword">OVER</span> (<span class="keyword">ORDER</span> <span class="keyword">BY</span> salary) <span class="keyword">AS</span> pct_cum</span><br><span class="line">  ,<span class="keyword">PERCENT_RANK</span>() <span class="keyword">OVER</span> (<span class="keyword">ORDER</span> <span class="keyword">BY</span> salary) <span class="keyword">AS</span> pct_rank</span><br><span class="line"><span class="keyword">FROM</span> t_employee;</span><br></pre></td></tr></table></figure><p><img src="/cnblogs/images/hive-window/employee-pct.png" alt="累积分布"></p><h3 id="点击流会话"><a href="#点击流会话" class="headerlink" title="点击流会话"></a>点击流会话</h3><p>我们可以根据点击流的时间间隔来将它们拆分成不同的会话，如超过 30 分钟认为是一次新的会话。我们还将为每个会话赋上自增 ID：</p><p><img src="/cnblogs/images/hive-window/clickstream.png" alt="点击流"></p><p>首先，在子查询 <code>b</code> 中，我们借助 <code>LAG(col)</code> 函数计算出当前行和上一行的时间差，如果大于 30 分钟则标记为新回话的开始。之后，我们对 <code>new_session</code> 字段做累计求和，从而得到一个递增的 ID 序列。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  ipaddress, clicktime</span><br><span class="line">  ,<span class="keyword">SUM</span>(<span class="keyword">IF</span>(new_session, <span class="number">1</span>, <span class="number">0</span>)) <span class="keyword">OVER</span> x + <span class="number">1</span> <span class="keyword">AS</span> sessionid</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">  <span class="keyword">SELECT</span></span><br><span class="line">    ipaddress, clicktime, ts</span><br><span class="line">    ,ts - LAG(ts) <span class="keyword">OVER</span> w &gt; <span class="number">1800</span> <span class="keyword">AS</span> new_session</span><br><span class="line">  <span class="keyword">FROM</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> *, <span class="keyword">UNIX_TIMESTAMP</span>(clicktime) <span class="keyword">AS</span> ts</span><br><span class="line">    <span class="keyword">FROM</span> t_clickstream</span><br><span class="line">  ) a</span><br><span class="line">  WINDOW w <span class="keyword">AS</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> ipaddress <span class="keyword">ORDER</span> <span class="keyword">BY</span> ts)</span><br><span class="line">) b</span><br><span class="line">WINDOW x <span class="keyword">AS</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> ipaddress <span class="keyword">ORDER</span> <span class="keyword">BY</span> ts);</span><br></pre></td></tr></table></figure><h2 id="窗口查询实现细节"><a href="#窗口查询实现细节" class="headerlink" title="窗口查询实现细节"></a>窗口查询实现细节</h2><p>简单来说，窗口查询有两个步骤：将记录分割成多个分区，然后在各个分区上调用窗口函数。分区过程对于了解 MapReduce 的用户应该很容易理解，Hadoop 会负责对记录进行打散和排序。但是，传统的 UDAF 函数只能为每个分区返回一条记录，而我们需要的是不仅输入数据是一张表，输出数据也是一张表（table-in, table-out），因此 Hive 社区引入了分区表函数（PTF）。</p><p>PTF 顾名思义是运行于分区之上、能够处理分区中的记录并输出多行结果的函数。下方的时序图列出了这个过程中重要的一些类。<code>PTFOperator</code> 会读取已经排好序的数据，创建相应的“输入分区”；<code>WindowTableFunction</code> 则负责管理窗口帧、调用窗口函数（UDAF）、并将结果写入“输出分区”。</p><p><img src="/cnblogs/images/hive-window/window-sequence.png" alt="PTF 时序图"></p><p>HIVE-896（<a href="https://issues.apache.org/jira/browse/HIVE-896" target="_blank" rel="noopener">链接</a>）包含了将分析型函数引入 Hive 的讨论过程；这份演示文档（<a href="https://www.slideshare.net/Hadoop_Summit/analytical-queries-with-hive" target="_blank" rel="noopener">链接</a>）则介绍了当时的主要研发团队是如何设计和实现 PTF 的。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+WindowingAndAnalytics" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+WindowingAndAnalytics</a></li><li><a href="https://github.com/hbutani/SQLWindowing" target="_blank" rel="noopener">https://github.com/hbutani/SQLWindowing</a></li><li><a href="https://content.pivotal.io/blog/time-series-analysis-1-introduction-to-window-functions" target="_blank" rel="noopener">https://content.pivotal.io/blog/time-series-analysis-1-introduction-to-window-functions</a></li><li><a href="https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html" target="_blank" rel="noopener">https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;SQL 结构化查询语言是数据分析领域的重要工具之一。它提供了数据筛选、转换、聚合等操作，并能借助 Hive 和 Hadoop 进行大数据量的处理。但是，传统的 SQL 语句并不能支持诸如分组排名、滑动平均值等计算，原因是 &lt;code&gt;GROUP BY&lt;/code&gt; 语句只能为每个分组的数据返回一行结果，而非每条数据一行。幸运的是，新版的 SQL 标准引入了窗口查询功能，使用 &lt;code&gt;WINDOW&lt;/code&gt; 语句我们可以基于分区和窗口为每条数据都生成一行结果记录，这一标准也已得到了 Hive 的支持。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/cnblogs/images/hive-window/window-stock.png&quot; alt=&quot;滑动平均值&quot;&gt;&lt;/p&gt;
&lt;p&gt;举例来说，我们想要计算表中每只股票的两日滑动平均值，可以编写以下查询语句：&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;`date`&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;`stock`&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;`close`&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  ,&lt;span class=&quot;keyword&quot;&gt;AVG&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;`close`&lt;/span&gt;) &lt;span class=&quot;keyword&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`w`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`mavg`&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`t_stock`&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;WINDOW &lt;span class=&quot;string&quot;&gt;`w`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AS&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`stock`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`date`&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;               &lt;span class=&quot;keyword&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ROW&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;OVER&lt;/code&gt;、&lt;code&gt;WINDOW&lt;/code&gt;、以及 &lt;code&gt;ROWS BETWEEN AND&lt;/code&gt; 都是新增的窗口查询关键字。在这个查询中，&lt;code&gt;PARTITION BY&lt;/code&gt; 和 &lt;code&gt;ORDER BY&lt;/code&gt; 的工作方式与 &lt;code&gt;GROUP BY&lt;/code&gt;、&lt;code&gt;ORDER BY&lt;/code&gt; 相似，区别在于它们不会将多行记录聚合成一条结果，而是将它们拆分到互不重叠的分区中进行后续处理。其后的 &lt;code&gt;ROWS BETWEEN AND&lt;/code&gt; 语句用于构建一个 &lt;em&gt;窗口帧&lt;/em&gt;。此例中，每一个窗口帧都包含了当前记录和上一条记录。下文会对窗口帧做进一步描述。最后，&lt;code&gt;AVG&lt;/code&gt; 是一个窗口函数，用于计算每个窗口帧的结果。窗口帧的定义（&lt;code&gt;WINDOW&lt;/code&gt; 语句）还可以直接附加到窗口函数之后：&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AVG&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;`close`&lt;/span&gt;) &lt;span class=&quot;keyword&quot;&gt;OVER&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`stock`&lt;/span&gt;) &lt;span class=&quot;keyword&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`mavg`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`t_stock`&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/cnblogs/categories/Big-Data/"/>
    
    
      <category term="hive" scheme="http://shzhangji.com/cnblogs/tags/hive/"/>
    
      <category term="analytics" scheme="http://shzhangji.com/cnblogs/tags/analytics/"/>
    
      <category term="sql" scheme="http://shzhangji.com/cnblogs/tags/sql/"/>
    
  </entry>
  
  <entry>
    <title>实时计算工具库 stream-lib 使用指南</title>
    <link href="http://shzhangji.com/cnblogs/2017/08/27/an-introduction-to-stream-lib-the-stream-processing-utilities/"/>
    <id>http://shzhangji.com/cnblogs/2017/08/27/an-introduction-to-stream-lib-the-stream-processing-utilities/</id>
    <published>2017-08-27T05:47:16.000Z</published>
    <updated>2017-08-28T00:58:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>进行大数据处理时，计算唯一值、95% 分位数等操作非常占用空间和时间。但有时我们只是想对数据集有一个概略的了解，数值的准确性并不那么重要。实时监控系统中也是如此，可以容忍一定的错误率。目前已经有许多算法可以通过牺牲准确性来减少计算所需的空间和时间，这些算法大多支持数据结构之间的合并，因此可以方便地用在实时计算中。<a href="https://github.com/addthis/stream-lib" target="_blank" rel="noopener"><code>stream-lib</code></a> 就是一个集成了很多此类算法的实时计算工具库，是对现有研究成果的 Java 实现。本文就将介绍这一工具库的使用方法。</p><h2 id="唯一值计算-HyperLogLog"><a href="#唯一值计算-HyperLogLog" class="headerlink" title="唯一值计算 HyperLogLog"></a>唯一值计算 <code>HyperLogLog</code></h2><p>独立访客（UV）是网站的重要指标之一。我们通常会为每一个用户生成一个 UUID，并在 HTTP Cookie 中记录和跟踪，或直接使用 IP 地址做近似计算。我们可以使用一个 <code>HashSet</code> 来计算 UV 的准确值，但无疑会占用大量的空间。<code>HyperLogLog</code> 则是一种近似算法，用于解决此类唯一值计算的问题。该算法<a href="https://en.wikipedia.org/wiki/HyperLogLog" target="_blank" rel="noopener">在对超过 10^9 个唯一值进行计算时可以做到 2% 的标准差，并只占用 1.5 kB 内存</a>。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.clearspring.analytics<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>stream<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ICardinality card = <span class="keyword">new</span> HyperLogLog(<span class="number">10</span>);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i : <span class="keyword">new</span> <span class="keyword">int</span>[] &#123; <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span> &#125;) &#123;</span><br><span class="line">    card.offer(i);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(card.cardinality()); <span class="comment">// 4</span></span><br></pre></td></tr></table></figure><a id="more"></a><p><code>HyperLogLog</code> 会计算每一个成员二进制值首位有多少个零，如果零的最大个数是 <code>n</code>，则唯一值数量就是 <code>2^n</code>。算法中有两个关键点，首先，成员的值必须是服从正态分布的，这一点可以通过哈希函数实现。<code>stream-lib</code> 使用的是 <a href="https://en.wikipedia.org/wiki/MurmurHash" target="_blank" rel="noopener">MurmurHash</a>，它简单、快速、且符合分布要求，应用于多种基于哈希查询的算法。其次，为了降低计算结果的方差，集合成员会先被拆分成多个子集合，最后的唯一值数量是各个子集合结果的调和平均数。上文代码中，我们传递给 <code>HyperLogLog</code> 构造函数的整型参数就表示会采用多少个二进制位来进行分桶。最后，准确性可以通过这个公式计算：<code>1.04/sqrt(2^log2m)</code>。</p><p><code>HyperLogLog</code> 是对 <code>LogLog</code> 算法的扩展，而 <code>HyperLogLogPlus</code> 则包含了更多优化策略。比如，它使用了 64 位的哈希函数，以减少哈希碰撞；对于唯一值数较小的集合，会引入纠偏机制；此外，它还对子集合的存储方式做了改进，能够从稀疏型的数据结构逐渐扩展为密集型。这几种算法都已包含在 <code>stream-lib</code> 中。</p><h2 id="集合成员测试-BloomFilter"><a href="#集合成员测试-BloomFilter" class="headerlink" title="集合成员测试 BloomFilter"></a>集合成员测试 <code>BloomFilter</code></h2><p><img src="/cnblogs/images/stream-lib/bloom-filter.jpg" alt="Bloom Filter"></p><p><code>BloomFilter</code> 用于检测一个元素是否包含在集合中，是一种广泛应用的数据结构。它的特点是有一定几率误报（False Positive Probability, FPP），但绝不会漏报（False Negative）。举例来说，Chrome 在检测恶意 URL 时，会在本地维护一个布隆过滤器。当用户输入一个 URL 时，如果布隆过滤器说它不在恶意网址库里，则它一定不在；如果返回结果为真，则 Chrome 会进一步请求服务器以确认是否的确是恶意网址，并提示给用户。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Filter filter = <span class="keyword">new</span> BloomFilter(<span class="number">100</span>, <span class="number">0.01</span>);</span><br><span class="line">filter.add(<span class="string">"google.com"</span>);</span><br><span class="line">filter.add(<span class="string">"twitter.com"</span>);</span><br><span class="line">filter.add(<span class="string">"facebook.com"</span>);</span><br><span class="line">System.out.println(filter.isPresent(<span class="string">"bing.com"</span>)); <span class="comment">// false</span></span><br></pre></td></tr></table></figure><p>布隆过滤器的构造过程比较简单：</p><ul><li>创建一个包含 <code>n</code> 个元素的位数组，Java 中可以直接使用 <a href="https://docs.oracle.com/javase/8/docs/api/java/util/BitSet.html" target="_blank" rel="noopener"><code>BitSet</code></a>；</li><li>使用 <code>k</code> 个哈希函数对新元素进行处理，结果更新到数组的对应位置中；</li><li>当需要测试一个元素是否在集合中时，同样进行 <code>k</code> 次哈希：<ul><li>若哈希结果的每一位都命中了，那这个元素就有可能会在集合中（False Positive）；</li><li>如果不是所有的比特位都命中，则该元素一定不在集合中。</li></ul></li></ul><p>同样，这些哈希函数必须是服从正态分布的，且要做到两两之间相互独立。Murmur 哈希算法能够满足这一要求。FPP 的计算公式为 <code>(1-e^(-kn/m))^k</code>，这个页面（<a href="https://llimllib.github.io/bloomfilter-tutorial/" target="_blank" rel="noopener">链接</a>）提供了在线的布隆过滤器可视化过程。这一算法的其它应用场景有：邮件服务器中用来判别垃圾发件人；Cassandra、HBase 会用它来过滤不存在的记录行；Squid 则基于布隆过滤器实现了<a href="https://wiki.squid-cache.org/SquidFaq/CacheDigests" target="_blank" rel="noopener">缓存摘要</a>。</p><h2 id="Top-K-排名-CountMinSketch"><a href="#Top-K-排名-CountMinSketch" class="headerlink" title="Top K 排名 CountMinSketch"></a>Top K 排名 <code>CountMinSketch</code></h2><p><img src="/cnblogs/images/stream-lib/count-min-sketch.png" alt="Count Min Sketch"></p><p><a href="https://stackoverflow.com/a/35356116/1030720" target="_blank" rel="noopener">图片来源</a></p><p><a href="https://en.wikipedia.org/wiki/Count%E2%80%93min_sketch" target="_blank" rel="noopener"><code>CountMinSketch</code></a> 是一种“速写”算法，能够使用较小的空间勾勒出数据集内各类事件的频次。比如，我们可以统计出当前最热门的推特内容，或是计算网站访问量最大的页面。当然，这一算法同样会牺牲一定的准确性。</p><p>下面这段代码演示的是如何使用 <code>stream-lib</code> 来统计数据量最多的记录：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">List&lt;String&gt; animals;</span><br><span class="line">IFrequency freq = <span class="keyword">new</span> CountMinSketch(<span class="number">10</span>, <span class="number">5</span>, <span class="number">0</span>);</span><br><span class="line">Map&lt;String, Long&gt; top = Collections.emptyMap();</span><br><span class="line"><span class="keyword">for</span> (String animal : animals) &#123;</span><br><span class="line">    freq.add(animal, <span class="number">1</span>);</span><br><span class="line">    top = Stream.concat(top.keySet().stream(), Stream.of(animal)).distinct()</span><br><span class="line">              .map(a -&gt; <span class="keyword">new</span> SimpleEntry&lt;String, Long&gt;(a, freq.estimateCount(a)))</span><br><span class="line">              .sorted(Comparator.comparing(SimpleEntry&lt;String, Long&gt;::getValue).reversed())</span><br><span class="line">              .limit(<span class="number">3</span>)</span><br><span class="line">              .collect(Collectors.toMap(SimpleEntry::getKey, SimpleEntry::getValue));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">System.out.println(top); <span class="comment">// &#123;rabbit=25, bird=45, spider=35&#125;</span></span><br></pre></td></tr></table></figure><p><code>CountMinSketch#estimateCount</code> 方法又称为 <em>点查询</em> ，用来读取“速写”中某一事件的频次。由于数据结构中无法记录具体的值，我们需要在另行编写代码来实现。</p><p><code>CountMinSketch</code> 的数据结构和布隆过滤器类似，只不过它会使用 <code>d</code> 个 <code>w</code> 位的数组，从而组成一个 <code>d x w</code> 的矩阵。加入新值时，该算法会对其应用 <code>d</code> 个哈希函数，并更新到矩阵的相应位置。这些哈希函数只需做到<a href="https://en.wikipedia.org/wiki/Pairwise_independence" target="_blank" rel="noopener">两两独立</a>即可，因此 <code>stream-lib</code> 使用了一种简单而快速的算法：<code>(a*x+b) mod p</code>。在进行 <em>点查询</em> 时，同样计算该值的哈希结果，找到矩阵中最小的值，即是它的频次。</p><p>这一算法的误差是 <code>ε = e / w</code>，误差概率是 <code>δ = 1 / e ^ d</code>。因此，我们可以通过增加 <code>w</code> 或 <code>d</code> 来提升计算精度。算法论文可以查看这个<a href="https://web.archive.org/web/20060907232042/http://www.eecs.harvard.edu/~michaelm/CS222/countmin.pdf" target="_blank" rel="noopener">链接</a>。</p><h2 id="分位数计算-T-Digest"><a href="#分位数计算-T-Digest" class="headerlink" title="分位数计算  T-Digest"></a>分位数计算  <code>T-Digest</code></h2><p><img src="/cnblogs/images/stream-lib/t-digest.png" alt="T-Digest"></p><p><a href="https://dataorigami.net/blogs/napkin-folding/19055451-percentile-and-quantile-estimation-of-big-data-the-t-digest" target="_blank" rel="noopener">图片来源</a></p><p>中位数、95% 分位数，这类计算在描述性统计中很常见。相较于平均数，中位数不会受到异常值的影响，但它的计算过程比较复杂，需要保留所有具体值，排序后取得中间位置的数作为结果。<code>T-Digest</code> 算法则通过一定计算，将数据集的分布情况粗略地记录下来，从而估计出指定的分位数值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Random rand = <span class="keyword">new</span> Random();</span><br><span class="line">List&lt;Double&gt; data = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">TDigest digest = <span class="keyword">new</span> TDigest(<span class="number">100</span>);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; ++i) &#123;</span><br><span class="line">    <span class="keyword">double</span> d = rand.nextDouble();</span><br><span class="line">    data.add(d);</span><br><span class="line">    digest.add(d);</span><br><span class="line">&#125;</span><br><span class="line">Collections.sort(data);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">double</span> q : <span class="keyword">new</span> <span class="keyword">double</span>[] &#123; <span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">0.9</span> &#125;) &#123;</span><br><span class="line">    System.out.println(String.format(<span class="string">"quantile=%.1f digest=%.4f exact=%.4f"</span>,</span><br><span class="line">            q, digest.quantile(q), data.get((<span class="keyword">int</span>) (data.size() * q))));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// quantile=0.1 digest=0.0998 exact=0.1003</span></span><br><span class="line"><span class="comment">// quantile=0.5 digest=0.5009 exact=0.5000</span></span><br><span class="line"><span class="comment">// quantile=0.9 digest=0.8994 exact=0.8998</span></span><br></pre></td></tr></table></figure><p><code>T-Digest</code> 的论文可以在这个<a href="https://raw.githubusercontent.com/tdunning/t-digest/master/docs/t-digest-paper/histo.pdf" target="_blank" rel="noopener">链接</a>中找到。简单来说，该算法使用了类似一维 k-means 聚类的过程，将真实的分布情况用若干中心点（Centroid）来描述。此外，不同的 <code>T-Digest</code> 实例之间可以进行合并，得到一个体积略大、但准确性更高的实例，这一点非常适用于并行计算。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我们可以看到，本文提到的大部分算法都是通过牺牲准确性来提升时间与空间的利用效率的。通过对数据集进行“速写”，抓住其中的“特征”，我们就能给出不错的估计结果。<code>stream-lib</code> 以及其它开源项目能够让我们非常便捷地将这类算法应用到实际问题中。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.javadoc.io/doc/com.clearspring.analytics/stream/2.9.5" target="_blank" rel="noopener">https://www.javadoc.io/doc/com.clearspring.analytics/stream/2.9.5</a></li><li><a href="http://www.addthis.com/blog/2011/03/29/new-open-source-stream-summarizing-java-library/" target="_blank" rel="noopener">http://www.addthis.com/blog/2011/03/29/new-open-source-stream-summarizing-java-library/</a></li><li><a href="https://www.mapr.com/blog/some-important-streaming-algorithms-you-should-know-about" target="_blank" rel="noopener">https://www.mapr.com/blog/some-important-streaming-algorithms-you-should-know-about</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;进行大数据处理时，计算唯一值、95% 分位数等操作非常占用空间和时间。但有时我们只是想对数据集有一个概略的了解，数值的准确性并不那么重要。实时监控系统中也是如此，可以容忍一定的错误率。目前已经有许多算法可以通过牺牲准确性来减少计算所需的空间和时间，这些算法大多支持数据结构之间的合并，因此可以方便地用在实时计算中。&lt;a href=&quot;https://github.com/addthis/stream-lib&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;code&gt;stream-lib&lt;/code&gt;&lt;/a&gt; 就是一个集成了很多此类算法的实时计算工具库，是对现有研究成果的 Java 实现。本文就将介绍这一工具库的使用方法。&lt;/p&gt;
&lt;h2 id=&quot;唯一值计算-HyperLogLog&quot;&gt;&lt;a href=&quot;#唯一值计算-HyperLogLog&quot; class=&quot;headerlink&quot; title=&quot;唯一值计算 HyperLogLog&quot;&gt;&lt;/a&gt;唯一值计算 &lt;code&gt;HyperLogLog&lt;/code&gt;&lt;/h2&gt;&lt;p&gt;独立访客（UV）是网站的重要指标之一。我们通常会为每一个用户生成一个 UUID，并在 HTTP Cookie 中记录和跟踪，或直接使用 IP 地址做近似计算。我们可以使用一个 &lt;code&gt;HashSet&lt;/code&gt; 来计算 UV 的准确值，但无疑会占用大量的空间。&lt;code&gt;HyperLogLog&lt;/code&gt; 则是一种近似算法，用于解决此类唯一值计算的问题。该算法&lt;a href=&quot;https://en.wikipedia.org/wiki/HyperLogLog&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;在对超过 10^9 个唯一值进行计算时可以做到 2% 的标准差，并只占用 1.5 kB 内存&lt;/a&gt;。&lt;/p&gt;
&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;com.clearspring.analytics&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;stream&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;2.9.5&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ICardinality card = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; HyperLogLog(&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i : &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;[] &amp;#123; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt; &amp;#125;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    card.offer(i);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;System.out.println(card.cardinality()); &lt;span class=&quot;comment&quot;&gt;// 4&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/cnblogs/categories/Big-Data/"/>
    
    
      <category term="java" scheme="http://shzhangji.com/cnblogs/tags/java/"/>
    
      <category term="stream processing" scheme="http://shzhangji.com/cnblogs/tags/stream-processing/"/>
    
      <category term="algorithm" scheme="http://shzhangji.com/cnblogs/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>使用 Binlog 和 Canal 从 MySQL 抽取数据</title>
    <link href="http://shzhangji.com/cnblogs/2017/08/13/extract-data-from-mysql-with-binlog-and-canal/"/>
    <id>http://shzhangji.com/cnblogs/2017/08/13/extract-data-from-mysql-with-binlog-and-canal/</id>
    <published>2017-08-13T02:06:58.000Z</published>
    <updated>2017-08-14T00:37:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>数据抽取是 ETL 流程的第一步。我们会将数据从 RDBMS 或日志服务器等外部系统抽取至数据仓库，进行清洗、转换、聚合等操作。在现代网站技术栈中，MySQL 是最常见的数据库管理系统，我们会从多个不同的 MySQL 实例中抽取数据，存入一个中心节点，或直接进入 Hive。市面上已有多种成熟的、基于 SQL 查询的抽取软件，如著名的开源项目 <a href="http://sqoop.apache.org/" target="_blank" rel="noopener">Apache Sqoop</a>，然而这些工具并不支持实时的数据抽取。MySQL Binlog 则是一种实时的数据流，用于主从节点之间的数据复制，我们可以利用它来进行数据抽取。借助阿里巴巴开源的 <a href="https://github.com/alibaba/canal" target="_blank" rel="noopener">Canal</a> 项目，我们能够非常便捷地将 MySQL 中的数据抽取到任意目标存储中。</p><p><img src="/cnblogs/images/canal.png" alt="Canal"></p><h2 id="Canal-的组成部分"><a href="#Canal-的组成部分" class="headerlink" title="Canal 的组成部分"></a>Canal 的组成部分</h2><p>简单来说，Canal 会将自己伪装成 MySQL 从节点（Slave），并从主节点（Master）获取 Binlog，解析和贮存后供下游消费端使用。Canal 包含两个组成部分：服务端和客户端。服务端负责连接至不同的 MySQL 实例，并为每个实例维护一个事件消息队列；客户端则可以订阅这些队列中的数据变更事件，处理并存储到数据仓库中。下面我们来看如何快速搭建起一个 Canal 服务。</p><a id="more"></a><h3 id="配置-MySQL-主节点"><a href="#配置-MySQL-主节点" class="headerlink" title="配置 MySQL 主节点"></a>配置 MySQL 主节点</h3><p>MySQL 默认没有开启 Binlog，因此我们需要对 <code>my.cnf</code> 文件做以下修改：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">server-id = 1</span><br><span class="line">log_bin = /path/to/mysql-bin.log</span><br><span class="line">binlog_format = ROW</span><br></pre></td></tr></table></figure><p>注意 <code>binlog_format</code> 必须设置为 <code>ROW</code>, 因为在 <code>STATEMENT</code> 或 <code>MIXED</code> 模式下, Binlog 只会记录和传输 SQL 语句（以减少日志大小），而不包含具体数据，我们也就无法保存了。</p><p>从节点通过一个专门的账号连接主节点，这个账号需要拥有全局的 <code>REPLICATION</code> 权限。我们可以使用 <code>GRANT</code> 命令创建这样的账号：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">SELECT</span>, <span class="keyword">REPLICATION</span> <span class="keyword">SLAVE</span>, <span class="keyword">REPLICATION</span> <span class="keyword">CLIENT</span></span><br><span class="line"><span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'canal'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'canal'</span>;</span><br></pre></td></tr></table></figure><h3 id="启动-Canal-服务端"><a href="#启动-Canal-服务端" class="headerlink" title="启动 Canal 服务端"></a>启动 Canal 服务端</h3><p>从 GitHub 项目发布页中下载 Canal 服务端代码（<a href="https://github.com/alibaba/canal/releases" target="_blank" rel="noopener">链接</a>），配置文件在 <code>conf</code> 文件夹下，有以下目录结构：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">canal.deployer/conf/canal.properties</span><br><span class="line">canal.deployer/conf/instanceA/instance.properties</span><br><span class="line">canal.deployer/conf/instanceB/instance.properties</span><br></pre></td></tr></table></figure><p><code>conf/canal.properties</code> 是主配置文件，如其中的 <code>canal.port</code> 用以指定服务端监听的端口。<code>instanceA/instance.properties</code> 则是各个实例的配置文件，主要的配置项有：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># slaveId 不能与 my.cnf 中的 server-id 项重复</span><br><span class="line">canal.instance.mysql.slaveId = 1234</span><br><span class="line">canal.instance.master.address = 127.0.0.1:3306</span><br><span class="line">canal.instance.dbUsername = canal</span><br><span class="line">canal.instance.dbPassword = canal</span><br><span class="line">canal.instance.connectionCharset = UTF-8</span><br><span class="line"># 订阅实例中所有的数据库和表</span><br><span class="line">canal.instance.filter.regex = .*\\..*</span><br></pre></td></tr></table></figure><p>执行 <code>sh bin/startup.sh</code> 命令开启服务端，在日志文件 <code>logs/example/example.log</code> 中可以看到以下输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Loading properties file from class path resource [canal.properties]</span><br><span class="line">Loading properties file from class path resource [example/instance.properties]</span><br><span class="line">start CannalInstance for 1-example</span><br><span class="line">[destination = example , address = /127.0.0.1:3306 , EventParser] prepare to find start position just show master status</span><br></pre></td></tr></table></figure><h3 id="编写-Canal-客户端"><a href="#编写-Canal-客户端" class="headerlink" title="编写 Canal 客户端"></a>编写 Canal 客户端</h3><p>从服务端消费变更消息时，我们需要创建一个 Canal 客户端，指定需要订阅的数据库和表，并开启轮询。</p><p>首先，在项目中添加 <code>com.alibaba.otter:canal.client</code> 依赖项，构建 <code>CanalConnector</code> 实例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">CanalConnector connector = CanalConnectors.newSingleConnector(</span><br><span class="line">        <span class="keyword">new</span> InetSocketAddress(<span class="string">"127.0.0.1"</span>, <span class="number">11111</span>), <span class="string">"example"</span>, <span class="string">""</span>, <span class="string">""</span>);</span><br><span class="line"></span><br><span class="line">connector.connect();</span><br><span class="line">connector.subscribe(<span class="string">".*\\..*"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    Message message = connector.getWithoutAck(<span class="number">100</span>);</span><br><span class="line">    <span class="keyword">long</span> batchId = message.getId();</span><br><span class="line">    <span class="keyword">if</span> (batchId == -<span class="number">1</span> || message.getEntries().isEmpty()) &#123;</span><br><span class="line">        Thread.sleep(<span class="number">3000</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        printEntries(message.getEntries());</span><br><span class="line">        connector.ack(batchId);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码和连接消息系统很相似。变更事件会批量发送过来，待处理完毕后我们可以 ACK 这一批次，从而避免消息丢失。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// printEntries</span></span><br><span class="line">RowChange rowChange = RowChange.parseFrom(entry.getStoreValue());</span><br><span class="line"><span class="keyword">for</span> (RowData rowData : rowChange.getRowDatasList()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (rowChange.getEventType() == EventType.INSERT) &#123;</span><br><span class="line">      printColumns(rowData.getAfterCollumnList());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>每一个 <code>Entry</code> 代表一组具有相同变更类型的数据列表，如 INSERT 类型、UPDATE、DELETE 等。每一行数据我们都可以获取到各个字段的信息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// printColumns</span></span><br><span class="line">String line = columns.stream()</span><br><span class="line">        .map(column -&gt; column.getName() + <span class="string">"="</span> + column.getValue())</span><br><span class="line">        .collect(Collectors.joining(<span class="string">","</span>));</span><br><span class="line">System.out.println(line);</span><br></pre></td></tr></table></figure><p>完整代码可以在 GitHub 中找到（<a href="https://github.com/jizhang/java-sandbox/blob/blog-canal/src/main/java/com/shzhangji/javasandbox/canal/SimpleClient.java" target="_blank" rel="noopener">链接</a>）。</p><h2 id="加载至数据仓库"><a href="#加载至数据仓库" class="headerlink" title="加载至数据仓库"></a>加载至数据仓库</h2><h3 id="关系型数据库与批量更新"><a href="#关系型数据库与批量更新" class="headerlink" title="关系型数据库与批量更新"></a>关系型数据库与批量更新</h3><p>若数据仓库是基于关系型数据库的，我们可以直接使用 <code>REPLACE</code> 语句将数据变更写入目标表。其中需要注意的是写入性能，在更新较频繁的场景下，我们通常会缓存一段时间的数据，并批量更新至数据库，如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">REPLACE</span> <span class="keyword">INTO</span> <span class="string">`user`</span> (<span class="string">`id`</span>, <span class="string">`name`</span>, <span class="string">`age`</span>, <span class="string">`updated`</span>) <span class="keyword">VALUES</span></span><br><span class="line">(<span class="number">1</span>, <span class="string">'Jerry'</span>, <span class="number">30</span>, <span class="string">'2017-08-12 16:00:00'</span>),</span><br><span class="line">(<span class="number">2</span>, <span class="string">'Mary'</span>, <span class="number">28</span>, <span class="string">'2017-08-12 17:00:00'</span>),</span><br><span class="line">(<span class="number">3</span>, <span class="string">'Tom'</span>, <span class="number">36</span>, <span class="string">'2017-08-12 18:00:00'</span>);</span><br></pre></td></tr></table></figure><p>另一种方式是将数据变更写入按分隔符分割的文本文件，并用 <code>LOAD DATA</code> 语句载入数据库。这些文件也可以用在需要写入 Hive 的场景中。不管使用哪一种方法，请一定注意要对字符串类型的字段进行转义，避免导入时出错。</p><h3 id="基于-Hive-的数据仓库"><a href="#基于-Hive-的数据仓库" class="headerlink" title="基于 Hive 的数据仓库"></a>基于 Hive 的数据仓库</h3><p>Hive 表保存在 HDFS 上，该文件系统不支持修改，因此我们需要一些额外工作来写入数据变更。常用的方式包括：JOIN、Hive 事务、或改用 HBase。</p><p>数据可以归类成基础数据和增量数据。如昨日的 <code>user</code> 表是基础数据，今日变更的行是增量数据。通过 <code>FULL OUTER JOIN</code>，我们可以将基础和增量数据合并成一张最新的数据表，并作为明天的基础数据：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  <span class="keyword">COALESCE</span>(b.<span class="string">`id`</span>, a.<span class="string">`id`</span>) <span class="keyword">AS</span> <span class="string">`id`</span></span><br><span class="line">  ,<span class="keyword">COALESCE</span>(b.<span class="string">`name`</span>, a.<span class="string">`name`</span>) <span class="keyword">AS</span> <span class="string">`name`</span></span><br><span class="line">  ,<span class="keyword">COALESCE</span>(b.<span class="string">`age`</span>, a.<span class="string">`age`</span>) <span class="keyword">AS</span> <span class="string">`age`</span></span><br><span class="line">  ,<span class="keyword">COALESCE</span>(b.<span class="string">`updated`</span>, a.<span class="string">`updated`</span>) <span class="keyword">AS</span> <span class="string">`updated`</span></span><br><span class="line"><span class="keyword">FROM</span> dw_stage.<span class="string">`user`</span> a</span><br><span class="line"><span class="keyword">FULL</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> (</span><br><span class="line">  <span class="comment">-- 增量数据会包含重复数据，因此需要选择最新的那一条</span></span><br><span class="line">  <span class="keyword">SELECT</span> <span class="string">`id`</span>, <span class="string">`name`</span>, <span class="string">`age`</span>, <span class="string">`updated`</span></span><br><span class="line">  <span class="keyword">FROM</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> *, ROW_NUMBER() <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="string">`id`</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="string">`updated`</span> <span class="keyword">DESC</span>) <span class="keyword">AS</span> <span class="string">`n`</span></span><br><span class="line">    <span class="keyword">FROM</span> dw_stage.<span class="string">`user_delta`</span></span><br><span class="line">  ) b</span><br><span class="line">  <span class="keyword">WHERE</span> <span class="string">`n`</span> = <span class="number">1</span></span><br><span class="line">) b</span><br><span class="line"><span class="keyword">ON</span> a.<span class="string">`id`</span> = b.<span class="string">`id`</span>;</span><br></pre></td></tr></table></figure><p>Hive 0.13 引入了事务和 ACID 表，0.14 开始支持 <code>INSERT</code>、<code>UPDATE</code>、<code>DELETE</code> 语句，Hive 2.0.0 则又新增了 <a href="https://cwiki.apache.org/confluence/display/Hive/HCatalog+Streaming+Mutation+API" target="_blank" rel="noopener">Streaming Mutation API</a>，用以通过编程的方式批量更新 Hive 表中的记录。目前，ACID 表必须使用 ORC 文件格式进行存储，且须按主键进行分桶（Bucket）。Hive 会将变更记录保存在增量文件中，当 <code>OrcInputFormat</code> 读取数据时会自动定位到最新的那条记录。官方案例可以在这个<a href="https://github.com/apache/hive/blob/master/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/ExampleUseCase.java" target="_blank" rel="noopener">链接</a>中查看。</p><p>最后，我们可以使用 HBase 来实现表数据的更新，它是一种 KV 存储系统，同样基于 HDFS。HBase 的数据可以直接为 MapReduce 脚本使用，且 Hive 中可以创建外部映射表指向 HBase。更多信息请查看<a href="http://hbase.apache.org/" target="_blank" rel="noopener">官方网站</a>。</p><h2 id="初始化数据"><a href="#初始化数据" class="headerlink" title="初始化数据"></a>初始化数据</h2><p>数据抽取通常是按需进行的，在新增一张表时，数据源中可能已经有大量原始记录了。常见的做法是手工将这批数据全量导入至目标表中，但我们也可以复用 Canal 这套机制来实现历史数据的抽取。</p><p>首先，我们在数据源库中创建一张辅助表：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`retl_buffer`</span> (</span><br><span class="line">  <span class="keyword">id</span> <span class="built_in">BIGINT</span> AUTO_INCREMENT PRIMARY <span class="keyword">KEY</span></span><br><span class="line">  ,table_name <span class="built_in">VARCHAR</span>(<span class="number">255</span>)</span><br><span class="line">  ,pk_value <span class="built_in">VARCHAR</span>(<span class="number">255</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>当需要全量抽取 <code>user</code> 表时，我们执行以下语句，将所有 <code>user.id</code> 写入辅助表中：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`retl_buffer`</span> (<span class="string">`table_name`</span>, <span class="string">`pk_value`</span>)</span><br><span class="line"><span class="keyword">SELECT</span> <span class="string">'user'</span>, <span class="string">`id`</span> <span class="keyword">FROM</span> <span class="string">`user`</span>;</span><br></pre></td></tr></table></figure><p>Canal 客户端在处理到 <code>retl_buffer</code> 表的数据变更时，可以从中解析出表名和主键的值，直接反查数据源，将数据写入目标表：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="string">"retl_buffer"</span>.equals(entry.getHeader().getTableName())) &#123;</span><br><span class="line">    String tableName = rowData.getAfterColumns(<span class="number">1</span>).getValue();</span><br><span class="line">    String pkValue = rowData.getAfterColumns(<span class="number">2</span>).getValue();</span><br><span class="line">    System.out.println(<span class="string">"SELECT * FROM "</span> + tableName + <span class="string">" WHERE id = "</span> + pkValue);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这一方法在阿里巴巴的另一个开源软件 <a href="https://github.com/alibaba/otter/wiki/Manager%E9%85%8D%E7%BD%AE%E4%BB%8B%E7%BB%8D#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%87%AA-%E7%94%B1-%E9%97%A8" target="_blank" rel="noopener">Otter</a> 中使用。</p><h2 id="Canal-高可用"><a href="#Canal-高可用" class="headerlink" title="Canal 高可用"></a>Canal 高可用</h2><ul><li>Canal 服务端中的实例可以配置一个备用 MySQL，从而能够在双 Master 场景下自动选择正在工作的数据源。注意两台主库都需要打开 <code>log_slave_updates</code> 选项。Canal 会使用自己的心跳机制（定期更新辅助表的记录）来检测主库的存活。</li><li>Canal 自身也有 HA 配置，配合 Zookeeper，我们可以开启多个 Canal 服务端，当某台服务器宕机时，客户端可以从 ZK 中获取新的服务端地址，继续进行消费。更多信息可以参考 <a href="https://github.com/alibaba/canal/wiki/AdminGuide" target="_blank" rel="noopener">Canal AdminGuide</a>。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://github.com/alibaba/canal/wiki" target="_blank" rel="noopener">https://github.com/alibaba/canal/wiki</a></li><li><a href="https://github.com/alibaba/otter/wiki" target="_blank" rel="noopener">https://github.com/alibaba/otter/wiki</a></li><li><a href="https://www.phdata.io/4-strategies-for-updating-hive-tables/" target="_blank" rel="noopener">https://www.phdata.io/4-strategies-for-updating-hive-tables/</a></li><li><a href="https://hortonworks.com/blog/four-step-strategy-incremental-updates-hive/" target="_blank" rel="noopener">https://hortonworks.com/blog/four-step-strategy-incremental-updates-hive/</a></li><li><a href="https://cwiki.apache.org/confluence/display/Hive/Hive+Transactions" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/Hive+Transactions</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;数据抽取是 ETL 流程的第一步。我们会将数据从 RDBMS 或日志服务器等外部系统抽取至数据仓库，进行清洗、转换、聚合等操作。在现代网站技术栈中，MySQL 是最常见的数据库管理系统，我们会从多个不同的 MySQL 实例中抽取数据，存入一个中心节点，或直接进入 Hive。市面上已有多种成熟的、基于 SQL 查询的抽取软件，如著名的开源项目 &lt;a href=&quot;http://sqoop.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Apache Sqoop&lt;/a&gt;，然而这些工具并不支持实时的数据抽取。MySQL Binlog 则是一种实时的数据流，用于主从节点之间的数据复制，我们可以利用它来进行数据抽取。借助阿里巴巴开源的 &lt;a href=&quot;https://github.com/alibaba/canal&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Canal&lt;/a&gt; 项目，我们能够非常便捷地将 MySQL 中的数据抽取到任意目标存储中。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/cnblogs/images/canal.png&quot; alt=&quot;Canal&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Canal-的组成部分&quot;&gt;&lt;a href=&quot;#Canal-的组成部分&quot; class=&quot;headerlink&quot; title=&quot;Canal 的组成部分&quot;&gt;&lt;/a&gt;Canal 的组成部分&lt;/h2&gt;&lt;p&gt;简单来说，Canal 会将自己伪装成 MySQL 从节点（Slave），并从主节点（Master）获取 Binlog，解析和贮存后供下游消费端使用。Canal 包含两个组成部分：服务端和客户端。服务端负责连接至不同的 MySQL 实例，并为每个实例维护一个事件消息队列；客户端则可以订阅这些队列中的数据变更事件，处理并存储到数据仓库中。下面我们来看如何快速搭建起一个 Canal 服务。&lt;/p&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/cnblogs/categories/Big-Data/"/>
    
    
      <category term="mysql" scheme="http://shzhangji.com/cnblogs/tags/mysql/"/>
    
      <category term="etl" scheme="http://shzhangji.com/cnblogs/tags/etl/"/>
    
      <category term="java" scheme="http://shzhangji.com/cnblogs/tags/java/"/>
    
      <category term="canal" scheme="http://shzhangji.com/cnblogs/tags/canal/"/>
    
  </entry>
  
  <entry>
    <title>Apache Flume 如何解析消息中的事件时间</title>
    <link href="http://shzhangji.com/cnblogs/2017/08/06/how-to-extract-event-time-in-apache-flume/"/>
    <id>http://shzhangji.com/cnblogs/2017/08/06/how-to-extract-event-time-in-apache-flume/</id>
    <published>2017-08-06T01:09:06.000Z</published>
    <updated>2017-08-07T04:50:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>数据开发工作中，从上游消息队列抽取数据是一项常规的 ETL 流程。在基于 Hadoop 构建的数据仓库体系中，我们通常会使用 Flume 将事件日志从 Kafka 抽取到 HDFS，然后针对其开发 MapReduce 脚本，或直接创建以时间分区的 Hive 外部表。这项流程中的关键一环是提取日志中的事件时间，因为实时数据通常会包含延迟，且在系统临时宕机的情况下，我们需要追回遗漏的数据，因而使用的时间戳必须是事件产生的时间。Flume 提供的诸多工具能帮助我们非常便捷地实现这一点。</p><p><img src="/cnblogs/images/flume.png" alt="Apache Flume"></p><h2 id="HDFS-Sink-和时间戳头信息"><a href="#HDFS-Sink-和时间戳头信息" class="headerlink" title="HDFS Sink 和时间戳头信息"></a>HDFS Sink 和时间戳头信息</h2><p>以下是一个基本的 HDFS Sink 配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a1.sinks = k1</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path = /user/flume/ds_alog/dt=%Y%m%d</span><br></pre></td></tr></table></figure><p><code>%Y%m%d</code> 是该 Sink 支持的时间占位符，它会使用头信息中 <code>timestamp</code> 的值来替换这些占位符。HDFS Sink 还提供了 <code>hdfs.useLocalTimeStamp</code> 选项，直接使用当前系统时间来替换时间占位符，但这并不是我们想要达到的目的。</p><p>我们还可以使用 Hive Sink 直接将事件日志导入成 Hive 表，它能直接和 Hive 元数据库通信，自动创建表分区，并支持分隔符分隔和 JSON 两种序列化形式。当然，它同样需要一个 <code>timestamp</code> 头信息。不过，我们没有选择 Hive Sink，主要出于以下原因：</p><ul><li>它不支持正则表达式，因此我们无法从类似访问日志这样的数据格式中提取字段列表；</li><li>它所提取的字段列表是根据 Hive 表信息产生的。假设上游数据源在 JSON 日志中加入了新的键值，直至我们主动更新 Hive 元信息，这些新增字段将被直接丢弃。对于数据仓库来说，完整保存原始数据是很有必要的。</li></ul><a id="more"></a><h2 id="正则表达式拦截器"><a href="#正则表达式拦截器" class="headerlink" title="正则表达式拦截器"></a>正则表达式拦截器</h2><p>Flume 提供了拦截器机制，我们可以在 Source 之后接上一系列操作，对数据进行基础的转换。例如，<code>TimestampInterceptor</code> 拦截器可以在消息头信息中增加当前时间。在本节中，我将演示如何借助拦截器来提取访问日志型和 JSON 型消息中的事件时间。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0.123 [2017-06-27 09:08:00] GET /</span><br><span class="line">0.234 [2017-06-27 09:08:01] GET /</span><br></pre></td></tr></table></figure><p><a href="http://flume.apache.org/FlumeUserGuide.html#regex-extractor-interceptor" target="_blank" rel="noopener"><code>RegexExtractorInterceptor</code></a> 可以基于正则表达式来提取字符串，配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a1.sources.r1.interceptors = i1</span><br><span class="line">a1.sources.r1.interceptors.i1.type = regex_extractor</span><br><span class="line">a1.sources.r1.interceptors.i1.regex = \\[(.*?)\\]</span><br><span class="line">a1.sources.r1.interceptors.i1.serializers = s1</span><br><span class="line">a1.sources.r1.interceptors.i1.serializers.s1.type = org.apache.flume.interceptor.RegexExtractorInterceptorMillisSerializer</span><br><span class="line">a1.sources.r1.interceptors.i1.serializers.s1.name = timestamp</span><br><span class="line">a1.sources.r1.interceptors.i1.serializers.s1.pattern = yyyy-MM-dd HH:mm:ss</span><br></pre></td></tr></table></figure><p>它会搜索字符串中满足 <code>\[(.*?)\]</code> 模式的子串，将第一个子模式即 <code>s1</code> 作为日期字符串进行解析，并将其转化成毫秒级时间戳，存入头信息 <code>timestamp</code>。</p><h3 id="搜索与替换拦截器"><a href="#搜索与替换拦截器" class="headerlink" title="搜索与替换拦截器"></a>搜索与替换拦截器</h3><p>对于 JSON 数据:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"actionTime"</span>:<span class="number">1498525680.023</span>,<span class="attr">"actionType"</span>:<span class="string">"pv"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"actionTime"</span>:<span class="number">1498525681.349</span>,<span class="attr">"actionType"</span>:<span class="string">"pv"</span>&#125;</span><br></pre></td></tr></table></figure><p>我们同样可以用正则拦截器将 <code>actionTime</code> 提取出来，但要注意的是该字段的单位是秒，而 HDFS Sink 要求的是毫秒，这就需要我们在提取之间对其进行转换，如直接将 <code>.</code> 去掉。<code>SearchAndReplaceInterceptor</code> 可以做到这一点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a1.sources.r1.interceptors = i1 i2</span><br><span class="line">a1.sources.r1.interceptors.i1.type = search_replace</span><br><span class="line">a1.sources.r1.interceptors.i1.searchPattern = \&quot;actionTime\&quot;:(\\d+)\\.(\\d+)</span><br><span class="line">a1.sources.r1.interceptors.i1.replaceString = \&quot;actionTime\&quot;:$1$2</span><br><span class="line">a1.sources.r1.interceptors.i2.type = regex_extractor</span><br><span class="line">a1.sources.r1.interceptors.i2.regex = \&quot;actionTime\&quot;:(\\d+)</span><br><span class="line">a1.sources.r1.interceptors.i2.serializers = s1</span><br><span class="line">a1.sources.r1.interceptors.i2.serializers.s1.name = timestamp</span><br></pre></td></tr></table></figure><p>这里我们串联了两个拦截器。首先使用正则替换将 <code>1498525680.023</code> 转换成 <code>1498525680023</code>，再用正则提取出 <code>actionTime</code> 并存入头信息。</p><h3 id="自定义拦截器"><a href="#自定义拦截器" class="headerlink" title="自定义拦截器"></a>自定义拦截器</h3><p>我们还可以编写自定义的拦截器，从而一次性完成提取、转换和更新操作。我们只需实现 <code>org.apache.flume.interceptor.Interceptor</code> 接口的 <code>intercept</code> 方法即可，源代码可以在 GitHub（<a href="https://github.com/jizhang/java-sandbox/blob/blog-flume/src/main/java/com/shzhangji/javasandbox/flume/ActionTimeInterceptor.java" target="_blank" rel="noopener">链接</a>）中找到，记得需要添加 <code>flume-ng-core</code> 依赖：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ActionTimeInterceptor</span> <span class="keyword">implements</span> <span class="title">Interceptor</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> ObjectMapper mapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Event <span class="title">intercept</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            JsonNode node = mapper.readTree(<span class="keyword">new</span> ByteArrayInputStream(event.getBody()));</span><br><span class="line">            <span class="keyword">long</span> timestamp = (<span class="keyword">long</span>) (node.get(<span class="string">"actionTime"</span>).getDoubleValue() * <span class="number">1000</span>);</span><br><span class="line">            event.getHeaders().put(<span class="string">"timestamp"</span>, Long.toString(timestamp));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">// no-op</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> event;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="使用-Kafka-Channel-直接导入数据"><a href="#使用-Kafka-Channel-直接导入数据" class="headerlink" title="使用 Kafka Channel 直接导入数据"></a>使用 Kafka Channel 直接导入数据</h2><p>当上游消息系统是 Kafka，并且你能够完全控制消息的数据格式，那就可以省去 Source 一环，直接用 Kafka Channel 将数据导入至 HDFS。其中的关键在于要使用 <code>AvroFlumeEvent</code> 格式来存储消息，这样 <a href="http://flume.apache.org/FlumeUserGuide.html#kafka-channel" target="_blank" rel="noopener">Kafka Channel</a> 才能从消息体中解析出 <code>timestamp</code> 头信息。如果消息内容是纯文本，那下游的 HDFS Sink 就会报时间戳找不到的错误了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 构建 AvroFlumeEvent 消息，该类可以在 flume-ng-sdk 依赖中找到</span></span><br><span class="line">Map&lt;CharSequence, CharSequence&gt; headers = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">headers.put(<span class="string">"timestamp"</span>, <span class="string">"1498525680023"</span>);</span><br><span class="line">String body = <span class="string">"some message"</span>;</span><br><span class="line">AvroFlumeEvent event = <span class="keyword">new</span> AvroFlumeEvent(headers, ByteBuffer.wrap(body.getBytes()));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用 Avro 编码器对消息进行序列化</span></span><br><span class="line">ByteArrayOutputStream out = <span class="keyword">new</span> ByteArrayOutputStream();</span><br><span class="line">BinaryEncoder encoder = EncoderFactory.get().directBinaryEncoder(out, <span class="keyword">null</span>);</span><br><span class="line">SpecificDatumWriter&lt;AvroFlumeEvent&gt; writer = <span class="keyword">new</span> SpecificDatumWriter&lt;&gt;(AvroFlumeEvent.class);</span><br><span class="line">writer.write(event, encoder);</span><br><span class="line">encoder.flush();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 发送字节码至 Kafka</span></span><br><span class="line">producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, <span class="keyword">byte</span>[]&gt;(<span class="string">"alog"</span>, out.toByteArray()));</span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://flume.apache.org/FlumeUserGuide.html" target="_blank" rel="noopener">http://flume.apache.org/FlumeUserGuide.html</a></li><li><a href="https://github.com/apache/flume" target="_blank" rel="noopener">https://github.com/apache/flume</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;数据开发工作中，从上游消息队列抽取数据是一项常规的 ETL 流程。在基于 Hadoop 构建的数据仓库体系中，我们通常会使用 Flume 将事件日志从 Kafka 抽取到 HDFS，然后针对其开发 MapReduce 脚本，或直接创建以时间分区的 Hive 外部表。这项流程中的关键一环是提取日志中的事件时间，因为实时数据通常会包含延迟，且在系统临时宕机的情况下，我们需要追回遗漏的数据，因而使用的时间戳必须是事件产生的时间。Flume 提供的诸多工具能帮助我们非常便捷地实现这一点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/cnblogs/images/flume.png&quot; alt=&quot;Apache Flume&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;HDFS-Sink-和时间戳头信息&quot;&gt;&lt;a href=&quot;#HDFS-Sink-和时间戳头信息&quot; class=&quot;headerlink&quot; title=&quot;HDFS Sink 和时间戳头信息&quot;&gt;&lt;/a&gt;HDFS Sink 和时间戳头信息&lt;/h2&gt;&lt;p&gt;以下是一个基本的 HDFS Sink 配置：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;a1.sinks = k1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;a1.sinks.k1.type = hdfs&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;a1.sinks.k1.hdfs.path = /user/flume/ds_alog/dt=%Y%m%d&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;%Y%m%d&lt;/code&gt; 是该 Sink 支持的时间占位符，它会使用头信息中 &lt;code&gt;timestamp&lt;/code&gt; 的值来替换这些占位符。HDFS Sink 还提供了 &lt;code&gt;hdfs.useLocalTimeStamp&lt;/code&gt; 选项，直接使用当前系统时间来替换时间占位符，但这并不是我们想要达到的目的。&lt;/p&gt;
&lt;p&gt;我们还可以使用 Hive Sink 直接将事件日志导入成 Hive 表，它能直接和 Hive 元数据库通信，自动创建表分区，并支持分隔符分隔和 JSON 两种序列化形式。当然，它同样需要一个 &lt;code&gt;timestamp&lt;/code&gt; 头信息。不过，我们没有选择 Hive Sink，主要出于以下原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;它不支持正则表达式，因此我们无法从类似访问日志这样的数据格式中提取字段列表；&lt;/li&gt;
&lt;li&gt;它所提取的字段列表是根据 Hive 表信息产生的。假设上游数据源在 JSON 日志中加入了新的键值，直至我们主动更新 Hive 元信息，这些新增字段将被直接丢弃。对于数据仓库来说，完整保存原始数据是很有必要的。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/cnblogs/categories/Big-Data/"/>
    
    
      <category term="etl" scheme="http://shzhangji.com/cnblogs/tags/etl/"/>
    
      <category term="java" scheme="http://shzhangji.com/cnblogs/tags/java/"/>
    
      <category term="flume" scheme="http://shzhangji.com/cnblogs/tags/flume/"/>
    
  </entry>
  
  <entry>
    <title>Spark Streaming 中如何实现 Exactly-Once 语义</title>
    <link href="http://shzhangji.com/cnblogs/2017/08/01/how-to-achieve-exactly-once-semantics-in-spark-streaming/"/>
    <id>http://shzhangji.com/cnblogs/2017/08/01/how-to-achieve-exactly-once-semantics-in-spark-streaming/</id>
    <published>2017-08-01T04:54:47.000Z</published>
    <updated>2017-08-01T04:54:47.000Z</updated>
    
    <content type="html"><![CDATA[<p>Exactly-once 语义是实时计算的难点之一。要做到每一条记录只会被处理一次，即使服务器或网络发生故障时也能保证没有遗漏，这不仅需要实时计算框架本身的支持，还对上游的消息系统、下游的数据存储有所要求。此外，我们在编写计算流程时也需要遵循一定规范，才能真正实现 Exactly-once。本文将讲述如何结合 Spark Streaming 框架、Kafka 消息系统、以及 MySQL 数据库来实现 Exactly-once 的实时计算流程。</p><p><img src="http://spark.apache.org/docs/latest/img/streaming-arch.png" alt="Spark Streaming"></p><h2 id="引例"><a href="#引例" class="headerlink" title="引例"></a>引例</h2><p>首先让我们实现一个简单而完整的实时计算流程。我们从 Kafka 接收用户访问日志，解析并提取其中的时间和日志级别，并统计每分钟错误日志的数量，结果保存到 MySQL 中。</p><p>示例日志:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2017-07-30 14:09:08 ERROR some message</span><br><span class="line">2017-07-30 14:09:20 INFO  some message</span><br><span class="line">2017-07-30 14:10:50 ERROR some message</span><br></pre></td></tr></table></figure><p>结果表结构，其中 <code>log_time</code> 字段会截取到分钟级别：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> error_log (</span><br><span class="line">  log_time datetime primary <span class="keyword">key</span>,</span><br><span class="line">  log_count <span class="built_in">int</span> <span class="keyword">not</span> <span class="literal">null</span> <span class="keyword">default</span> <span class="number">0</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure><a id="more"></a><p>Scala 项目通常使用 <code>sbt</code> 来管理。我们将下列依赖添加到 <code>build.sbt</code> 文件中。本例使用的是 Spark 2.2 和 Kafka 0.10，数据库操作类库使用了 ScalikeJDBC 3.0。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scalaVersion := <span class="string">"2.11.11"</span></span><br><span class="line"></span><br><span class="line">libraryDependencies ++= <span class="type">Seq</span>(</span><br><span class="line">  <span class="string">"org.apache.spark"</span> %% <span class="string">"spark-streaming"</span> % <span class="string">"2.2.0"</span> % <span class="string">"provided"</span>,</span><br><span class="line">  <span class="string">"org.apache.spark"</span> %% <span class="string">"spark-streaming-kafka-0-10"</span> % <span class="string">"2.2.0"</span>,</span><br><span class="line">  <span class="string">"org.scalikejdbc"</span> %% <span class="string">"scalikejdbc"</span> % <span class="string">"3.0.1"</span>,</span><br><span class="line">  <span class="string">"mysql"</span> % <span class="string">"mysql-connector-java"</span> % <span class="string">"5.1.43"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>完整的示例代码已上传至 GitHub（<a href="https://github.com/jizhang/spark-sandbox/blob/master/src/main/scala/ExactlyOnce.scala" target="_blank" rel="noopener">链接</a>），下面我仅选取重要的部分加以说明：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 初始化数据库连接</span></span><br><span class="line"><span class="type">ConnectionPool</span>.singleton(<span class="string">"jdbc:mysql://localhost:3306/spark"</span>, <span class="string">"root"</span>, <span class="string">""</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建 Spark Streaming 上下文</span></span><br><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"ExactlyOnce"</span>).setIfMissing(<span class="string">"spark.master"</span>, <span class="string">"local[2]"</span>)</span><br><span class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用 Kafka Direct API 创建 DStream</span></span><br><span class="line"><span class="keyword">val</span> messages = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>](ssc,</span><br><span class="line">   <span class="type">LocationStrategies</span>.<span class="type">PreferConsistent</span>,</span><br><span class="line">   <span class="type">ConsumerStrategies</span>.<span class="type">Subscribe</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="type">Seq</span>(<span class="string">"alog"</span>), kafkaParams))</span><br><span class="line"></span><br><span class="line">messages.foreachRDD &#123; rdd =&gt;</span><br><span class="line">  <span class="comment">// 日志处理</span></span><br><span class="line">  <span class="keyword">val</span> result = rdd.map(_.value)</span><br><span class="line">    .flatMap(parseLog) <span class="comment">// 日志解析函数</span></span><br><span class="line">    .filter(_.level == <span class="string">"ERROR"</span>)</span><br><span class="line">    .map(log =&gt; log.time.truncatedTo(<span class="type">ChronoUnit</span>.<span class="type">MINUTES</span>) -&gt; <span class="number">1</span>)</span><br><span class="line">    .reduceByKey(_ + _)</span><br><span class="line">    .collect()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 结果保存至数据库</span></span><br><span class="line">  <span class="type">DB</span>.autoCommit &#123; <span class="keyword">implicit</span> session =&gt;</span><br><span class="line">    result.foreach &#123; <span class="keyword">case</span> (time, count) =&gt;</span><br><span class="line">      <span class="string">sql""</span><span class="string">"</span></span><br><span class="line"><span class="string">      insert into error_log (log_time, log_count)</span></span><br><span class="line"><span class="string">      value ($&#123;time&#125;, $&#123;count&#125;)</span></span><br><span class="line"><span class="string">      on duplicate key update log_count = log_count + values(log_count)</span></span><br><span class="line"><span class="string">      "</span><span class="string">""</span>.update.apply()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="实时计算语义"><a href="#实时计算语义" class="headerlink" title="实时计算语义"></a>实时计算语义</h2><p>实时计算有三种语义，分别是 At-most-once、At-least-once、以及 Exactly-once。一个典型的 Spark Streaming 应用程序会包含三个处理阶段：接收数据、处理汇总、输出结果。每个阶段都需要做不同的处理才能实现相应的语义。</p><p>对于 <strong>接收数据</strong>，主要取决于上游数据源的特性。例如，从 HDFS 这类支持容错的文件系统中读取文件，能够直接支持 Exactly-once 语义。如果上游消息系统支持 ACK（如RabbitMQ），我们就可以结合 Spark 的 Write Ahead Log 特性来实现 At-least-once 语义。对于非可靠的数据接收器（如 <code>socketTextStream</code>），当 Worker 或 Driver 节点发生故障时就会产生数据丢失，提供的语义也是未知的。而 Kafka 消息系统是基于偏移量（Offset）的，它的 Direct API 可以提供 Exactly-once 语义。</p><p>在使用 Spark RDD 对数据进行 <strong>转换或汇总</strong> 时，我们可以天然获得 Exactly-once 语义，因为 RDD 本身就是一种具备容错性、不变性、以及计算确定性的数据结构。只要数据来源是可用的，且处理过程中没有副作用（Side effect），我们就能一直得到相同的计算结果。</p><p><strong>结果输出</strong> 默认符合 At-least-once 语义，因为 <code>foreachRDD</code> 方法可能会因为 Worker 节点失效而执行多次，从而重复写入外部存储。我们有两种方式解决这一问题，幂等更新和事务更新。下面我们将深入探讨这两种方式。</p><h2 id="使用幂等写入实现-Exactly-once"><a href="#使用幂等写入实现-Exactly-once" class="headerlink" title="使用幂等写入实现 Exactly-once"></a>使用幂等写入实现 Exactly-once</h2><p>如果多次写入会产生相同的结果数据，我们可以认为这类写入操作是幂等的。<code>saveAsTextFile</code> 就是一种典型的幂等写入。如果消息中包含唯一主键，那么多次写入相同的数据也不会在数据库中产生重复记录。这种方式也就能等价于 Exactly-once 语义了。但需要注意的是，幂等写入只适用于 Map-only 型的计算流程，即没有 Shuffle、Reduce、Repartition 等操作。此外，我们还需对 Kafka DStream 做一些额外设置：</p><ul><li>将 <code>enable.auto.commit</code> 设置为 <code>false</code>。默认情况下，Kafka DStream 会在接收到数据后立刻更新自己的偏移量，我们需要将这个动作推迟到计算完成之后。</li><li>打开 Spark Streaming 的 Checkpoint 特性，用于存放 Kafka 偏移量。但若应用程序代码发生变化，Checkpoint 数据也将无法使用，这就需要改用下面的操作：</li><li>在数据输出之后手动提交 Kafka 偏移量。<code>HasOffsetRanges</code> 类，以及 <code>commitAsync</code> API 可以做到这一点：</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">messages.foreachRDD &#123; rdd =&gt;</span><br><span class="line">  <span class="keyword">val</span> offsetRanges = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</span><br><span class="line">  rdd.foreachPartition &#123; iter =&gt;</span><br><span class="line">    <span class="comment">// output to database</span></span><br><span class="line">  &#125;</span><br><span class="line">  messages.asInstanceOf[<span class="type">CanCommitOffsets</span>].commitAsync(offsetRanges)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="使用事务写入实现-Exactly-once"><a href="#使用事务写入实现-Exactly-once" class="headerlink" title="使用事务写入实现 Exactly-once"></a>使用事务写入实现 Exactly-once</h2><p>在使用事务型写入时，我们需要生成一个唯一 ID，这个 ID 可以使用当前批次的时间、分区号、或是 Kafka 偏移量来生成。之后，我们需要在一个事务中将处理结果和这个唯一 ID 一同写入数据库。这一原子性的操作将带给我们 Exactly-once 语义，而且该方法可以同时适用于 Map-only 以及包含汇聚操作的计算流程。</p><p>我们通常会在 <code>foreachPartition</code> 方法中来执行数据库写入操作。对于 Map-only 流程来说是适用的，因为这种流程下 Kafka 分区和 RDD 分区是一一对应的，我们可以用以下方式获取各分区的偏移量：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">messages.foreachRDD &#123; rdd =&gt;</span><br><span class="line">  <span class="keyword">val</span> offsetRanges = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</span><br><span class="line">  rdd.foreachPartition &#123; iter =&gt;</span><br><span class="line">    <span class="keyword">val</span> offsetRange = offsetRanges(<span class="type">TaskContext</span>.get.partitionId)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但对于包含 Shuffle 的计算流程（如上文的错误日志统计），我们需要先将处理结果拉取到 Driver 进程中，然后才能执行事务操作：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">messages.foreachRDD &#123; rdd =&gt;</span><br><span class="line">  <span class="keyword">val</span> offsetRanges = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</span><br><span class="line">  <span class="keyword">val</span> result = processLogs(rdd).collect() <span class="comment">// parse log and count error</span></span><br><span class="line">  <span class="type">DB</span>.localTx &#123; <span class="keyword">implicit</span> session =&gt;</span><br><span class="line">    result.foreach &#123; <span class="keyword">case</span> (time, count) =&gt;</span><br><span class="line">      <span class="comment">// save to error_log table</span></span><br><span class="line">    &#125;</span><br><span class="line">    offsetRanges.foreach &#123; offsetRange =&gt;</span><br><span class="line">      <span class="keyword">val</span> affectedRows = <span class="string">sql""</span><span class="string">"</span></span><br><span class="line"><span class="string">      update kafka_offset set offset = $&#123;offsetRange.untilOffset&#125;</span></span><br><span class="line"><span class="string">      where topic = $&#123;topic&#125; and `partition` = $&#123;offsetRange.partition&#125;</span></span><br><span class="line"><span class="string">      and offset = $&#123;offsetRange.fromOffset&#125;</span></span><br><span class="line"><span class="string">      "</span><span class="string">""</span>.update.apply()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (affectedRows != <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">Exception</span>(<span class="string">"fail to update offset"</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果偏移量写入失败，或者重复处理了某一部分数据（<code>offset != $fromOffset</code> 判断条件不通过），该事务就会回滚，从而做到 Exactly-once。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>实时计算中的 Exactly-once 是比较强的一种语义，因而会给你的应用程序引入额外的开销。此外，它尚不能很好地支持<a href="https://github.com/koeninger/kafka-exactly-once/blob/master/src/main/scala/example/Windowed.scala" target="_blank" rel="noopener">窗口型</a>操作。因此，是否要在代码中使用这一语义就需要开发者自行判断了。很多情况下，数据丢失或重复处理并不那么重要。不过，了解 Exactly-once 的开发流程还是有必要的，对学习 Spark Streaming 也会有所助益。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://blog.cloudera.com/blog/2015/03/exactly-once-spark-streaming-from-apache-kafka/" target="_blank" rel="noopener">http://blog.cloudera.com/blog/2015/03/exactly-once-spark-streaming-from-apache-kafka/</a></li><li><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/streaming-programming-guide.html</a></li><li><a href="http://spark.apache.org/docs/latest/streaming-kafka-0-10-integration.html" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/streaming-kafka-0-10-integration.html</a></li><li><a href="http://kafka.apache.org/documentation.html#semantics" target="_blank" rel="noopener">http://kafka.apache.org/documentation.html#semantics</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Exactly-once 语义是实时计算的难点之一。要做到每一条记录只会被处理一次，即使服务器或网络发生故障时也能保证没有遗漏，这不仅需要实时计算框架本身的支持，还对上游的消息系统、下游的数据存储有所要求。此外，我们在编写计算流程时也需要遵循一定规范，才能真正实现 Exactly-once。本文将讲述如何结合 Spark Streaming 框架、Kafka 消息系统、以及 MySQL 数据库来实现 Exactly-once 的实时计算流程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://spark.apache.org/docs/latest/img/streaming-arch.png&quot; alt=&quot;Spark Streaming&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;引例&quot;&gt;&lt;a href=&quot;#引例&quot; class=&quot;headerlink&quot; title=&quot;引例&quot;&gt;&lt;/a&gt;引例&lt;/h2&gt;&lt;p&gt;首先让我们实现一个简单而完整的实时计算流程。我们从 Kafka 接收用户访问日志，解析并提取其中的时间和日志级别，并统计每分钟错误日志的数量，结果保存到 MySQL 中。&lt;/p&gt;
&lt;p&gt;示例日志:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;2017-07-30 14:09:08 ERROR some message&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2017-07-30 14:09:20 INFO  some message&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2017-07-30 14:10:50 ERROR some message&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;结果表结构，其中 &lt;code&gt;log_time&lt;/code&gt; 字段会截取到分钟级别：&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; error_log (&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  log_time datetime primary &lt;span class=&quot;keyword&quot;&gt;key&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  log_count &lt;span class=&quot;built_in&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;default&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;);&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/cnblogs/categories/Big-Data/"/>
    
    
      <category term="spark" scheme="http://shzhangji.com/cnblogs/tags/spark/"/>
    
      <category term="scala" scheme="http://shzhangji.com/cnblogs/tags/scala/"/>
    
      <category term="stream processing" scheme="http://shzhangji.com/cnblogs/tags/stream-processing/"/>
    
      <category term="spark streaming" scheme="http://shzhangji.com/cnblogs/tags/spark-streaming/"/>
    
      <category term="kafka" scheme="http://shzhangji.com/cnblogs/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>通过 SQL 查询学习 Pandas 数据处理</title>
    <link href="http://shzhangji.com/cnblogs/2017/07/23/learn-pandas-from-a-sql-perspective/"/>
    <id>http://shzhangji.com/cnblogs/2017/07/23/learn-pandas-from-a-sql-perspective/</id>
    <published>2017-07-23T12:57:00.000Z</published>
    <updated>2017-07-26T01:21:43.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://pandas.pydata.org/" target="_blank" rel="noopener">Pandas</a> 是一款广泛使用的数据处理工具。结合 NumPy 和 Matplotlib 类库，我们可以在内存中进行高性能的数据清洗、转换、分析及可视化工作。虽然 Python 本身是一门非常容易学习的语言，但要熟练掌握 Pandas 丰富的 API 接口及正确的使用方式，还是需要投入一定时间的。对于数据开发工程师或分析师而言，SQL 语言是标准的数据查询工具。本文提供了一系列的示例，如何将常见的 SQL 查询语句使用 Pandas 来实现。</p><p>Pandas 的安装和基本概念并不在本文讲述范围内，请读者到官网上阅读相关文档，或者阅读《<a href="https://book.douban.com/subject/25779298/" target="_blank" rel="noopener">利用 Python 进行数据分析</a>》一书。我推荐大家使用 <a href="https://www.continuum.io/downloads" target="_blank" rel="noopener">Anaconda</a> Python 套件，其中集成了 <a href="https://pythonhosted.org/spyder/" target="_blank" rel="noopener">Spyder</a> 集成开发环境。在运行下文的代码之前，请先引入 Pandas 和 NumPy 包：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h2 id="FROM-读取数据"><a href="#FROM-读取数据" class="headerlink" title="FROM - 读取数据"></a><code>FROM</code> - 读取数据</h2><p>首先，我们需要将数据加载到工作区（内存）。Pandas 原生支持非常多的数据格式，CSV 是较常见的一种。我们以航班延误时间数据集为例（<a href="/uploads/flights.csv">下载地址</a>）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">date,delay,distance,origin,destination</span><br><span class="line">02221605,3,358,BUR,SMF</span><br><span class="line">01022100,-5,239,HOU,DAL</span><br><span class="line">03210808,6,288,BWI,ALB</span><br></pre></td></tr></table></figure><p>我们可以使用 <code>pd.read_csv</code> 函数加载它：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'flights.csv'</span>, dtype=&#123;<span class="string">'date'</span>: str&#125;)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><p>这条命令会将 <code>flights.csv</code> 文件读入内存，使用首行作为列名，并自动检测每一列的数据类型。其中，由于 <code>date</code> 一列的日期格式是 <code>%m%d%H%M</code>，自动转换成数字后会失去月份的前异零（02 月的 0），因此我们显式指定了该列的 <code>dtype</code>，告知 Pandas 保留原值。</p><a id="more"></a><p><code>df.head</code> 用于查看数据集的前 N 行，功能类似于 <code>LIMIT N</code>。如果要实现 <code>LIMIT 10, 100</code>，可以使用 <code>df.iloc[10:100]</code>。此外，IPython 终端默认只显示 60 行数据，我们可以通过以下方法修改设置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pd.options.display.max_rows = <span class="number">100</span></span><br><span class="line">df.iloc[<span class="number">10</span>:<span class="number">100</span>]</span><br></pre></td></tr></table></figure><p>另外一种常见的数据源是关系型数据库，Pandas 也提供了内置支持：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conn = pymysql.connect(host=<span class="string">'localhost'</span>, user=<span class="string">'root'</span>)</span><br><span class="line">df = pd.read_sql(<span class="string">"""</span></span><br><span class="line"><span class="string">select `date`, `delay`, `distance`, `origin`, `destination`</span></span><br><span class="line"><span class="string">from flights limit 1000</span></span><br><span class="line"><span class="string">"""</span>, conn)</span><br></pre></td></tr></table></figure><p>如果要将 DataFrame 保存到文件或数据库中去，可以分别使用 <code>pd.to_csv</code> 和 <code>pd.to_sql</code> 函数。</p><h2 id="SELECT-选择列"><a href="#SELECT-选择列" class="headerlink" title="SELECT - 选择列"></a><code>SELECT</code> - 选择列</h2><p><code>SELECT</code> 语句在 SQL 中用于选择需要的列，并对数据做清洗和转换。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'date'</span>] <span class="comment"># SELECT `date`</span></span><br><span class="line">df[[<span class="string">'date'</span>, <span class="string">'delay'</span>]] <span class="comment"># SELECT `date`, `delay`</span></span><br><span class="line">df.loc[<span class="number">10</span>:<span class="number">100</span>, [<span class="string">'date'</span>, <span class="string">'delay'</span>]] <span class="comment"># SELECT `date, `delay` LIMIT 10, 100</span></span><br></pre></td></tr></table></figure><p>SQL 提供了诸多函数，大部分都可以用 Pandas 来实现，而且我们也很容易用 Python 编写自定义函数。下面我将列举一些常用的函数。</p><h3 id="字符串函数"><a href="#字符串函数" class="headerlink" title="字符串函数"></a>字符串函数</h3><p>Pandas 的字符串函数可以通过 DateFrame 和 Series 的 <code>str</code> 属性来调用，如 <code>df[&#39;origin&#39;].str.lower()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SELECT CONCAT(origin, ' to ', destination)</span></span><br><span class="line">df[<span class="string">'origin'</span>].str.cat(df[<span class="string">'destination'</span>], sep=<span class="string">' to '</span>)</span><br><span class="line"></span><br><span class="line">df[<span class="string">'origin'</span>].str.strip() <span class="comment"># TRIM(origin)</span></span><br><span class="line">df[<span class="string">'origin'</span>].str.len() <span class="comment"># LENGTH(origin)</span></span><br><span class="line">df[<span class="string">'origin'</span>].str.replace(<span class="string">'a'</span>, <span class="string">'b'</span>) <span class="comment"># REPLACE(origin, 'a', 'b')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># SELECT SUBSTRING(origin, 1, 1)</span></span><br><span class="line">df[<span class="string">'origin'</span>].str[<span class="number">0</span>:<span class="number">1</span>] <span class="comment"># 使用 Python 字符串索引</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># SELECT SUBSTRING_INDEX(domain, '.', 2)</span></span><br><span class="line"><span class="comment"># www.example.com -&gt; www.example</span></span><br><span class="line">df[<span class="string">'domain'</span>].str.split(<span class="string">'.'</span>).str[:<span class="number">2</span>].str.join(<span class="string">'.'</span>)</span><br><span class="line">df[<span class="string">'domain'</span>].str.extract(<span class="string">r'^([^.]+\.[^.]+)'</span>)</span><br></pre></td></tr></table></figure><p>Pandas 有一个名为广播的特性（broadcast），简单来说就是能够将低维数据（包括单个标量）和高维数据进行结合和处理。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'full_date'</span>] = <span class="string">'2001'</span> + df[<span class="string">'date'</span>] <span class="comment"># CONCAT('2001', `date`)</span></span><br><span class="line">df[<span class="string">'delay'</span>] / <span class="number">60</span></span><br><span class="line">df[<span class="string">'delay'</span>].div(<span class="number">60</span>) <span class="comment"># 同上</span></span><br></pre></td></tr></table></figure><p>Pandas 还内置了很多字符串函数，它们的用法和 SQL 有一定区别，但功能更强。完整列表可以参考文档 <a href="https://pandas.pydata.org/pandas-docs/stable/text.html" target="_blank" rel="noopener">Working with Text Data</a>。</p><h3 id="日期函数"><a href="#日期函数" class="headerlink" title="日期函数"></a>日期函数</h3><p><code>pd.to_datetime</code> 用于将各种日期字符串转换成标准的 <code>datetime64</code> 类型。日期类型的 Series 都会有一个 <code>dt</code> 属性，从中可以获取到有关日期时间的信息，具体请参考文档 <a href="https://pandas.pydata.org/pandas-docs/stable/timeseries.html" target="_blank" rel="noopener">Time Series / Date functionality</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SELECT STR_TO_DATE(full_date, '%Y%m%d%H%i%s') AS `datetime`</span></span><br><span class="line">df[<span class="string">'datetime'</span>] = pd.to_datetime(df[<span class="string">'full_date'</span>], format=<span class="string">'%Y%m%d%H%M%S'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># SELECT DATE_FORMAT(`datetime`, '%Y-%m-%d')</span></span><br><span class="line">df[<span class="string">'datetime'</span>].dt.strftime(<span class="string">'%Y-%m-%d'</span>)</span><br><span class="line"></span><br><span class="line">df[<span class="string">'datetime'</span>].dt.month <span class="comment"># MONTH(`datetime`)</span></span><br><span class="line">df[<span class="string">'datetime'</span>].dt.hour <span class="comment"># HOUR(`datetime`)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># SELECT UNIX_TIMESTAMP(`datetime`)</span></span><br><span class="line">df[<span class="string">'datetime'</span>].view(<span class="string">'int64'</span>) // pd.Timedelta(<span class="number">1</span>, unit=<span class="string">'s'</span>).value</span><br><span class="line"></span><br><span class="line"><span class="comment"># SELECT FROM_UNIXTIME(`timestamp`)</span></span><br><span class="line">pd.to_datetime(df[<span class="string">'timestamp'</span>], unit=<span class="string">'s'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># SELECT `datetime` + INTERVAL 1 DAY</span></span><br><span class="line">df[<span class="string">'datetime'</span>] + pd.Timedelta(<span class="number">1</span>, unit=<span class="string">'D'</span>)</span><br></pre></td></tr></table></figure><h2 id="WHERE-选择行"><a href="#WHERE-选择行" class="headerlink" title="WHERE - 选择行"></a><code>WHERE</code> - 选择行</h2><p>在 Pandas 中使用逻辑表达式后，会返回一个布尔型的 Series，通过它可以对数据集进行过滤：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(df[<span class="string">'delay'</span>] &gt; <span class="number">0</span>).head()</span><br><span class="line"><span class="comment"># 0  True</span></span><br><span class="line"><span class="comment"># 1 False</span></span><br><span class="line"><span class="comment"># 2  True</span></span><br><span class="line"><span class="comment"># dtype: bool</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># WHERE delay &gt; 0</span></span><br><span class="line">df[df[<span class="string">'delay'</span>] &gt; <span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>我们可以用位运算符来组合多个查询条件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># WHERE delay &gt; 0 AND distance &lt;= 500</span></span><br><span class="line">df[(df[<span class="string">'delay'</span>] &gt; <span class="number">0</span>) &amp; (df[<span class="string">'distance'</span>] &lt;= <span class="number">500</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># WHERE delay &gt; 0 OR origin = 'BUR'</span></span><br><span class="line">df[(df[<span class="string">'delay'</span>] &gt; <span class="number">0</span>) | (df[<span class="string">'origin'</span>] == <span class="string">'BUR'</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># WHERE NOT (delay &gt; 0)</span></span><br><span class="line">df[~(df[<span class="string">'delay'</span>] &gt; <span class="number">0</span>)]</span><br></pre></td></tr></table></figure><p>对于 <code>IS NULL</code> 和 <code>IS NOT NULL</code>，也提供了相应的内置函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[df[<span class="string">'delay'</span>].isnull()] <span class="comment"># delay IS NULL</span></span><br><span class="line">df[df[<span class="string">'delay'</span>].notnull()] <span class="comment"># delay IS NOT NUL</span></span><br></pre></td></tr></table></figure><p>此外，Pandas 还提供了 <code>df.query</code> 方法，可以使用字符串表达式来编写过滤条件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.query(<span class="string">'delay &gt; 0 and distaince &lt;= 500'</span>)</span><br><span class="line">df.query(<span class="string">'(delay &gt; 0) | (origin == "BUR")'</span>)</span><br></pre></td></tr></table></figure><p>其实，Pandas 提供了功能强大的数据选取工具，很多是无法用 SQL 表达出来的，建议详细阅读 <a href="https://pandas.pydata.org/pandas-docs/stable/indexing.html" target="_blank" rel="noopener">Indexing and Selecting Data</a> 文档，其中包含了丰富的示例。</p><h2 id="GROUP-BY-汇总"><a href="#GROUP-BY-汇总" class="headerlink" title="GROUP BY - 汇总"></a><code>GROUP BY</code> - 汇总</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SELECT origin, COUNT(*) FROM flights GROUP BY origin</span></span><br><span class="line">df.groupby(<span class="string">'origin'</span>).size()</span><br><span class="line"><span class="comment"># origin</span></span><br><span class="line"><span class="comment"># ABQ    22</span></span><br><span class="line"><span class="comment"># ALB     4</span></span><br><span class="line"><span class="comment"># AMA     4</span></span><br><span class="line"><span class="comment"># dtype: int64</span></span><br></pre></td></tr></table></figure><p>聚合运算包含了两个部分，一是分组字段，二是聚合函数。我们可以传递多个分组字段给 <code>df.groupby</code>，也能够指定多个聚合函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SELECT origin, destination, SUM(delay), AVG(distance)</span></span><br><span class="line"><span class="comment"># GROUP BY origin, destination</span></span><br><span class="line">df.groupby([<span class="string">'origin'</span>, <span class="string">'destination'</span>]).agg(&#123;</span><br><span class="line">    <span class="string">'delay'</span>: np.sum,</span><br><span class="line">    <span class="string">'distance'</span>: np.mean</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># SELECT origin, MIN(delay), MAX(delay) GROUP BY origin</span></span><br><span class="line">df.groupby(<span class="string">'origin'</span>)[<span class="string">'delay'</span>].agg([<span class="string">'min'</span>, <span class="string">'max'</span>])</span><br></pre></td></tr></table></figure><p>我们还可以将函数的运行结果作为分组条件。更多示例请见 <a href="https://pandas.pydata.org/pandas-docs/stable/groupby.html" target="_blank" rel="noopener">Group By: split-apply-combine</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SELECT LENGTH(origin), COUNT(*) GROUP BY LENGTH(origin)</span></span><br><span class="line">df.set_index(<span class="string">'origin'</span>).groupby(len).size()</span><br></pre></td></tr></table></figure><h2 id="ORDER-BY-排序"><a href="#ORDER-BY-排序" class="headerlink" title="ORDER BY - 排序"></a><code>ORDER BY</code> - 排序</h2><p>Pandas 中有两类排序，按索引和按数值。如果不了解 Pandas 的索引，还请自行查阅相关教程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ORDER BY origin</span></span><br><span class="line">df.set_index(<span class="string">'origin'</span>).sort_index()</span><br><span class="line">df.sort_values(by=<span class="string">'origin'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ORDER BY origin ASC, destination DESC</span></span><br><span class="line">df.sort_values(by=[<span class="string">'origin'</span>, <span class="string">'destination'</span>], ascending=[<span class="keyword">True</span>, <span class="keyword">False</span>])</span><br></pre></td></tr></table></figure><h2 id="JOIN-关联查询"><a href="#JOIN-关联查询" class="headerlink" title="JOIN - 关联查询"></a><code>JOIN</code> - 关联查询</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># FROM product a LEFT JOIN category b ON a.cid = b.id</span></span><br><span class="line">pd.merge(df_product, df_category, left_on=<span class="string">'cid'</span>, right_on=<span class="string">'id'</span>, how=<span class="string">'left'</span>)</span><br></pre></td></tr></table></figure><p>如果联合查询的键是同名的，可以直接使用 <code>on=[&#39;k1&#39;, &#39;k2&#39;]</code>。默认的关联方式是 <code>INNER JOIN</code>（<code>how=&#39;inner&#39;</code>），其它还有左外连接（<code>left</code>）、右外连接（<code>right</code>）、以及 <code>FULL OUTER JOIN</code>（<code>outer</code>)。</p><p><code>pd.concat</code> 可用于实现 <code>UNION</code> 查询。 更多关联查询的示例请参考 <a href="https://pandas.pydata.org/pandas-docs/stable/merging.html" target="_blank" rel="noopener">Merge, join, and concatenate</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SELECT * FROM a UNION SELECT * FROM b</span></span><br><span class="line">pd.concat([df_a, df_b]).drop_duplicates()</span><br></pre></td></tr></table></figure><h1 id="分组排名"><a href="#分组排名" class="headerlink" title="分组排名"></a>分组排名</h1><p>最后，我们经常会需要在分组中按某种规则排序，并获得前几位的记录。MySQL 中需要通过变量来实现，Pandas 中则可以使用 <code>rank</code> 函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rnk = df.groupby(<span class="string">'origin'</span>)[<span class="string">'delay'</span>].rank(method=<span class="string">'first'</span>, ascending=<span class="keyword">False</span>)</span><br><span class="line">df.assign(rnk=rnk).query(<span class="string">'rnk &lt;= 3'</span>).sort_values([<span class="string">'origin'</span>, <span class="string">'rnk'</span>])</span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html" target="_blank" rel="noopener">https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html</a></li><li><a href="http://www.gregreda.com/2013/01/23/translating-sql-to-pandas-part1/" target="_blank" rel="noopener">http://www.gregreda.com/2013/01/23/translating-sql-to-pandas-part1/</a></li><li><a href="http://codingsight.com/pivot-tables-in-mysql/" target="_blank" rel="noopener">http://codingsight.com/pivot-tables-in-mysql/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://pandas.pydata.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Pandas&lt;/a&gt; 是一款广泛使用的数据处理工具。结合 NumPy 和 Matplotlib 类库，我们可以在内存中进行高性能的数据清洗、转换、分析及可视化工作。虽然 Python 本身是一门非常容易学习的语言，但要熟练掌握 Pandas 丰富的 API 接口及正确的使用方式，还是需要投入一定时间的。对于数据开发工程师或分析师而言，SQL 语言是标准的数据查询工具。本文提供了一系列的示例，如何将常见的 SQL 查询语句使用 Pandas 来实现。&lt;/p&gt;
&lt;p&gt;Pandas 的安装和基本概念并不在本文讲述范围内，请读者到官网上阅读相关文档，或者阅读《&lt;a href=&quot;https://book.douban.com/subject/25779298/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;利用 Python 进行数据分析&lt;/a&gt;》一书。我推荐大家使用 &lt;a href=&quot;https://www.continuum.io/downloads&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Anaconda&lt;/a&gt; Python 套件，其中集成了 &lt;a href=&quot;https://pythonhosted.org/spyder/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Spyder&lt;/a&gt; 集成开发环境。在运行下文的代码之前，请先引入 Pandas 和 NumPy 包：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;FROM-读取数据&quot;&gt;&lt;a href=&quot;#FROM-读取数据&quot; class=&quot;headerlink&quot; title=&quot;FROM - 读取数据&quot;&gt;&lt;/a&gt;&lt;code&gt;FROM&lt;/code&gt; - 读取数据&lt;/h2&gt;&lt;p&gt;首先，我们需要将数据加载到工作区（内存）。Pandas 原生支持非常多的数据格式，CSV 是较常见的一种。我们以航班延误时间数据集为例（&lt;a href=&quot;/uploads/flights.csv&quot;&gt;下载地址&lt;/a&gt;）：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;date,delay,distance,origin,destination&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;02221605,3,358,BUR,SMF&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;01022100,-5,239,HOU,DAL&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;03210808,6,288,BWI,ALB&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们可以使用 &lt;code&gt;pd.read_csv&lt;/code&gt; 函数加载它：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;df = pd.read_csv(&lt;span class=&quot;string&quot;&gt;&#39;flights.csv&#39;&lt;/span&gt;, dtype=&amp;#123;&lt;span class=&quot;string&quot;&gt;&#39;date&#39;&lt;/span&gt;: str&amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df.head()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这条命令会将 &lt;code&gt;flights.csv&lt;/code&gt; 文件读入内存，使用首行作为列名，并自动检测每一列的数据类型。其中，由于 &lt;code&gt;date&lt;/code&gt; 一列的日期格式是 &lt;code&gt;%m%d%H%M&lt;/code&gt;，自动转换成数字后会失去月份的前异零（02 月的 0），因此我们显式指定了该列的 &lt;code&gt;dtype&lt;/code&gt;，告知 Pandas 保留原值。&lt;/p&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/cnblogs/categories/Big-Data/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/cnblogs/tags/python/"/>
    
      <category term="analytics" scheme="http://shzhangji.com/cnblogs/tags/analytics/"/>
    
      <category term="pandas" scheme="http://shzhangji.com/cnblogs/tags/pandas/"/>
    
      <category term="sql" scheme="http://shzhangji.com/cnblogs/tags/sql/"/>
    
  </entry>
  
  <entry>
    <title>使用 WebSocket 和 Python 编写日志查看器</title>
    <link href="http://shzhangji.com/cnblogs/2017/07/16/log-tailer-with-websocket-and-python/"/>
    <id>http://shzhangji.com/cnblogs/2017/07/16/log-tailer-with-websocket-and-python/</id>
    <published>2017-07-16T07:55:05.000Z</published>
    <updated>2017-07-17T00:35:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>在生产环境运维工作中，查看线上服务器日志是一项常规工作。如果这项工作可以在浏览器中进行，而无需登录服务器执行 <code>tail -f</code> 命令，就太方便了。我们可以使用 WebSocket 技术轻松实现这一目标。在本文中，我将带各位一起使用 Python 编写一个日志查看工具。</p><p><img src="/cnblogs/images/logviewer-websocket.png" alt="基于 WebSocket 的日志查看器"></p><h2 id="WebSocket-简介"><a href="#WebSocket-简介" class="headerlink" title="WebSocket 简介"></a>WebSocket 简介</h2><p>WebSocket 是一个标准化协议，构建在 TCP 之上，能够在客户端和服务端之间建立一个全双工的通信渠道。这里的客户端和服务端通常是用户浏览器和 Web 服务器。在 WebSocket 诞生之前，如果我们想保持这样的一个长连接，就需要使用诸如长轮询、永久帧、Comet 等技术。而现今 WebSocket 已经得到了所有主流浏览器的支持，我们可以使用它开发出在线聊天室、游戏、实时仪表盘等软件。此外，WebSocket 可以通过 HTTP Upgrade 请求来建立连接，并使用 80 端口通信，从而降低对现有网络环境的影响，如无需穿越防火墙。</p><a id="more"></a><h2 id="websockets-Python-类库"><a href="#websockets-Python-类库" class="headerlink" title="websockets Python 类库"></a><code>websockets</code> Python 类库</h2><p><code>websockets</code> 是第三方的 Python 类库，它能基于 Python 提供的 <code>asyncio</code> 包来实现 WebSocket 服务端以及客户端应用。我们可以使用 <code>pip</code> 来安装它，要求 Python 3.3 以上的版本。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install websockets</span><br><span class="line"><span class="comment"># For Python 3.3</span></span><br><span class="line">pip install asyncio</span><br></pre></td></tr></table></figure><p>下面是一段简单的 Echo 服务代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> websockets</span><br><span class="line"></span><br><span class="line"><span class="meta">@asyncio.coroutine</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">echo</span><span class="params">(websocket, path)</span>:</span></span><br><span class="line">    message = <span class="keyword">yield</span> <span class="keyword">from</span> websocket.recv()</span><br><span class="line">    print(<span class="string">'recv'</span>, message)</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> websocket.send(message)</span><br><span class="line"></span><br><span class="line">start_server = websockets.serve(echo, <span class="string">'localhost'</span>, <span class="number">8765</span>)</span><br><span class="line"></span><br><span class="line">asyncio.get_event_loop().run_until_complete(start_server)</span><br><span class="line">asyncio.get_event_loop().run_forever()</span><br></pre></td></tr></table></figure><p>可以看到，我们使用 Python 的协程来处理客户端请求。协程是 Python 3.3 引入的新概念，简单来说，它能通过单个线程来实现并发编程，主要适用于处理套接字 I/O 请求等场景。Python 3.5 开始又引入了 <code>async</code> 和 <code>await</code> 关键字，方便程序员使用协程。以下是使用新关键字对 Echo 服务进行改写：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">echo</span><span class="params">(websocket, path)</span>:</span></span><br><span class="line">    message = <span class="keyword">await</span> websocket.recv()</span><br><span class="line">    <span class="keyword">await</span> websocket.send(message)</span><br></pre></td></tr></table></figure><p>对于客户端应用，我们直接使用浏览器内置的 <code>WebSocket</code> 类。将下面的代码直接粘贴到 Chrome 浏览器的 JavaScript 控制台中就可以运行了：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> ws = <span class="keyword">new</span> WebSocket(<span class="string">'ws://localhost:8765'</span>)</span><br><span class="line">ws.onmessage = <span class="function">(<span class="params">event</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(event.data)</span><br><span class="line">&#125;</span><br><span class="line">ws.onopen = <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">  ws.send(<span class="string">'hello'</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="查看并监听日志"><a href="#查看并监听日志" class="headerlink" title="查看并监听日志"></a>查看并监听日志</h2><p>我们将通过以下几步来构建日志查看器：</p><ul><li>首先，客户端发起一个 WebSocket 请求，并将请求的文件路径包含在 URL 中，形如 <code>ws://localhost:8765/tmp/build.log?tail=1</code>；</li><li>服务端接受到请求后，将文件路径解析出来，顺带解析出是否要持续监听日志的标志位；</li><li>服务端打开日志文件，开始不断向客户端发送日志文件内容。</li></ul><p>完整的源代码可以在 <a href="https://github.com/jizhang/logviewer" target="_blank" rel="noopener">GitHub</a> 中查看，以下只截取重要的部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@asyncio.coroutine</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">view_log</span><span class="params">(websocket, path)</span>:</span></span><br><span class="line">    parse_result = urllib.parse.urlparse(path)</span><br><span class="line">    file_path = os.path.abspath(parse_result.path)</span><br><span class="line">    query = urllib.parse.parse_qs(parse_result.query)</span><br><span class="line">    tail = query <span class="keyword">and</span> query[<span class="string">'tail'</span>] <span class="keyword">and</span> query[<span class="string">'tail'</span>][<span class="number">0</span>] == <span class="string">'1'</span></span><br><span class="line">    <span class="keyword">with</span> open(file_path) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">yield</span> <span class="keyword">from</span> websocket.send(f.read())</span><br><span class="line">        <span class="keyword">if</span> tail:</span><br><span class="line">            <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">                content = f.read()</span><br><span class="line">                <span class="keyword">if</span> content:</span><br><span class="line">                    <span class="keyword">yield</span> <span class="keyword">from</span> websocket.send(content)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">yield</span> <span class="keyword">from</span> asyncio.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">yield</span> <span class="keyword">from</span> websocket.close()</span><br></pre></td></tr></table></figure><h2 id="其它特性"><a href="#其它特性" class="headerlink" title="其它特性"></a>其它特性</h2><ul><li>在实际应用中发现，浏览器有时不会正确关闭 WebSocket 连接，导致服务端资源浪费，因此我们添加一个简单的心跳机制：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> time.time() - last_heartbeat &gt; HEARTBEAT_INTERVAL:</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> websocket.send(<span class="string">'ping'</span>)</span><br><span class="line">    pong = <span class="keyword">yield</span> <span class="keyword">from</span> asyncio.wait_for(websocket.recv(), <span class="number">5</span>)</span><br><span class="line">    <span class="keyword">if</span> pong != <span class="string">'pong'</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">'Ping error'</span>))</span><br><span class="line">    last_heartbeat = time.time()</span><br></pre></td></tr></table></figure><ul><li>日志文件中有时会包含 ANSI 颜色高亮（如日志级别），我们可以使用 <code>ansi2html</code> 包来将高亮部分转换成 HTML 代码：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ansi2html <span class="keyword">import</span> Ansi2HTMLConverter</span><br><span class="line">conv = Ansi2HTMLConverter(inline=<span class="keyword">True</span>)</span><br><span class="line"><span class="keyword">yield</span> <span class="keyword">from</span> websocket.send(conv.convert(content, full=<span class="keyword">False</span>))</span><br></pre></td></tr></table></figure><ul><li>最后，日志文件路径也需要进行权限检查，本例中是将客户端传递的路径转换成绝对路径后，简单判断了路径前缀，以作权限控制。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://en.wikipedia.org/wiki/WebSocket" target="_blank" rel="noopener">WebSocket - Wikipedia</a></li><li><a href="https://websockets.readthedocs.io/en/stable/intro.html" target="_blank" rel="noopener">websockets - Get Started</a></li><li><a href="https://docs.python.org/3/library/asyncio-task.html" target="_blank" rel="noopener">Tasks and coroutines</a></li><li><a href="https://stackoverflow.com/questions/12523044/how-can-i-tail-a-log-file-in-python" target="_blank" rel="noopener">How can I tail a log file in Python?</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在生产环境运维工作中，查看线上服务器日志是一项常规工作。如果这项工作可以在浏览器中进行，而无需登录服务器执行 &lt;code&gt;tail -f&lt;/code&gt; 命令，就太方便了。我们可以使用 WebSocket 技术轻松实现这一目标。在本文中，我将带各位一起使用 Python 编写一个日志查看工具。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/cnblogs/images/logviewer-websocket.png&quot; alt=&quot;基于 WebSocket 的日志查看器&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;WebSocket-简介&quot;&gt;&lt;a href=&quot;#WebSocket-简介&quot; class=&quot;headerlink&quot; title=&quot;WebSocket 简介&quot;&gt;&lt;/a&gt;WebSocket 简介&lt;/h2&gt;&lt;p&gt;WebSocket 是一个标准化协议，构建在 TCP 之上，能够在客户端和服务端之间建立一个全双工的通信渠道。这里的客户端和服务端通常是用户浏览器和 Web 服务器。在 WebSocket 诞生之前，如果我们想保持这样的一个长连接，就需要使用诸如长轮询、永久帧、Comet 等技术。而现今 WebSocket 已经得到了所有主流浏览器的支持，我们可以使用它开发出在线聊天室、游戏、实时仪表盘等软件。此外，WebSocket 可以通过 HTTP Upgrade 请求来建立连接，并使用 80 端口通信，从而降低对现有网络环境的影响，如无需穿越防火墙。&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/cnblogs/categories/Programming/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/cnblogs/tags/python/"/>
    
      <category term="ops" scheme="http://shzhangji.com/cnblogs/tags/ops/"/>
    
      <category term="websocket" scheme="http://shzhangji.com/cnblogs/tags/websocket/"/>
    
  </entry>
  
  <entry>
    <title>为什么不用 ES6 完全替换 Lodash</title>
    <link href="http://shzhangji.com/cnblogs/2017/06/29/why-use-lodash-when-es6-is-available/"/>
    <id>http://shzhangji.com/cnblogs/2017/06/29/why-use-lodash-when-es6-is-available/</id>
    <published>2017-06-29T06:49:14.000Z</published>
    <updated>2017-06-29T06:49:14.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://lodash.com/" target="_blank" rel="noopener">Lodash</a> 是一款非常知名的 JavaScript 工具库，能够让开发者十分便捷地操纵数组和对象。我则是非常喜欢用它提供的函数式编程风格来操作集合类型，特别是链式调用和惰性求值。然而，随着 <a href="http://www.ecma-international.org/ecma-262/6.0/" target="_blank" rel="noopener">ECMAScript 2015 Standard (ES6)</a> 得到越来越多主流浏览器的支持，以及像 <a href="https://babeljs.io/" target="_blank" rel="noopener">Babel</a> 这样，能够将 ES6 代码编译成 ES5 从而在旧浏览器上运行的工具日渐流行，人们会发现许多 Lodash 提供的功能已经可以用 ES6 来替换了。然而真的如此吗？我认为，Lodash 仍然会非常流行，因为它可以为程序员提供更多的便利，并且优化我们编程的方式。</p><h2 id="map-和-Array-map-是有区别的"><a href="#map-和-Array-map-是有区别的" class="headerlink" title="_.map 和 Array#map 是有区别的"></a><code>_.map</code> 和 <code>Array#map</code> 是有区别的</h2><p>在处理集合对象时，<code>_.map</code>、<code>_.reduce</code>、<code>_.filter</code>、以及 <code>_.forEach</code> 的使用频率很高，而今 ES6 已经能够原生支持这些操作：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">_.map([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], (i) =&gt; i + <span class="number">1</span>)</span><br><span class="line">_.reduce([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], (sum, i) =&gt; sum + i, <span class="number">0</span>)</span><br><span class="line">_.filter([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], (i) =&gt; i &gt; <span class="number">1</span>)</span><br><span class="line">_.forEach([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], (i) =&gt; &#123; <span class="built_in">console</span>.log(i) &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用 ES6 改写</span></span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>].map(<span class="function">(<span class="params">i</span>) =&gt;</span> i + <span class="number">1</span>)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>].reduce(<span class="function">(<span class="params">sum, i</span>) =&gt;</span> sum + i, <span class="number">0</span>)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>].filter(<span class="function">(<span class="params">i</span>) =&gt;</span> i &gt; <span class="number">1</span>)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>].forEach(<span class="function">(<span class="params">i</span>) =&gt;</span> &#123; <span class="built_in">console</span>.log(i) &#125;)</span><br></pre></td></tr></table></figure><p>但是，Lodash 的 <code>_.map</code> 函数功能更强大，它能够操作对象类型，提供了遍历和过滤的快捷方式，能够惰性求值，对 <code>null</code> 值容错，并且有着更好的性能。</p><a id="more"></a><h3 id="遍历对象类型"><a href="#遍历对象类型" class="headerlink" title="遍历对象类型"></a>遍历对象类型</h3><p>ES6 中有以下几种方式来遍历对象：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> key <span class="keyword">in</span> obj) &#123; <span class="built_in">console</span>.log(obj[key]) &#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> key <span class="keyword">of</span> <span class="built_in">Object</span>.keys(obj)) &#123; <span class="built_in">console</span>.log(obj[key]) &#125;</span><br><span class="line"><span class="built_in">Object</span>.keys(obj).forEach(<span class="function">(<span class="params">key</span>) =&gt;</span> &#123; <span class="built_in">console</span>.log(obj[key]) &#125;)</span><br></pre></td></tr></table></figure><p>Lodash 中则有一个统一的方法 <code>_.forEach</code>：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">_.forEach(obj, (value, key) =&gt; &#123; <span class="built_in">console</span>.log(value) &#125;)</span><br></pre></td></tr></table></figure><p>虽然 ES6 的 <code>Map</code> 类型也<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map" target="_blank" rel="noopener">提供</a>了 <code>forEach</code> 方法，但我们需要先费些功夫将普通的对象类型转换为 <code>Map</code> 类型：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// http://stackoverflow.com/a/36644532/1030720</span></span><br><span class="line"><span class="keyword">const</span> buildMap = <span class="function"><span class="params">o</span> =&gt;</span> <span class="built_in">Object</span>.keys(o).reduce(<span class="function">(<span class="params">m, k</span>) =&gt;</span> m.set(k, o[k]), <span class="keyword">new</span> <span class="built_in">Map</span>());</span><br></pre></td></tr></table></figure><h3 id="遍历和过滤的快捷方式"><a href="#遍历和过滤的快捷方式" class="headerlink" title="遍历和过滤的快捷方式"></a>遍历和过滤的快捷方式</h3><p>比如我们想从一组对象中摘取出某个属性的值：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> arr = [&#123; <span class="attr">n</span>: <span class="number">1</span> &#125;, &#123; <span class="attr">n</span>: <span class="number">2</span> &#125;]</span><br><span class="line"><span class="comment">// ES6</span></span><br><span class="line">arr.map(<span class="function">(<span class="params">obj</span>) =&gt;</span> obj.n)</span><br><span class="line"><span class="comment">// Lodash</span></span><br><span class="line">_.map(arr, <span class="string">'n'</span>)</span><br></pre></td></tr></table></figure><p>当对象类型的嵌套层级很多时，Lodash 的快捷方式就更实用了：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> arr = [</span><br><span class="line">  &#123; <span class="attr">a</span>: [ &#123; <span class="attr">n</span>: <span class="number">1</span> &#125; ]&#125;,</span><br><span class="line">  &#123; <span class="attr">b</span>: [ &#123; <span class="attr">n</span>: <span class="number">1</span> &#125; ]&#125;</span><br><span class="line">]</span><br><span class="line"><span class="comment">// ES6</span></span><br><span class="line">arr.map(<span class="function">(<span class="params">obj</span>) =&gt;</span> obj.a[<span class="number">0</span>].n) <span class="comment">// TypeError: 属性 'a' 在 arr[1] 中未定义</span></span><br><span class="line"><span class="comment">// Lodash</span></span><br><span class="line">_.map(arr, <span class="string">'a[0].n'</span>) <span class="comment">// =&gt; [1, undefined]</span></span><br></pre></td></tr></table></figure><p>可以看到，Lodash 的快捷方式还对 <code>null</code> 值做了容错处理。此外还有过滤快捷方式，以下是从 Lodash 官方文档中摘取的示例代码：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> users = [</span><br><span class="line">  &#123; <span class="string">'user'</span>: <span class="string">'barney'</span>, <span class="string">'age'</span>: <span class="number">36</span>, <span class="string">'active'</span>: <span class="literal">true</span> &#125;,</span><br><span class="line">  &#123; <span class="string">'user'</span>: <span class="string">'fred'</span>,   <span class="string">'age'</span>: <span class="number">40</span>, <span class="string">'active'</span>: <span class="literal">false</span> &#125;</span><br><span class="line">];</span><br><span class="line"><span class="comment">// ES6</span></span><br><span class="line">users.filter(<span class="function">(<span class="params">o</span>) =&gt;</span> o.active)</span><br><span class="line"><span class="comment">// Lodash</span></span><br><span class="line">_.filter(users, <span class="string">'active'</span>)</span><br><span class="line">_.filter(users, [<span class="string">'active'</span>, <span class="literal">true</span>])</span><br><span class="line">_.filter(users, &#123;<span class="string">'active'</span>: <span class="literal">true</span>, <span class="string">'age'</span>: <span class="number">36</span>&#125;)</span><br></pre></td></tr></table></figure><h3 id="链式调用和惰性求值"><a href="#链式调用和惰性求值" class="headerlink" title="链式调用和惰性求值"></a>链式调用和惰性求值</h3><p>Lodash 的这一特性就非常有趣和实用了。现在很流行使用短小可测的函数，结合链式调用和惰性求值，来操作集合类型。大部分 Lodash 函数都可以进行链式调用，下面是一个典型的 <strong>WordCount</strong> 示例：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> lines = <span class="string">`</span></span><br><span class="line"><span class="string">an apple orange the grape</span></span><br><span class="line"><span class="string">banana an apple melon</span></span><br><span class="line"><span class="string">an orange banana apple</span></span><br><span class="line"><span class="string">`</span>.split(<span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">_.chain(lines)</span><br><span class="line">  .flatMap(<span class="function"><span class="params">line</span> =&gt;</span> line.split(<span class="regexp">/\s+/</span>))</span><br><span class="line">  .filter(<span class="function"><span class="params">word</span> =&gt;</span> word.length &gt; <span class="number">3</span>)</span><br><span class="line">  .groupBy(_.identity)</span><br><span class="line">  .mapValues(_.size)</span><br><span class="line">  .forEach(<span class="function">(<span class="params">count, word</span>) =&gt;</span> &#123; <span class="built_in">console</span>.log(word, count) &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// apple 3</span></span><br><span class="line"><span class="comment">// orange 2</span></span><br><span class="line"><span class="comment">// grape 1</span></span><br><span class="line"><span class="comment">// banana 2</span></span><br><span class="line"><span class="comment">// melon 1</span></span><br></pre></td></tr></table></figure><h2 id="解构赋值和箭头函数"><a href="#解构赋值和箭头函数" class="headerlink" title="解构赋值和箭头函数"></a>解构赋值和箭头函数</h2><p>ES6 引入了解构赋值、箭头函数等新的语言特性，可以用来替换 Lodash：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Lodash</span></span><br><span class="line">_.head([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]) <span class="comment">// =&gt; 1</span></span><br><span class="line">_.tail([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]) <span class="comment">// =&gt; [2, 3]</span></span><br><span class="line"><span class="comment">// ES6 解构赋值（destructuring syntax）</span></span><br><span class="line"><span class="keyword">const</span> [head, ...tail] = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">// Lodash</span></span><br><span class="line"><span class="keyword">let</span> say = _.rest(<span class="function">(<span class="params">who, fruits</span>) =&gt;</span> who + <span class="string">' likes '</span> + fruits.join(<span class="string">','</span>))</span><br><span class="line">say(<span class="string">'Jerry'</span>, <span class="string">'apple'</span>, <span class="string">'grape'</span>)</span><br><span class="line"><span class="comment">// ES6 spread syntax</span></span><br><span class="line">say = <span class="function">(<span class="params">who, ...fruits</span>) =&gt;</span> who + <span class="string">' likes '</span> + fruits.join(<span class="string">','</span>)</span><br><span class="line">say(<span class="string">'Mary'</span>, <span class="string">'banana'</span>, <span class="string">'orange'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Lodash</span></span><br><span class="line">_.constant(<span class="number">1</span>)() <span class="comment">// =&gt; 1</span></span><br><span class="line">_.identity(<span class="number">2</span>) <span class="comment">// =&gt; 2</span></span><br><span class="line"><span class="comment">// ES6</span></span><br><span class="line">(<span class="function"><span class="params">x</span> =&gt;</span> (<span class="function"><span class="params">()</span> =&gt;</span> x))(<span class="number">1</span>)() <span class="comment">// =&gt; 1</span></span><br><span class="line">(<span class="function"><span class="params">x</span> =&gt;</span> x)(<span class="number">2</span>) <span class="comment">// =&gt; 2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 偏应用（Partial application）</span></span><br><span class="line"><span class="keyword">let</span> add = <span class="function">(<span class="params">a, b</span>) =&gt;</span> a + b</span><br><span class="line"><span class="comment">// Lodash</span></span><br><span class="line"><span class="keyword">let</span> add1 = _.partial(add, <span class="number">1</span>)</span><br><span class="line"><span class="comment">// ES6</span></span><br><span class="line">add1 = <span class="function"><span class="params">b</span> =&gt;</span> add(<span class="number">1</span>, b)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 柯里化（Curry）</span></span><br><span class="line"><span class="comment">// Lodash</span></span><br><span class="line"><span class="keyword">let</span> curriedAdd = _.curry(add)</span><br><span class="line"><span class="keyword">let</span> add1 = curriedAdd(<span class="number">1</span>)</span><br><span class="line"><span class="comment">// ES6</span></span><br><span class="line">curriedAdd = <span class="function"><span class="params">a</span> =&gt;</span> b =&gt; a + b</span><br><span class="line">add1 = curriedAdd(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>对于集合类操作，我更倾向于使用 Lodash 函数，因为它们的定义更准确，而且可以串联成链；对于那些可以用箭头函数来重写的用例，Lodash 同样显得更简单和清晰一些。此外，<a href="#参考资料">参考资料</a>里的几篇文章中也提到，在函数式编程场景下，Lodash 提供了更为实用的柯里化、<a href="https://lodash.com/docs/#add" target="_blank" rel="noopener">运算符函数</a>、<a href="https://github.com/lodash/lodash/wiki/FP-Guide" target="_blank" rel="noopener">FP 模式</a>等特性。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Lodash 为 JavaScript 语言增添了诸多特性，程序员可以用它轻松写出语义精确、执行高效的代码。此外，Lodash 已经完全<a href="https://lodash.com/custom-builds" target="_blank" rel="noopener">模块化</a>了。虽然它的某些特性最终会被淘汰，但仍有许多功能是值得我们继续使用的。同时，Lodash 这样的类库也在不断推动 JavaScript 语言本身的发展。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.sitepoint.com/lodash-features-replace-es6/" target="_blank" rel="noopener">10 Lodash Features You Can Replace with ES6</a></li><li><a href="https://derickbailey.com/2016/09/12/does-es6-mean-the-end-of-underscore-lodash/" target="_blank" rel="noopener">Does ES6 Mean The End Of Underscore / Lodash?</a></li><li><a href="https://www.reddit.com/r/javascript/comments/41fq2s/why_should_i_use_lodash_or_rather_what_lodash/" target="_blank" rel="noopener">Why should I use lodash - reddit</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://lodash.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Lodash&lt;/a&gt; 是一款非常知名的 JavaScript 工具库，能够让开发者十分便捷地操纵数组和对象。我则是非常喜欢用它提供的函数式编程风格来操作集合类型，特别是链式调用和惰性求值。然而，随着 &lt;a href=&quot;http://www.ecma-international.org/ecma-262/6.0/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ECMAScript 2015 Standard (ES6)&lt;/a&gt; 得到越来越多主流浏览器的支持，以及像 &lt;a href=&quot;https://babeljs.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Babel&lt;/a&gt; 这样，能够将 ES6 代码编译成 ES5 从而在旧浏览器上运行的工具日渐流行，人们会发现许多 Lodash 提供的功能已经可以用 ES6 来替换了。然而真的如此吗？我认为，Lodash 仍然会非常流行，因为它可以为程序员提供更多的便利，并且优化我们编程的方式。&lt;/p&gt;
&lt;h2 id=&quot;map-和-Array-map-是有区别的&quot;&gt;&lt;a href=&quot;#map-和-Array-map-是有区别的&quot; class=&quot;headerlink&quot; title=&quot;_.map 和 Array#map 是有区别的&quot;&gt;&lt;/a&gt;&lt;code&gt;_.map&lt;/code&gt; 和 &lt;code&gt;Array#map&lt;/code&gt; 是有区别的&lt;/h2&gt;&lt;p&gt;在处理集合对象时，&lt;code&gt;_.map&lt;/code&gt;、&lt;code&gt;_.reduce&lt;/code&gt;、&lt;code&gt;_.filter&lt;/code&gt;、以及 &lt;code&gt;_.forEach&lt;/code&gt; 的使用频率很高，而今 ES6 已经能够原生支持这些操作：&lt;/p&gt;
&lt;figure class=&quot;highlight js&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;_.map([&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;], (i) =&amp;gt; i + &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;_.reduce([&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;], (sum, i) =&amp;gt; sum + i, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;_.filter([&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;], (i) =&amp;gt; i &amp;gt; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;_.forEach([&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;], (i) =&amp;gt; &amp;#123; &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(i) &amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// 使用 ES6 改写&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;].map(&lt;span class=&quot;function&quot;&gt;(&lt;span class=&quot;params&quot;&gt;i&lt;/span&gt;) =&amp;gt;&lt;/span&gt; i + &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;].reduce(&lt;span class=&quot;function&quot;&gt;(&lt;span class=&quot;params&quot;&gt;sum, i&lt;/span&gt;) =&amp;gt;&lt;/span&gt; sum + i, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;].filter(&lt;span class=&quot;function&quot;&gt;(&lt;span class=&quot;params&quot;&gt;i&lt;/span&gt;) =&amp;gt;&lt;/span&gt; i &amp;gt; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;].forEach(&lt;span class=&quot;function&quot;&gt;(&lt;span class=&quot;params&quot;&gt;i&lt;/span&gt;) =&amp;gt;&lt;/span&gt; &amp;#123; &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(i) &amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;但是，Lodash 的 &lt;code&gt;_.map&lt;/code&gt; 函数功能更强大，它能够操作对象类型，提供了遍历和过滤的快捷方式，能够惰性求值，对 &lt;code&gt;null&lt;/code&gt; 值容错，并且有着更好的性能。&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/cnblogs/categories/Programming/"/>
    
    
      <category term="javascript" scheme="http://shzhangji.com/cnblogs/tags/javascript/"/>
    
      <category term="frontend" scheme="http://shzhangji.com/cnblogs/tags/frontend/"/>
    
      <category term="es6" scheme="http://shzhangji.com/cnblogs/tags/es6/"/>
    
      <category term="lodash" scheme="http://shzhangji.com/cnblogs/tags/lodash/"/>
    
  </entry>
  
  <entry>
    <title>使用 Crossfilter 和 dc.js 构建交互式报表</title>
    <link href="http://shzhangji.com/cnblogs/2017/06/18/build-interactive-report-with-crossfilter-and-dc-js/"/>
    <id>http://shzhangji.com/cnblogs/2017/06/18/build-interactive-report-with-crossfilter-and-dc-js/</id>
    <published>2017-06-18T10:59:53.000Z</published>
    <updated>2017-06-19T01:06:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>在对多维数据集进行图表分析时，我们希望在图表之间建立联系，选择图表中的一部分数据后，其他图表也会相应变动。这项工作可以通过开发完成，即在服务端对数据进行过滤，并更新所有图表。此外，我们还可以借助 Crossfilter 和 dc.js 这两个工具，直接在浏览器中对数据进行操作。</p><h2 id="航班延误统计"><a href="#航班延误统计" class="headerlink" title="航班延误统计"></a>航班延误统计</h2><p>这是 Crossfilter 官方网站提供的示例，基于 <a href="http://stat-computing.org/dataexpo/2009/" target="_blank" rel="noopener">ASA Data Expo</a> 数据集的航班延误统计。下面我们将介绍如何用 dc.js 来实现这份交互式报表。项目源码可以在 <a href="https://jsfiddle.net/zjerryj/gjao9sws/" target="_blank" rel="noopener">JSFiddle</a> 中浏览，演示的数据量减少到 1000 条。</p><p><img src="/cnblogs/images/airline-ontime-performance.png" alt=""></p><a id="more"></a><h2 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h2><p><a href="http://crossfilter.github.io/crossfilter/" target="_blank" rel="noopener">Crossfilter</a> 是一个 JavaScript 类库，能够在浏览器端对大量数据进行多维分析。它的特点是可以在不同的 Group By 查询之间实现“交叉过滤”，自动连接和更新查询结果。结合 <a href="https://dc-js.github.io/dc.js/" target="_blank" rel="noopener">dc.js</a> 图表类库，我们就可以构建出高性能、交互式的分析报表了。</p><h2 id="数据集、维度、度量"><a href="#数据集、维度、度量" class="headerlink" title="数据集、维度、度量"></a>数据集、维度、度量</h2><p>Crossfilter 中有维度、度量等概念。如果你对数据仓库或统计分析有所了解，这些术语和 OLAP 立方体中的定义是相似的。</p><ul><li>数据集：即一张二维表，包含行和列，在 JavaScript 中通常是由对象组成的数组；</li><li>维度：用于进行 Group By 操作的字段，它通常是可枚举的值，如日期、性别，也可以是数值范围，如年龄范围等；</li><li>度量：可以进行合计、计算标准差等操作，通常是数值型的，如收入、子女人数；记录数也是一种度量；</li></ul><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> flights = d3.csv.parse(flightsCsv)</span><br><span class="line"><span class="keyword">let</span> flight = crossfilter(flights)</span><br><span class="line"><span class="keyword">let</span> hour = flight.dimension(<span class="function">(<span class="params">d</span>) =&gt;</span> d.date.getHours() + d.date.getMinutes() / <span class="number">60</span>)</span><br><span class="line"><span class="keyword">let</span> hours = hour.group(<span class="built_in">Math</span>.floor)</span><br></pre></td></tr></table></figure><p>这段代码首先创建了一个 crossfilter 对象，数据来源是 CSV 格式的文本。之后，我们定义了一个“小时”的维度，它是从 <code>date</code> 字段计算得到的，并近似到了整数，用作 Group By 条件。定义完这个查询后，我们就可以获取航班延误次数最多的三个小时的数据了：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hours.top(<span class="number">3</span>)</span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">[</span><br><span class="line">  &#123; <span class="attr">key</span>: <span class="number">13</span>, <span class="attr">value</span>: <span class="number">72</span> &#125;,</span><br><span class="line">  &#123; <span class="attr">key</span>: <span class="number">20</span>, <span class="attr">value</span>: <span class="number">72</span> &#125;,</span><br><span class="line">  &#123; <span class="attr">key</span>:  <span class="number">8</span>, <span class="attr">value</span>: <span class="number">71</span> &#125;,</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><p>我们将 24 个小时的延误次数用柱状图展现出来：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> hourChart = dc.barChart(<span class="string">'#hour-chart'</span>)</span><br><span class="line">hourChart</span><br><span class="line">  .width(<span class="number">350</span>)</span><br><span class="line">  .height(<span class="number">150</span>)</span><br><span class="line">  .dimension(hour)</span><br><span class="line">  .group(hours)</span><br><span class="line">  .x(d3.scale.linear()</span><br><span class="line">    .domain([<span class="number">0</span>, <span class="number">24</span>])</span><br><span class="line">    .rangeRound([<span class="number">0</span>, <span class="number">10</span> * <span class="number">24</span>]))</span><br><span class="line">  .controlsUseVisibility(<span class="literal">true</span>)</span><br></pre></td></tr></table></figure><p>对应的 HTML 代码是：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"hour-chart"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"title"</span>&gt;</span>Time of Day</span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"reset"</span> <span class="attr">href</span>=<span class="string">"javascript:;"</span> <span class="attr">style</span>=<span class="string">"visibility: hidden;"</span>&gt;</span>reset<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure><p>我们可以看到，dc.js 和 crossfilter 结合的非常好，只需将维度信息传入 dc.js ，并对坐标轴进行适当配置，就可以完成可视化。在这个例子中，X 轴是 0 到 24 个小时（维度），Y 轴则是航班延误次数（度量）。</p><p>注意这里 <code>class=&quot;reset&quot;</code> 的用法，它和 <code>controlUseVisibility</code> 一起使用，会在指定位置产生一个 <code>reset</code> 按钮。你可以试着在图表上进行拖拽，对数据进行筛选后就能看到 <code>reset</code> 按钮了。</p><h2 id="交叉过滤"><a href="#交叉过滤" class="headerlink" title="交叉过滤"></a>交叉过滤</h2><p>接下来我们可以创建更多图表，如航班延误时间的直方图，源代码可以在 JSFiddle 中找到。当你对其中一个图表进行过滤时，其他图表就会自动过滤和更新，这样我们就可以查看某些限定条件下数据的分布情况了。</p><p>dc.js 还提供了许多可视化类型，如饼图、表格、自定义HTML等。当然，要完全掌握这些，还需要学习 d3.js ，市面上很多绘图类库都是构建在它之上的。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://crossfilter.github.io/crossfilter/" target="_blank" rel="noopener">Crossfilter - Fast Multidimensional Filtering for Coordinated Views</a></li><li><a href="https://dc-js.github.io/dc.js/" target="_blank" rel="noopener">dc.js - Dimensional Charting Javascript Library</a></li><li><a href="http://blog.rusty.io/2012/09/17/crossfilter-tutorial/" target="_blank" rel="noopener">Crossfiler Tutorial</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在对多维数据集进行图表分析时，我们希望在图表之间建立联系，选择图表中的一部分数据后，其他图表也会相应变动。这项工作可以通过开发完成，即在服务端对数据进行过滤，并更新所有图表。此外，我们还可以借助 Crossfilter 和 dc.js 这两个工具，直接在浏览器中对数据进行操作。&lt;/p&gt;
&lt;h2 id=&quot;航班延误统计&quot;&gt;&lt;a href=&quot;#航班延误统计&quot; class=&quot;headerlink&quot; title=&quot;航班延误统计&quot;&gt;&lt;/a&gt;航班延误统计&lt;/h2&gt;&lt;p&gt;这是 Crossfilter 官方网站提供的示例，基于 &lt;a href=&quot;http://stat-computing.org/dataexpo/2009/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ASA Data Expo&lt;/a&gt; 数据集的航班延误统计。下面我们将介绍如何用 dc.js 来实现这份交互式报表。项目源码可以在 &lt;a href=&quot;https://jsfiddle.net/zjerryj/gjao9sws/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;JSFiddle&lt;/a&gt; 中浏览，演示的数据量减少到 1000 条。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/cnblogs/images/airline-ontime-performance.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/cnblogs/categories/Big-Data/"/>
    
    
      <category term="crossfilter" scheme="http://shzhangji.com/cnblogs/tags/crossfilter/"/>
    
      <category term="dc.js" scheme="http://shzhangji.com/cnblogs/tags/dc-js/"/>
    
      <category term="analytics" scheme="http://shzhangji.com/cnblogs/tags/analytics/"/>
    
  </entry>
  
</feed>
